+ echo Logging output to experiments/logs/train_vgg_cnn_m_1024.txt.2017-01-10_14-27-22
Logging output to experiments/logs/train_vgg_cnn_m_1024.txt.2017-01-10_14-27-22
+ ./tools/train_net.py --gpu 0
Called with args:
Namespace(cfg_file=None, gpu_id=0, imdb_name='sensiac_train', max_iters=40000, pretrained_model='data/imagenet_models/VGG_CNN_M_1024.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/VGG_CNN_M_1024/solver.prototxt')
Using config:
{'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'IR_Reg',
 'PIXEL_MEANS': array([[[ 102.9801,  115.9465,  122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec',
 'TEST': {'BBOX_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'BATCH_SIZE': 128,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.1,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'IMS_PER_BATCH': 2,
           'MAX_SIZE': 1000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False}}
Loaded dataset `train` for training
Appending horizontally-flipped training examples...
ss roi
yes
/home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/tools/../lib/datasets/../../data/sample_data/Annotations/IR_Reg/train.txt
[[398 196 444 218]]
[[330 202 388 228]]
[[279 174 339 202]]
[[404 192 448 216]]
[[173 170 219 198]]
[[418 197 446 217]]
[[228 191 256 213]]
[[353 186 429 218]]
[[415 186 477 212]]
[[283 179 351 205]]
[[415 199 449 219]]
[[360 206 410 228]]
[[332 206 378 228]]
[[114 203 186 237]]
[[445 186 519 218]]
[[382 196 424 218]]
[[190 192 240 218]]
[[177 184 217 206]]
[[180 169 232 197]]
[[438 189 490 215]]
[[277 194 327 216]]
[[361 196 449 230]]
[[422 191 458 215]]
[[225 187 251 207]]
[[440 190 474 214]]
[[362 188 412 210]]
[[488 186 556 218]]
[[169 186 203 208]]
[[234 187 272 207]]
[[358 167 432 199]]
[[293 196 345 218]]
[[258 190 312 214]]
[[424 191 456 215]]
[[287 207 375 241]]
[[166 188 200 210]]
[[379 186 427 210]]
[[419 189 455 213]]
[[324 196 376 218]]
[[417 202 481 228]]
[[394 204 436 226]]
[[206 200 246 222]]
[[341 206 431 240]]
[[324 182 388 208]]
[[165 180 209 206]]
[[171 179 201 205]]
[[226 200 274 222]]
[[414 188 452 212]]
[[357 194 407 216]]
[[468 193 498 221]]
[[ 59 167 109 199]]
[[451 186 491 214]]
[[194 181 256 209]]
[[422 202 486 228]]
[[198 175 254 201]]
[[382 191 430 213]]
[[413 204 433 222]]
[[359 184 409 208]]
[[451 195 493 223]]
[[377 194 425 216]]
[[316 190 356 210]]
[[536 182 572 214]]
[[493 200 529 226]]
[[304 206 352 228]]
[[500 207 554 241]]
[[378 186 430 210]]
[[268 188 310 208]]
[[249 187 291 207]]
[[396 202 428 222]]
[[431 187 483 215]]
[[341 190 409 216]]
[[417 207 447 229]]
[[257 189 297 211]]
[[415 191 455 215]]
[[223 200 271 222]]
[[408 196 452 218]]
[[188 193 230 219]]
[[284 194 336 216]]
[[184 180 228 204]]
[[148 205 234 239]]
[[177 180 253 212]]
[[415 200 463 222]]
[[326 193 366 215]]
[[412 198 474 224]]
[[446 195 476 219]]
[[ 66 167 108 199]]
[[441 193 475 215]]
[[278 181 346 209]]
[[111 195 191 229]]
[[522 179 574 211]]
[[193 196 235 222]]
[[443 193 481 217]]
[[493 207 559 241]]
[[271 188 313 208]]
[[209 200 241 222]]
[[419 196 467 218]]
[[439 193 475 217]]
[[179 181 233 209]]
[[400 203 424 221]]
[[410 206 450 228]]
[[210 200 240 222]]
[[369 185 417 209]]
[[290 190 332 210]]
[[ 63 170 117 202]]
[[217 200 263 222]]
[[394 182 452 210]]
[[290 194 344 216]]
[[418 196 466 218]]
[[263 180 333 208]]
[[257 200 321 226]]
[[302 192 344 214]]
[[364 202 402 220]]
[[392 181 452 209]]
[[198 192 248 214]]
[[491 200 529 226]]
[[433 201 521 235]]
[[407 191 469 217]]
[[486 208 556 242]]
[[370 198 424 220]]
[[237 195 275 213]]
[[479 199 557 233]]
[[255 208 345 242]]
[[113 195 195 229]]
[[183 184 225 208]]
[[442 200 478 222]]
[[384 197 472 231]]
[[309 186 355 210]]
[[394 190 458 216]]
[[100 195 168 229]]
[[371 190 437 216]]
[[117 190 173 218]]
[[208 177 260 201]]
[[214 191 274 217]]
[[325 214 409 248]]
[[477 191 521 219]]
[[246 190 294 212]]
[[331 198 371 216]]
[[491 200 529 226]]
[[359 196 447 230]]
[[390 206 438 228]]
[[189 194 227 220]]
[[398 202 430 220]]
[[162 185 186 207]]
[[288 185 338 209]]
[[164 179 206 205]]
[[166 183 202 205]]
[[449 191 497 217]]
[[ 57 168  99 200]]
[[295 201 357 227]]
[[281 188 323 208]]
[[444 186 488 214]]
[[451 192 477 214]]
[[373 206 423 228]]
[[181 185 233 213]]
[[233 191 273 213]]
[[505 207 555 241]]
[[ 70 166 126 198]]
[[412 196 460 218]]
[[353 206 403 228]]
[[427 194 465 216]]
[[411 205 447 227]]
[[245 172 307 200]]
[[417 206 447 228]]
[[357 196 445 230]]
[[280 194 330 216]]
[[240 192 284 214]]
[[238 193 290 215]]
[[168 171 210 199]]
[[215 180 249 204]]
[[151 178 225 210]]
[[447 187 491 215]]
[[177 183 217 207]]
[[263 199 313 221]]
[[425 190 455 214]]
[[277 194 331 216]]
[[454 191 478 213]]
[[536 183 576 215]]
[[287 191 347 217]]
[[200 198 254 224]]
[[447 187 499 213]]
[[222 196 260 216]]
[[348 202 408 228]]
[[430 201 518 235]]
[[387 191 435 215]]
[[435 193 473 217]]
[[237 190 299 216]]
[[218 170 280 198]]
[[460 199 514 225]]
[[375 190 425 212]]
[[343 191 385 211]]
[[365 183 433 209]]
[[194 197 242 223]]
[[474 172 540 204]]
[[341 193 401 219]]
[[396 206 442 228]]
[[367 206 417 228]]
[[240 209 332 243]]
[[307 194 359 216]]
[[231 189 263 209]]
[[189 181 251 209]]
[[443 200 529 234]]
[[223 202 267 224]]
[[337 193 389 215]]
[[239 183 289 205]]
[[167 174 211 202]]
[[493 186 559 218]]
[[442 198 478 220]]
[[190 170 248 198]]
[[371 193 413 213]]
[[428 197 472 219]]
[[186 176 236 202]]
[[222 198 292 226]]
[[163 171 197 199]]
[[160 178 200 202]]
[[321 189 389 215]]
[[418 191 458 215]]
[[455 192 481 214]]
[[393 200 445 222]]
[[444 187 498 213]]
[[453 201 479 223]]
[[316 179 376 207]]
[[438 199 478 221]]
[[420 197 446 217]]
[[380 190 446 216]]
[[229 191 259 213]]
[[398 195 450 217]]
[[360 192 402 212]]
[[365 195 407 217]]
[[410 198 446 220]]
[[346 184 394 208]]
[[378 201 414 221]]
[[358 180 420 208]]
[[244 190 282 210]]
[[420 198 448 218]]
[[425 186 483 212]]
[[439 193 481 217]]
[[427 200 471 222]]
[[447 195 475 219]]
[[447 202 507 228]]
[[228 188 258 208]]
[[252 190 302 212]]
[[395 194 433 214]]
[[362 199 432 227]]
[[445 193 475 215]]
[[303 201 343 221]]
[[357 203 419 229]]
[[236 182 312 214]]
[[431 188 489 214]]
[[444 196 476 220]]
[[364 206 414 228]]
[[337 182 401 208]]
[[211 200 245 222]]
[[431 200 473 222]]
[[489 200 529 226]]
[[326 207 412 241]]
[[222 195 260 213]]
[[482 200 526 226]]
[[200 195 226 213]]
[[259 199 309 221]]
[[325 183 377 207]]
[[170 177 206 203]]
[[424 198 450 218]]
[[187 176 241 202]]
[[ 69 167 119 199]]
[[356 191 424 217]]
[[348 192 402 216]]
[[329 184 393 212]]
[[394 193 430 213]]
[[342 194 384 216]]
[[426 190 458 214]]
[[355 197 443 231]]
[[ 75 171 133 203]]
[[390 202 424 220]]
[[471 190 505 216]]
[[303 188 353 210]]
[[321 201 371 223]]
[[303 194 357 216]]
[[292 204 342 226]]
[[474 199 554 233]]
[[250 181 320 209]]
[[234 172 296 200]]
[[226 180 270 204]]
[[344 193 396 215]]
[[313 179 373 207]]
[[361 183 429 209]]
[[442 186 488 214]]
[[469 199 519 225]]
[[296 190 348 214]]
[[238 181 308 209]]
[[420 191 458 215]]
[[425 188 467 212]]
[[101 196 151 230]]
[[282 182 332 206]]
[[475 196 517 224]]
[[405 197 443 219]]
[[327 192 377 214]]
[[342 200 414 228]]
[[382 186 448 212]]
[[400 195 436 215]]
[[353 201 393 221]]
[[269 190 331 216]]
[[268 191 310 213]]
[[223 178 285 204]]
[[214 179 250 203]]
[[219 195 257 213]]
[[406 189 468 215]]
[[261 191 315 215]]
[[307 198 347 216]]
[[349 198 387 216]]
[[332 206 420 240]]
[[345 206 395 228]]
[[236 187 274 207]]
[[183 183 245 209]]
[[181 178 235 206]]
[[156 179 230 211]]
[[391 199 443 221]]
[[363 192 405 212]]
[[385 191 433 215]]
[[162 186 188 208]]
[[432 195 470 217]]
[[474 186 544 218]]
[[194 169 252 197]]
[[180 181 236 209]]
[[204 195 234 213]]
[[201 196 225 214]]
[[422 194 462 216]]
[[361 190 411 212]]
[[331 184 379 208]]
[[172 186 234 214]]
[[417 197 503 231]]
[[405 190 449 214]]
[[446 193 482 217]]
[[404 195 454 217]]
[[ 72 168 106 200]]
[[279 193 331 215]]
[[427 190 459 214]]
[[371 192 425 216]]
[[248 193 300 215]]
[[244 171 306 199]]
[[113 189 165 217]]
[[378 202 414 220]]
[[198 195 218 213]]
[[471 191 519 219]]
[[447 192 481 214]]
[[246 189 292 211]]
[[188 196 260 224]]
[[213 195 249 215]]
[[201 195 231 213]]
[[386 194 426 214]]
[[272 200 336 226]]
[[492 206 552 240]]
[[193 191 239 213]]
[[132 205 214 239]]
[[393 185 459 213]]
[[461 191 499 219]]
[[304 193 346 215]]
[[243 199 293 221]]
[[391 192 439 214]]
[[387 193 425 213]]
[[183 196 255 224]]
[[156 178 230 210]]
[[369 203 431 229]]
[[304 193 356 217]]
[[301 181 367 207]]
[[166 179 204 205]]
[[281 187 331 209]]
[[245 179 299 203]]
[[202 195 234 213]]
[[272 205 322 227]]
[[391 195 443 217]]
[[178 185 220 209]]
[[315 193 357 215]]
[[211 195 247 215]]
[[170 166 244 198]]
[[234 189 288 213]]
[[429 185 483 213]]
[[341 206 391 228]]
[[164 186 192 208]]
[[326 191 380 215]]
[[229 187 253 207]]
[[463 199 545 233]]
[[393 194 445 216]]
[[496 175 556 207]]
[[275 196 359 230]]
[[282 196 366 230]]
[[239 190 275 210]]
[[169 179 201 205]]
[[437 193 473 215]]
[[296 190 348 212]]
[[228 188 260 208]]
[[408 190 450 214]]
[[379 190 427 214]]
[[231 196 269 216]]
[[431 197 473 219]]
[[452 199 536 233]]
[[279 167 349 199]]
[[470 187 540 219]]
[[209 185 257 207]]
[[244 191 298 215]]
[[404 195 438 215]]
[[405 205 443 227]]
[[443 199 479 221]]
[[257 180 327 208]]
[[162 180 190 204]]
[[239 195 279 213]]
[[424 200 468 222]]
[[371 190 421 214]]
[[247 196 287 214]]
[[220 179 288 207]]
[[175 183 211 207]]
[[128 165 202 197]]
[[301 182 349 206]]
[[429 187 481 215]]
[[195 192 249 218]]
[[323 182 393 210]]
[[400 188 448 212]]
[[244 180 292 204]]
[[414 196 444 216]]
[[201 195 227 213]]
[[161 178 237 210]]
[[291 175 349 203]]
[[373 195 425 217]]
[[230 196 316 230]]
[[355 206 405 228]]
[[367 190 417 214]]
[[230 188 284 212]]
[[250 195 290 213]]
[[304 183 352 207]]
[[215 180 243 204]]
[[390 197 478 231]]
[[236 190 270 210]]
[[464 202 538 236]]
[[254 180 308 204]]
[[276 193 328 215]]
[[303 189 345 209]]
[[399 189 443 213]]
[[287 194 341 216]]
[[397 203 423 221]]
[[419 185 479 211]]
[[237 182 301 210]]
[[162 186 188 208]]
[[205 181 271 209]]
[[285 200 331 222]]
[[225 179 271 203]]
[[544 182 580 214]]
[[175 170 223 198]]
[[420 169 492 201]]
[[426 198 486 224]]
[[470 202 524 228]]
[[365 190 433 216]]
[[412 192 458 216]]
[[223 184 271 206]]
[[224 193 276 215]]
[[133 165 207 197]]
[[428 191 472 215]]
[[392 199 458 227]]
[[257 193 307 215]]
[[438 186 486 214]]
[[294 182 342 206]]
[[439 186 489 214]]
[[346 190 414 216]]
[[248 203 298 225]]
[[164 177 206 201]]
[[456 187 488 215]]
[[320 189 388 215]]
[[168 182 202 206]]
[[437 200 475 222]]
[[414 194 462 218]]
[[302 175 362 203]]
[[421 191 455 215]]
[[327 197 409 231]]
[[229 182 305 214]]
[[302 194 354 216]]
[[327 214 413 248]]
[[326 206 372 228]]
[[453 191 499 217]]
[[453 192 477 214]]
[[233 190 271 212]]
[[225 195 263 213]]
[[516 185 574 217]]
[[366 202 414 224]]
[[392 202 426 220]]
[[159 166 233 198]]
[[442 185 488 213]]
[[195 197 243 223]]
[[283 191 325 213]]
[[419 184 471 212]]
[[230 188 256 208]]
[[342 197 394 219]]
[[321 188 371 210]]
[[122 177 192 209]]
[[446 199 482 221]]
[[231 191 267 213]]
[[454 200 532 234]]
[[280 181 350 209]]
[[386 204 430 226]]
[[376 192 430 216]]
[[191 185 237 209]]
[[444 200 504 226]]
[[167 186 201 208]]
[[187 170 245 198]]
[[501 207 559 241]]
[[415 192 461 216]]
[[215 190 267 214]]
[[161 185 185 207]]
[[257 193 309 215]]
[[189 191 237 213]]
[[215 180 249 204]]
[[399 206 445 228]]
[[403 186 467 212]]
[[388 182 448 210]]
[[165 179 205 205]]
[[246 181 294 205]]
[[390 190 454 216]]
[[243 183 293 205]]
[[ 76 170 124 202]]
[[371 206 463 240]]
[[444 192 480 214]]
[[271 213 361 247]]
[[397 203 461 229]]
[[370 201 408 221]]
[[354 185 404 209]]
[[415 206 447 228]]
[[235 196 273 216]]
[[337 195 377 217]]
[[287 190 329 210]]
[[442 195 476 219]]
[[216 188 268 212]]
[[214 208 304 242]]
[[383 201 447 227]]
[[406 205 444 227]]
[[272 198 344 226]]
[[438 185 484 213]]
[[233 182 297 210]]
[[165 188 199 210]]
[[413 183 467 211]]
[[337 183 403 209]]
[[448 193 478 215]]
[[407 204 433 222]]
[[534 183 578 215]]
[[395 206 441 228]]
[[396 200 448 222]]
[[287 213 375 247]]
[[413 186 475 212]]
[[131 184 181 212]]
[[390 190 454 216]]
[[238 185 288 207]]
[[456 199 510 225]]
[[468 186 540 218]]
[[337 191 379 211]]
[[317 195 369 217]]
[[321 205 367 227]]
[[373 202 409 222]]
[[437 193 473 215]]
[[257 199 299 219]]
[[212 179 264 203]]
[[176 182 226 210]]
[[415 184 469 212]]
[[443 200 479 222]]
[[207 194 241 214]]
[[170 178 210 204]]
[[216 201 258 223]]
[[214 180 244 204]]
[[328 184 376 208]]
[[205 200 245 222]]
[[438 192 476 214]]
[[353 189 403 213]]
[[188 193 232 219]]
[[242 190 280 210]]
[[192 183 234 205]]
[[190 195 230 221]]
[[366 206 458 240]]
[[375 206 425 228]]
[[419 195 461 217]]
[[450 186 524 218]]
[[242 197 282 217]]
[[258 181 328 209]]
[[170 189 208 211]]
[[383 196 445 222]]
[[271 199 319 221]]
[[320 189 370 211]]
[[394 190 458 216]]
[[132 183 184 211]]
[[455 188 499 214]]
[[325 202 367 222]]
[[230 191 262 213]]
[[233 189 287 213]]
[[299 201 339 221]]
[[219 193 271 215]]
[[287 192 329 214]]
[[444 192 494 218]]
[[455 199 539 233]]
[[479 208 553 242]]
[[413 207 449 229]]
[[205 176 255 200]]
[[408 206 450 228]]
[[258 166 330 198]]
[[310 179 370 207]]
[[295 181 365 209]]
[[433 187 493 215]]
[[485 186 553 218]]
[[404 169 476 201]]
[[413 196 457 218]]
[[455 184 491 212]]
[[406 187 470 213]]
[[409 188 449 212]]
[[383 199 415 217]]
[[421 200 467 222]]
[[233 197 273 217]]
[[111 189 161 217]]
[[399 212 489 246]]
[[368 199 438 227]]
[[445 185 489 213]]
[[109 189 155 217]]
[[180 180 246 208]]
[[377 195 419 217]]
[[467 193 497 221]]
[[219 200 265 222]]
[[316 201 356 221]]
[[215 179 243 203]]
[[339 206 387 228]]
[[431 213 519 247]]
[[180 189 224 211]]
[[288 201 350 227]]
[[165 170 199 198]]
[[536 184 584 216]]
[[108 201 174 235]]
[[445 187 491 215]]
[[281 193 335 215]]
[[187 176 239 202]]
[[394 192 446 216]]
[[278 183 350 215]]
[[404 200 468 228]]
[[182 186 226 210]]
[[260 188 328 214]]
[[350 193 402 215]]
[[173 180 209 204]]
[[311 185 385 217]]
[[196 192 242 214]]
[[362 193 404 213]]
[[178 177 232 205]]
[[226 191 286 217]]
[[340 188 390 212]]
[[218 200 264 222]]
[[385 186 431 210]]
[[313 188 363 210]]
[[214 177 276 203]]
[[356 201 396 221]]
[[436 198 494 224]]
[[201 195 221 213]]
[[426 192 468 216]]
[[291 184 363 216]]
[[207 195 241 213]]
[[439 191 477 213]]
[[229 199 277 221]]
[[219 201 261 223]]
[[376 199 430 221]]
[[211 177 263 201]]
[[209 181 277 209]]
[[457 192 481 214]]
[[422 187 498 219]]
[[320 192 374 216]]
[[214 180 244 204]]
[[430 192 474 216]]
[[283 181 353 209]]
[[354 194 406 216]]
[[337 202 379 222]]
[[239 199 303 225]]
[[376 193 418 213]]
[[437 198 477 220]]
[[193 185 239 209]]
[[444 200 478 222]]
[[267 181 321 205]]
[[373 193 415 213]]
[[476 200 524 226]]
[[418 207 448 229]]
[[167 186 237 214]]
[[415 192 453 216]]
[[381 184 447 212]]
[[198 195 220 213]]
[[377 186 425 210]]
[[385 202 421 220]]
[[449 200 481 222]]
[[421 190 457 214]]
[[201 195 229 213]]
[[396 194 448 216]]
[[330 193 384 217]]
[[507 186 569 218]]
[[164 169 200 197]]
[[433 198 475 220]]
[[221 194 257 212]]
[[302 206 350 228]]
[[470 196 516 224]]
[[199 195 225 213]]
[[316 183 386 211]]
[[411 202 501 236]]
[[479 196 519 224]]
[[254 181 318 209]]
[[478 200 524 226]]
[[322 182 374 206]]
[[431 185 481 213]]
[[294 181 364 209]]
[[384 194 436 216]]
[[160 184 186 206]]
[[405 202 469 228]]
[[276 189 342 215]]
[[338 196 390 218]]
[[440 194 476 218]]
[[421 197 467 219]]
[[265 205 315 227]]
[[206 195 236 213]]
[[260 200 324 226]]
[[354 184 404 208]]
[[420 202 510 236]]
[[428 202 490 228]]
[[129 187 197 215]]
[[297 197 381 231]]
[[409 188 471 214]]
[[175 206 263 240]]
[[175 178 221 204]]
[[247 183 297 205]]
[[202 170 262 198]]
[[372 196 460 230]]
[[308 201 354 223]]
[[447 200 481 222]]
[[422 198 482 224]]
[[412 197 498 231]]
[[315 205 363 227]]
[[159 179 199 203]]
[[274 204 324 226]]
[[228 202 274 224]]
[[400 186 464 212]]
[[459 189 505 215]]
[[254 172 314 200]]
[[318 192 374 218]]
[[434 198 516 232]]
[[234 195 274 213]]
[[231 197 271 217]]
[[217 185 265 207]]
[[238 181 284 205]]
[[189 196 277 230]]
[[249 190 311 216]]
[[483 200 527 226]]
[[264 207 354 241]]
[[451 192 483 214]]
[[215 177 267 201]]
[[358 202 406 224]]
[[191 195 233 221]]
[[182 184 230 212]]
[[367 202 405 220]]
[[375 195 437 221]]
[[427 201 515 235]]
[[334 196 386 218]]
[[320 206 366 228]]
[[404 203 432 221]]
[[209 195 243 215]]
[[424 198 446 218]]
[[323 206 369 228]]
[[306 206 354 228]]
[[205 181 271 209]]
[[201 177 251 201]]
[[334 192 384 214]]
[[237 195 277 213]]
[[265 193 315 215]]
[[191 206 281 240]]
[[299 201 345 223]]
[[430 198 474 220]]
[[382 203 428 225]]
[[207 196 235 214]]
[[369 186 417 210]]
[[171 180 205 204]]
[[366 186 414 210]]
[[232 191 270 213]]
[[394 197 456 223]]
[[372 211 464 245]]
[[245 198 317 226]]
[[382 185 450 213]]
[[232 177 296 203]]
[[107 195 185 229]]
[[177 184 235 210]]
[[268 190 320 212]]
[[222 180 264 204]]
[[177 181 217 205]]
[[161 172 199 200]]
[[319 190 361 210]]
[[349 201 389 219]]
[[418 192 454 216]]
[[360 198 414 220]]
[[ 67 170 123 202]]
[[179 185 235 213]]
[[450 201 478 223]]
[[253 193 303 215]]
[[417 188 475 216]]
[[447 200 527 234]]
[[416 198 448 218]]
[[434 201 496 227]]
[[362 195 404 217]]
[[228 197 268 217]]
[[391 204 435 226]]
[[482 192 522 220]]
[[296 197 336 215]]
[[356 206 406 228]]
[[287 194 337 216]]
[[374 196 462 230]]
[[341 203 399 229]]
[[228 187 252 207]]
[[226 195 264 213]]
[[332 193 374 215]]
[[485 193 523 221]]
[[357 201 419 227]]
[[453 184 491 212]]
[[207 197 279 225]]
[[416 191 476 217]]
[[225 180 269 204]]
[[280 205 330 227]]
[[426 170 498 202]]
[[431 193 469 215]]
[[293 205 343 227]]
[[444 191 476 215]]
[[236 187 276 207]]
[[181 185 231 213]]
[[277 184 337 212]]
[[202 195 230 213]]
[[412 198 448 220]]
[[415 207 449 229]]
[[395 185 457 213]]
[[417 207 449 229]]
[[377 206 427 228]]
[[306 201 352 223]]
[[169 189 209 211]]
[[309 189 351 209]]
[[348 192 390 212]]
[[208 198 264 224]]
[[108 201 176 235]]
[[423 191 455 215]]
[[229 202 275 224]]
[[210 200 252 222]]
[[443 199 499 225]]
[[267 195 307 213]]
[[341 184 389 208]]
[[385 186 451 212]]
[[220 181 282 209]]
[[425 191 455 215]]
[[372 203 434 229]]
[[342 206 390 228]]
[[451 200 483 222]]
[[447 200 479 222]]
[[460 188 500 214]]
[[335 193 377 215]]
[[532 180 578 212]]
[[249 192 299 214]]
[[230 187 252 207]]
[[357 194 419 220]]
[[401 190 447 214]]
[[462 171 530 203]]
[[ 60 168  98 200]]
[[305 180 371 206]]
[[453 190 499 216]]
[[373 190 423 214]]
[[424 197 468 219]]
[[266 199 308 219]]
[[427 199 453 219]]
[[ 95 164 163 196]]
[[472 190 504 216]]
[[401 192 451 216]]
[[376 190 426 214]]
[[318 201 378 227]]
[[368 202 416 224]]
[[364 193 416 215]]
[[317 182 369 206]]
[[131 164 205 196]]
[[271 197 311 215]]
[[323 185 397 217]]
[[306 207 390 241]]
[[128 205 210 239]]
[[259 189 299 211]]
[[161 184 189 206]]
[[361 206 411 228]]
[[239 198 311 226]]
[[356 195 398 217]]
[[320 183 366 207]]
[[394 196 446 218]]
[[391 187 441 211]]
[[201 184 247 206]]
[[401 205 441 227]]
[[396 190 442 212]]
[[541 181 579 213]]
[[425 190 455 214]]
[[439 187 513 219]]
[[411 188 451 212]]
[[390 190 438 214]]
[[218 170 280 198]]
[[240 177 306 203]]
[[383 187 445 215]]
[[402 202 466 228]]
[[282 200 330 222]]
[[420 185 476 213]]
[[140 183 196 211]]
[[297 193 339 215]]
[[110 175 178 207]]
[[372 203 418 225]]
[[357 185 421 213]]
[[171 180 201 204]]
[[441 194 473 216]]
[[273 191 315 213]]
[[220 178 282 204]]
[[527 185 581 217]]
[[426 201 488 227]]
[[453 192 479 214]]
[[215 170 277 198]]
[[211 201 247 223]]
[[468 202 540 236]]
[[209 195 241 213]]
[[510 185 572 217]]
[[281 181 333 205]]
[[436 200 476 222]]
[[411 187 471 215]]
[[190 194 228 220]]
[[315 213 397 247]]
[[280 200 328 222]]
[[248 190 302 214]]
[[463 196 513 224]]
[[174 170 220 198]]
[[150 179 224 211]]
[[272 182 344 214]]
[[222 178 286 204]]
[[453 202 511 228]]
[[268 197 308 215]]
[[231 191 265 213]]
[[383 211 473 245]]
[[473 191 507 217]]
[[374 201 438 227]]
[[416 188 492 220]]
[[206 192 256 214]]
[[340 178 402 206]]
[[440 185 486 213]]
[[408 200 456 222]]
[[260 180 330 208]]
[[348 197 432 231]]
[[249 178 315 204]]
[[459 189 501 215]]
[[355 189 405 213]]
[[239 180 287 204]]
[[305 184 377 216]]
[[149 166 223 198]]
[[343 191 385 211]]
[[471 190 503 216]]
[[294 200 340 222]]
[[318 198 358 216]]
[[461 194 497 222]]
[[173 190 211 212]]
[[400 194 434 214]]
[[481 208 555 242]]
[[280 198 352 226]]
[[316 187 364 211]]
[[242 187 282 207]]
[[321 167 395 199]]
[[399 197 439 219]]
[[197 191 247 213]]
[[201 196 227 214]]
[[325 189 393 215]]
[[357 211 447 245]]
[[417 197 445 217]]
[[469 210 547 244]]
[[272 189 324 211]]
[[390 202 424 222]]
[[260 199 302 219]]
[[222 191 282 217]]
[[424 200 470 222]]
[[485 195 519 223]]
[[414 202 478 228]]
[[232 180 278 204]]
[[436 199 492 227]]
[[314 187 360 211]]
[[183 179 239 207]]
[[200 196 224 214]]
[[185 170 243 198]]
[[422 198 450 218]]
[[294 193 336 215]]
[[459 187 531 219]]
[[240 171 302 199]]
[[336 184 384 208]]
[[309 180 375 206]]
[[235 209 327 243]]
[[379 197 467 231]]
[[291 184 365 216]]
[[272 182 324 206]]
[[463 193 497 221]]
[[217 179 259 203]]
[[448 192 478 214]]
[[317 176 379 204]]
[[402 189 464 215]]
[[270 193 324 215]]
[[247 189 295 211]]
[[503 186 567 218]]
[[402 194 436 214]]
[[420 191 454 215]]
[[388 190 436 214]]
[[308 192 360 214]]
[[190 184 222 212]]
[[126 191 186 219]]
[[245 196 331 230]]
[[179 184 219 208]]
[[381 202 415 222]]
[[252 193 304 215]]
[[208 191 260 213]]
[[363 203 425 229]]
[[450 193 478 215]]
[[297 182 345 206]]
[[189 184 225 212]]
[[215 180 243 204]]
[[281 207 371 241]]
[[438 186 488 214]]
[[282 205 332 227]]
[[285 207 373 241]]
[[161 173 201 201]]
[[415 196 463 218]]
[[161 180 235 212]]
[[272 190 314 210]]
[[292 179 358 205]]
[[214 181 282 209]]
[[362 187 414 211]]
[[332 184 396 212]]
[[221 201 265 223]]
[[215 195 251 215]]
[[281 189 347 215]]
[[451 211 535 245]]
[[455 191 499 217]]
[[230 178 282 202]]
[[426 191 460 215]]
[[200 186 248 210]]
[[315 201 375 227]]
[[423 185 479 213]]
[[312 191 364 213]]
[[533 181 571 213]]
[[424 213 512 247]]
[[218 195 252 215]]
[[198 195 222 213]]
[[330 201 380 223]]
[[399 204 441 226]]
[[321 195 373 217]]
[[404 191 466 217]]
[[165 195 233 223]]
[[483 201 529 227]]
[[164 171 202 199]]
[[408 187 472 213]]
[[238 187 278 207]]
[[325 190 365 210]]
[[439 200 477 222]]
[[435 188 491 214]]
[[384 199 436 221]]
[[179 184 219 206]]
[[393 188 439 212]]
[[245 181 315 209]]
[[222 195 256 215]]
[[243 193 295 215]]
[[287 181 357 209]]
[[266 193 318 215]]
[[360 211 450 245]]
[[456 202 514 228]]
[[298 191 350 213]]
[[220 194 272 216]]
[[199 195 221 213]]
[[217 180 255 204]]
[[318 201 360 221]]
[[368 201 432 227]]
[[325 198 365 216]]
[[ 92 173 156 205]]
[[277 189 329 211]]
[[321 201 381 227]]
[[210 200 240 222]]
[[173 175 223 203]]
[[297 204 347 226]]
[[269 199 317 221]]
[[284 205 334 227]]
[[416 195 464 219]]
[[296 182 348 206]]
[[364 183 432 211]]
[[ 86 165 150 197]]
[[345 167 419 199]]
[[281 196 321 214]]
[[325 192 377 214]]
[[457 192 481 214]]
[[174 176 226 204]]
[[236 190 276 212]]
[[346 185 396 209]]
[[235 191 277 213]]
[[173 179 219 205]]
[[234 188 270 208]]
[[160 178 190 202]]
[[389 188 435 212]]
[[103 198 161 232]]
[[406 196 456 218]]
[[259 188 301 208]]
[[141 205 225 239]]
[[352 198 390 216]]
[[262 188 304 208]]
[[408 183 464 211]]
[[471 190 507 216]]
[[261 181 309 205]]
[[254 182 324 210]]
[[298 175 358 203]]
[[402 205 442 227]]
[[147 193 213 221]]
[[245 192 293 214]]
[[336 200 408 228]]
[[309 207 393 241]]
[[346 192 388 212]]
[[162 177 204 201]]
[[184 180 250 208]]
[[440 199 480 221]]
[[416 197 446 217]]
[[361 198 397 216]]
[[288 195 340 217]]
[[431 191 459 215]]
[[181 180 223 204]]
[[366 179 428 207]]
[[394 202 422 222]]
[[354 211 444 245]]
[[216 191 276 217]]
[[400 193 444 215]]
[[452 200 482 222]]
[[201 195 225 213]]
[[215 180 267 204]]
[[233 177 299 203]]
[[321 183 391 211]]
[[302 191 354 213]]
[[292 191 352 217]]
[[498 206 554 240]]
[[199 196 221 214]]
[[117 176 187 208]]
[[167 180 201 206]]
[[429 195 467 217]]
[[188 193 232 219]]
[[360 194 412 216]]
[[ 71 169 111 201]]
[[255 190 309 214]]
[[184 178 260 210]]
[[231 191 255 213]]
[[366 194 414 216]]
[[271 191 313 213]]
[[429 191 459 215]]
[[454 178 542 214]]
[[291 190 343 214]]
[[249 212 339 246]]
[[257 204 307 226]]
[[160 187 188 209]]
[[419 194 459 216]]
[[298 199 338 219]]
[[ 59 168 103 200]]
[[383 186 429 210]]
[[225 194 277 216]]
[[178 177 226 203]]
[[216 195 248 215]]
[[398 190 462 216]]
[[418 190 456 214]]
[[295 176 353 204]]
[[468 172 534 204]]
[[178 177 224 203]]
[[192 184 236 206]]
[[121 190 177 218]]
[[454 179 542 215]]
[[394 203 458 229]]
[[365 184 433 210]]
[[233 192 285 214]]
[[438 190 474 214]]
[[255 193 307 215]]
[[351 206 401 228]]
[[237 190 291 214]]
[[429 197 473 219]]
[[426 191 454 215]]
[[405 188 447 212]]
[[409 204 433 222]]
[[206 170 268 198]]
[[312 182 362 206]]
[[265 193 317 215]]
[[234 180 282 204]]
[[284 189 326 209]]
[[250 180 304 204]]
[[ 65 166 121 198]]
[[402 203 466 229]]
[[259 204 309 226]]
[[303 190 355 214]]
[[380 194 432 216]]
[[393 194 431 214]]
[[375 185 443 211]]
[[229 196 265 216]]
[[220 179 264 203]]
[[163 183 195 207]]
[[200 195 228 213]]
[[374 193 426 215]]
[[377 186 439 214]]
[[427 192 469 216]]
[[418 192 464 216]]
[[317 188 367 210]]
[[211 191 269 217]]
[[307 190 347 210]]
[[188 193 234 219]]
[[175 185 213 207]]
[[308 193 350 215]]
[[207 195 237 215]]
[[ 61 169 109 201]]
[[234 199 282 221]]
[[401 191 463 217]]
[[160 182 222 210]]
[[356 194 398 216]]
[[410 184 466 212]]
[[428 190 484 216]]
[[172 178 248 210]]
[[284 190 326 210]]
[[387 191 435 213]]
[[176 189 218 211]]
[[301 190 341 210]]
[[227 188 259 208]]
[[233 177 297 203]]
[[435 198 475 220]]
[[424 198 448 218]]
[[400 203 430 221]]
[[330 183 394 209]]
[[404 203 468 229]]
[[454 184 492 212]]
[[419 200 465 222]]
[[231 212 321 246]]
[[405 195 439 215]]
[[433 202 495 228]]
[[408 192 450 216]]
[[435 185 483 213]]
[[369 190 419 214]]
[[286 174 344 202]]
[[136 177 208 209]]
[[222 195 258 215]]
[[418 189 454 213]]
[[165 189 201 211]]
[[281 191 333 213]]
[[383 206 431 228]]
[[356 192 398 212]]
[[334 201 384 223]]
[[161 172 199 200]]
[[213 185 281 211]]
[[313 182 379 208]]
[[315 192 367 214]]
[[444 188 498 214]]
[[166 172 204 200]]
[[478 186 548 218]]
[[369 183 437 209]]
[[182 184 228 212]]
[[410 196 454 218]]
[[229 180 273 204]]
[[259 208 349 242]]
[[199 170 259 198]]
[[324 192 374 214]]
[[243 181 291 205]]
[[346 193 408 219]]
[[385 195 437 217]]
[[164 183 194 207]]
[[226 166 300 198]]
[[416 198 448 218]]
[[439 212 525 246]]
[[414 196 444 216]]
[[255 172 317 200]]
[[234 171 296 199]]
[[184 185 230 209]]
[[432 197 474 219]]
[[359 184 425 210]]
[[441 192 493 218]]
[[236 199 286 221]]
[[117 183 155 211]]
[[236 176 302 202]]
[[257 195 297 213]]
[[201 195 229 213]]
[[315 167 387 199]]
[[259 198 331 226]]
[[386 204 476 238]]
[[350 189 400 213]]
[[400 187 466 213]]
[[333 201 391 227]]
[[371 198 405 216]]
[[277 182 327 206]]
[[261 173 321 201]]
[[302 195 354 217]]
[[195 197 241 223]]
[[417 184 471 212]]
[[454 199 508 225]]
[[506 207 554 241]]
[[322 198 362 216]]
[[216 181 286 209]]
[[537 181 579 213]]
[[450 202 508 228]]
[[270 173 328 201]]
[[250 198 290 218]]
[[428 190 460 214]]
[[211 200 243 222]]
[[451 192 479 214]]
[[416 185 474 213]]
[[117 176 187 208]]
[[389 202 419 222]]
[[315 189 365 211]]
[[319 197 401 231]]
[[207 191 265 217]]
[[368 198 422 220]]
[[230 177 294 203]]
[[180 185 234 213]]
[[375 199 409 217]]
[[175 179 221 203]]
[[424 198 484 224]]
[[326 201 384 227]]
[[200 207 290 241]]
[[210 200 242 222]]
[[400 187 444 211]]
[[104 197 156 231]]
[[340 192 390 214]]
[[427 192 467 214]]
[[182 176 230 202]]
[[252 191 306 215]]
[[ 68 167 114 199]]
[[370 195 432 221]]
[[327 184 373 208]]
[[474 202 526 228]]
[[324 179 386 207]]
[[281 200 321 220]]
[[281 201 345 227]]
[[ 98 195 164 229]]
[[228 188 262 208]]
[[368 192 422 216]]
[[354 192 408 216]]
[[460 199 544 233]]
[[171 180 247 212]]
[[479 186 549 218]]
[[392 187 454 215]]
[[351 202 399 224]]
[[231 189 261 209]]
[[419 189 477 215]]
[[351 197 405 219]]
[[525 184 577 216]]
[[250 182 326 214]]
[[308 205 356 227]]
[[ 69 166 121 198]]
[[231 191 269 213]]
[[182 189 228 211]]
[[292 181 362 209]]
[[386 187 448 215]]
[[397 168 471 200]]
[[319 190 359 210]]
[[371 189 421 211]]
[[277 199 325 221]]
[[413 206 449 228]]
[[358 190 430 224]]
[[256 188 298 208]]
[[455 202 513 228]]
[[328 177 390 205]]
[[349 203 389 223]]
[[276 191 318 213]]
[[468 190 502 216]]
[[ 65 170 119 202]]
[[218 180 256 204]]
[[231 171 293 199]]
[[206 185 272 211]]
[[392 202 426 222]]
[[371 192 425 216]]
[[373 194 421 216]]
[[455 185 489 213]]
[[237 179 291 203]]
[[403 183 459 211]]
[[387 194 439 216]]
[[110 185 142 213]]
[[218 191 278 217]]
[[171 205 259 239]]
[[325 184 371 208]]
[[450 193 484 217]]
[[354 192 396 212]]
[[204 170 264 198]]
[[415 188 459 212]]
[[301 182 351 206]]
[[429 200 471 222]]
[[178 170 228 198]]
[[173 183 207 211]]
[[486 194 516 222]]
[[203 195 231 213]]
[[274 173 332 201]]
[[235 187 273 207]]
[[127 194 213 228]]
[[304 182 352 206]]
[[256 178 322 204]]
[[296 190 348 214]]
[[178 182 228 210]]
[[538 183 584 215]]
[[256 190 318 216]]
[[166 180 242 212]]
[[455 201 481 223]]
[[380 211 470 245]]
[[224 200 272 222]]
[[255 199 305 221]]
[[ 72 166 130 198]]
[[105 199 165 233]]
[[354 203 394 223]]
[[289 174 349 202]]
[[270 181 320 205]]
[[182 166 256 198]]
[[432 191 460 215]]
[[355 192 397 212]]
[[ 98 195 162 229]]
[[174 175 224 203]]
[[418 198 478 224]]
[[405 186 469 214]]
[[195 185 243 209]]
[[362 211 454 245]]
[[340 206 388 228]]
[[173 181 199 205]]
[[251 182 299 206]]
[[151 205 237 239]]
[[103 198 159 232]]
[[202 187 252 211]]
[[387 186 433 210]]
[[305 191 357 213]]
[[444 193 476 215]]
[[202 191 258 217]]
[[425 195 465 217]]
[[118 165 190 197]]
[[417 206 447 228]]
[[218 196 256 216]]
[[365 201 429 227]]
[[225 170 287 198]]
[[241 198 281 218]]
[[148 182 208 210]]
[[316 192 368 216]]
[[280 213 368 247]]
[[461 189 505 215]]
[[215 170 277 198]]
[[453 185 491 213]]
[[389 203 453 229]]
[[397 187 463 213]]
[[322 190 362 210]]
[[422 198 448 218]]
[[468 190 506 216]]
[[247 192 295 214]]
[[312 183 360 207]]
[[ 74 166 134 198]]
[[366 190 416 214]]
[[188 192 234 218]]
[[245 208 337 242]]
[[277 184 327 208]]
[[227 180 273 204]]
[[163 181 225 209]]
[[411 205 447 227]]
[[410 204 432 222]]
[[251 189 299 211]]
[[405 197 467 223]]
[[251 181 315 209]]
[[170 178 214 202]]
[[334 198 374 216]]
[[231 186 299 212]]
[[450 185 492 213]]
[[232 199 280 221]]
[[297 189 339 209]]
[[257 181 331 213]]
[[322 179 382 207]]
[[ 73 165 137 197]]
[[213 179 245 203]]
[[379 195 431 217]]
[[297 185 345 209]]
[[318 213 400 247]]
[[406 188 452 212]]
[[423 195 463 217]]
[[189 191 235 213]]
[[418 191 454 215]]
[[263 181 331 209]]
[[473 196 517 224]]
[[354 195 396 217]]
[[385 202 421 222]]
[[190 183 232 205]]
[[404 193 448 215]]
[[278 192 320 214]]
[[279 199 319 219]]
[[435 185 483 213]]
[[304 190 344 210]]
[[435 193 475 215]]
[[343 185 407 213]]
[[355 202 415 228]]
[[402 196 448 218]]
[[365 195 407 217]]
[[387 181 447 209]]
[[340 197 422 231]]
[[172 183 214 211]]
[[ 98 195 158 229]]
[[334 214 422 248]]
[[161 184 187 206]]
[[430 201 492 227]]
[[401 204 423 222]]
[[352 167 426 199]]
[[338 193 398 219]]
[[392 196 440 218]]
[[102 195 176 229]]
[[447 199 503 225]]
[[446 200 478 222]]
[[487 201 529 227]]
[[310 190 350 210]]
[[386 184 450 212]]
[[192 196 234 222]]
[[449 188 505 216]]
[[419 190 457 214]]
[[208 188 258 212]]
[[254 196 294 214]]
[[387 200 417 218]]
[[202 181 268 209]]
[[115 184 149 212]]
[[315 191 373 217]]
[[406 196 440 216]]
[[248 191 302 215]]
[[200 195 228 213]]
[[399 187 443 211]]
[[357 189 407 213]]
[[174 183 218 211]]
[[65526   233    62   267]]
[[247 193 299 215]]
[[440 200 478 222]]
[[227 195 267 213]]
[[202 176 260 202]]
[[249 190 299 212]]
[[251 199 293 219]]
[[405 203 425 221]]
[[209 177 271 203]]
[[454 185 490 213]]
[[313 200 353 220]]
[[474 209 550 243]]
[[381 191 429 215]]
[[486 200 562 234]]
[[238 190 274 210]]
[[396 187 440 211]]
[[175 186 235 214]]
[[285 197 325 215]]
[[371 193 423 215]]
[[295 193 347 217]]
[[216 181 292 213]]
[[266 189 318 211]]
[[447 193 475 215]]
[[420 187 482 213]]
[[476 199 556 233]]
[[275 197 315 215]]
[[216 200 262 222]]
[[334 206 382 228]]
[[399 197 437 219]]
[[183 181 241 209]]
[[467 196 515 224]]
[[425 187 485 213]]
[[407 189 449 213]]
[[342 183 408 209]]
[[210 200 240 222]]
[[203 198 259 224]]
[[228 179 298 207]]
[[444 200 478 222]]
[[296 179 362 205]]
[[168 182 204 206]]
[[260 204 310 226]]
[[246 203 296 225]]
[[202 184 246 206]]
[[410 187 472 213]]
[[399 186 465 214]]
[[371 196 413 218]]
[[390 191 436 215]]
[[356 192 410 216]]
[[292 182 340 206]]
[[293 194 347 216]]
[[437 189 473 213]]
[[404 183 460 211]]
[[172 182 204 206]]
[[444 170 514 202]]
[[288 196 328 214]]
[[358 192 412 216]]
[[431 185 481 213]]
[[416 199 450 219]]
[[509 177 567 209]]
[[183 177 231 201]]
[[233 180 279 204]]
[[219 199 279 225]]
[[275 207 365 241]]
[[ 78 172 138 204]]
[[330 190 398 216]]
[[331 192 381 214]]
[[373 199 407 217]]
[[118 183 158 211]]
[[413 190 453 214]]
[[261 189 311 211]]
[[220 180 260 204]]
[[353 195 403 217]]
[[218 177 280 203]]
[[289 183 347 211]]
[[423 192 467 216]]
[[316 201 364 223]]
[[105 188 147 216]]
[[278 191 320 213]]
[[442 193 482 217]]
[[422 187 484 213]]
[[268 196 352 230]]
[[374 186 426 210]]
[[357 207 449 241]]
[[223 199 285 225]]
[[338 206 386 228]]
[[285 182 335 206]]
[[500 207 560 241]]
[[316 196 368 218]]
[[457 199 541 233]]
[[380 203 444 229]]
[[277 183 351 215]]
[[234 189 268 209]]
[[404 197 442 219]]
[[214 195 250 213]]
[[380 201 416 221]]
[[155 205 241 239]]
[[408 183 464 211]]
[[ 83 172 145 204]]
[[165 178 209 202]]
[[446 191 476 215]]
[[415 189 453 213]]
[[239 199 289 221]]
[[246 178 300 202]]
[[439 187 495 213]]
[[270 199 312 219]]
[[342 198 382 216]]
[[239 202 287 224]]
[[202 195 232 213]]
[[339 185 403 213]]
[[448 186 492 214]]
[[316 189 384 215]]
[[323 196 373 218]]
[[463 188 505 214]]
[[223 178 275 202]]
[[396 194 432 214]]
[[276 205 326 227]]
[[513 185 573 217]]
[[177 182 215 204]]
[[228 191 256 213]]
[[469 189 507 215]]
[[428 198 488 224]]
[[384 190 432 212]]
[[410 186 474 214]]
[[349 178 411 206]]
[[337 213 425 247]]
[[281 190 323 210]]
[[170 177 208 203]]
[[241 190 303 216]]
[[158 205 246 239]]
[[354 186 408 210]]
[[ 68 167 116 199]]
[[105 165 177 197]]
[[477 204 545 238]]
[[348 192 390 212]]
[[208 200 242 222]]
[[219 180 271 204]]
[[368 198 404 216]]
[[349 200 421 228]]
[[260 183 308 207]]
[[336 197 416 231]]
[[261 189 301 211]]
[[391 192 443 216]]
[[424 198 450 218]]
[[264 195 304 213]]
[[454 177 540 213]]
[[362 180 424 208]]
[[412 204 434 222]]
[[234 202 282 224]]
[[458 194 496 222]]
[[265 190 317 212]]
[[221 170 283 198]]
[[303 197 343 215]]
[[185 181 245 209]]
[[261 196 301 214]]
[[346 201 386 221]]
[[277 181 329 205]]
[[282 199 322 219]]
[[202 169 260 197]]
[[345 194 387 216]]
[[367 189 417 211]]
[[202 195 226 213]]
[[462 199 514 225]]
[[432 200 472 222]]
[[215 179 243 203]]
[[291 181 361 209]]
[[174 181 210 205]]
[[421 184 473 212]]
[[449 192 497 218]]
[[396 191 442 215]]
[[343 201 393 223]]
[[198 195 220 213]]
[[445 199 479 221]]
[[445 190 495 216]]
[[196 179 256 207]]
[[306 191 364 217]]
[[366 211 458 245]]
[[238 187 278 207]]
[[106 200 170 234]]
[[402 203 424 221]]
[[427 191 459 215]]
[[435 186 487 214]]
[[389 187 435 211]]
[[173 183 209 207]]
[[413 199 449 219]]
[[387 203 451 229]]
[[324 189 374 211]]
[[421 186 481 212]]
[[213 201 253 223]]
[[114 175 182 207]]
[[390 199 442 221]]
[[348 188 398 212]]
[[381 199 413 217]]
[[245 199 295 221]]
[[158 182 218 210]]
[[412 191 472 217]]
[[236 191 278 213]]
[[263 193 315 215]]
[[166 195 254 229]]
[[132 187 200 215]]
[[487 194 519 222]]
[[337 197 417 231]]
[[200 181 264 209]]
[[415 207 449 229]]
[[316 183 378 211]]
[[332 178 394 206]]
[[317 191 371 215]]
[[494 200 530 226]]
[[184 175 236 201]]
[[185 180 231 204]]
[[200 196 288 230]]
[[254 203 304 225]]
[[421 190 457 214]]
[[338 190 406 216]]
[[429 187 503 219]]
[[480 204 548 238]]
[[202 195 222 213]]
[[278 179 346 205]]
[[375 199 429 221]]
[[227 188 257 208]]
[[189 193 227 219]]
[[321 176 383 204]]
[[489 200 529 226]]
[[287 205 337 227]]
[[439 200 499 226]]
[[433 198 491 224]]
[[321 183 367 207]]
[[265 213 355 247]]
[[229 191 259 213]]
[[446 193 496 219]]
[[190 192 242 218]]
[[244 197 284 217]]
[[443 189 491 217]]
[[433 187 509 219]]
[[233 179 287 203]]
[[249 199 289 219]]
[[255 198 295 218]]
[[251 203 301 225]]
[[391 206 439 228]]
[[408 193 452 215]]
[[383 187 429 211]]
[[309 201 369 227]]
[[118 164 190 196]]
[[376 190 442 216]]
[[418 200 480 228]]
[[347 206 397 228]]
[[357 201 397 219]]
[[343 206 393 228]]
[[268 181 338 209]]
[[357 193 409 215]]
[[382 201 418 221]]
[[187 179 245 207]]
[[371 191 443 225]]
[[256 182 332 214]]
[[391 168 465 200]]
[[110 189 158 217]]
[[292 187 342 209]]
[[215 200 261 222]]
[[330 184 376 208]]
[[316 201 376 227]]
[[224 171 286 199]]
[[411 183 465 211]]
[[333 188 381 212]]
[[331 202 373 222]]
[[357 186 411 210]]
[[230 191 256 213]]
[[188 181 264 213]]
[[327 187 375 211]]
[[294 189 336 209]]
[[432 191 460 215]]
[[214 194 246 214]]
[[478 173 544 205]]
[[488 200 564 234]]
[[370 195 422 217]]
[[444 202 504 228]]
[[184 176 234 202]]
[[385 206 433 228]]
[[383 191 431 215]]
[[299 182 359 210]]
[[187 192 235 218]]
[[204 185 254 209]]
[[454 178 542 214]]
[[200 195 224 213]]
[[130 177 202 209]]
[[274 179 342 205]]
[[174 195 244 223]]
[[268 204 318 226]]
[[427 199 451 219]]
[[227 199 289 225]]
[[279 205 329 227]]
[[165 173 209 201]]
[[216 179 292 211]]
[[206 181 274 209]]
[[353 189 403 213]]
[[203 191 259 217]]
[[396 202 422 220]]
[[369 193 419 215]]
[[385 182 445 210]]
[[216 179 284 207]]
[[382 202 418 220]]
[[409 200 473 228]]
[[448 195 492 223]]
[[365 190 415 214]]
[[289 192 331 214]]
[[479 192 521 220]]
[[422 199 452 219]]
[[195 176 249 202]]
[[263 179 317 203]]
[[452 191 482 215]]
[[199 195 219 213]]
[[370 206 420 228]]
[[235 181 305 209]]
[[380 168 454 200]]
[[431 188 471 212]]
[[209 195 243 213]]
[[277 213 365 247]]
[[343 185 393 209]]
[[170 174 218 202]]
[[363 202 411 224]]
[[160 177 202 201]]
[[403 200 453 222]]
[[369 186 433 214]]
[[404 197 490 231]]
[[308 182 378 210]]
[[302 199 374 227]]
[[230 195 270 213]]
[[273 180 325 204]]
[[123 194 209 228]]
[[415 189 453 213]]
[[497 186 563 218]]
[[163 186 189 208]]
[[215 201 255 223]]
[[122 183 168 211]]
[[165 188 201 210]]
[[534 181 578 213]]
[[451 193 485 217]]
[[ 82 170 138 202]]
[[279 179 347 205]]
[[223 180 265 204]]
[[357 198 395 216]]
[[206 184 252 206]]
[[457 190 501 216]]
[[286 189 352 215]]
[[229 187 263 207]]
[[412 192 452 216]]
[[286 181 338 205]]
[[478 202 528 228]]
[[440 193 474 215]]
[[410 196 458 218]]
[[354 197 408 219]]
[[311 192 363 214]]
[[325 181 389 207]]
[[265 178 333 204]]
[[291 182 339 206]]
[[346 193 398 215]]
[[378 190 428 214]]
[[194 197 240 223]]
[[347 195 389 217]]
[[237 192 281 214]]
[[331 191 373 211]]
[[392 196 432 218]]
[[250 208 340 242]]
[[422 200 466 222]]
[[319 192 371 214]]
[[417 207 447 229]]
[[225 179 293 207]]
[[317 205 365 227]]
[[432 191 462 215]]
[[339 193 393 217]]
[[470 203 542 237]]
[[369 191 437 217]]
[[429 197 513 231]]
[[388 202 422 220]]
[[313 182 383 210]]
[[337 192 387 214]]
[[300 191 360 217]]
[[245 202 295 224]]
[[529 180 577 212]]
[[331 206 417 240]]
[[215 199 275 225]]
[[310 205 358 227]]
[[170 180 202 204]]
[[228 187 254 207]]
[[249 187 317 213]]
[[357 194 409 216]]
[[222 179 266 203]]
[[455 186 489 214]]
[[359 194 421 220]]
[[258 189 308 211]]
[[229 188 283 212]]
[[194 178 242 202]]
[[288 182 338 206]]
[[405 188 481 220]]
[[466 192 498 220]]
[[340 213 428 247]]
[[441 199 481 221]]
[[433 192 477 216]]
[[410 206 450 228]]
[[ 66 167 110 199]]
[[176 184 234 210]]
[[240 192 286 214]]
[[225 202 271 224]]
[[234 193 286 215]]
[[231 180 275 204]]
[[159 180 197 204]]
[[388 192 440 216]]
[[103 197 151 231]]
[[377 191 427 213]]
[[212 201 250 223]]
[[234 191 274 213]]
[[266 198 338 226]]
[[309 181 379 209]]
[[158 178 192 202]]
[[451 192 483 214]]
[[388 202 422 222]]
[[112 202 184 236]]
[[281 182 333 206]]
[[250 172 310 200]]
[[270 184 320 208]]
[[232 191 268 213]]
[[427 187 487 213]]
[[298 190 366 216]]
[[ 71 168 109 200]]
[[406 200 456 222]]
[[189 185 233 209]]
[[116 184 152 212]]
[[362 185 412 209]]
[[290 200 336 222]]
[[257 191 311 215]]
[[388 187 438 211]]
[[351 180 413 208]]
[[311 201 359 223]]
[[394 206 440 228]]
[[178 182 230 210]]
[[413 192 453 216]]
[[292 200 332 220]]
[[210 194 240 214]]
[[387 189 463 221]]
[[492 207 558 241]]
[[217 198 287 226]]
[[350 197 436 231]]
[[216 185 284 211]]
[[184 184 228 208]]
[[411 205 447 227]]
[[ 72 168 110 200]]
[[429 192 471 216]]
[[487 200 529 226]]
[[376 184 442 212]]
[[ 93 164 163 196]]
[[448 200 478 222]]
[[377 190 443 216]]
[[ 95 172 157 204]]
[[181 170 237 198]]
[[189 193 229 219]]
[[186 179 242 207]]
[[247 202 297 224]]
[[164 170 200 198]]
[[256 182 326 210]]
[[174 183 212 205]]
[[253 199 303 221]]
[[395 189 441 213]]
[[ 59 169 107 201]]
[[407 193 457 217]]
[[330 190 372 210]]
[[170 179 212 205]]
[[293 174 353 202]]
[[216 195 252 213]]
[[407 206 449 228]]
[[327 167 401 199]]
[[394 196 434 218]]
[[476 191 506 217]]
[[441 200 501 226]]
[[119 183 161 211]]
[[189 179 235 203]]
[[386 190 434 214]]
[[193 179 253 207]]
[[206 198 262 224]]
[[266 180 336 208]]
[[519 185 575 217]]
[[453 190 503 216]]
[[343 197 427 231]]
[[451 199 507 225]]
[[447 187 489 215]]
[[297 207 383 241]]
[[113 176 181 208]]
[[431 193 471 217]]
[[343 195 385 217]]
[[209 188 261 212]]
[[275 186 325 208]]
[[200 195 226 213]]
[[165 189 197 211]]
[[432 191 462 215]]
[[448 201 478 223]]
[[362 194 424 220]]
[[246 190 284 210]]
[[333 190 383 212]]
[[417 202 481 228]]
[[163 185 187 207]]
[[287 187 337 209]]
[[355 183 423 211]]
[[466 193 498 221]]
[[327 179 389 207]]
[[209 200 241 222]]
[[266 189 306 211]]
[[387 187 433 211]]
[[227 188 261 208]]
[[164 183 198 205]]
[[346 198 384 216]]
[[287 199 359 227]]
[[420 213 508 247]]
[[415 206 447 228]]
[[230 188 258 208]]
[[ 58 167 106 199]]
[[386 186 436 210]]
[[177 189 221 211]]
[[162 173 204 201]]
[[409 190 451 214]]
[[274 188 316 208]]
[[270 181 338 209]]
[[368 203 406 223]]
[[262 182 324 210]]
[[288 179 354 205]]
[[243 179 309 205]]
[[266 200 330 226]]
[[278 200 318 220]]
[[422 193 468 217]]
[[432 190 488 216]]
[[450 190 494 218]]
[[475 192 507 218]]
[[126 183 174 211]]
[[212 200 246 222]]
[[186 183 248 209]]
[[210 191 268 217]]
[[189 169 243 197]]
[[384 190 432 214]]
[[388 186 464 218]]
[[268 186 318 208]]
[[439 198 477 220]]
[[414 185 472 213]]
[[456 186 490 214]]
[[278 205 328 227]]
[[272 204 322 226]]
[[114 165 186 197]]
[[314 180 380 206]]
[[405 203 433 221]]
[[402 195 452 217]]
[[363 196 451 230]]
[[359 194 401 216]]
[[448 200 482 222]]
[[384 192 436 216]]
[[240 187 280 207]]
[[ 99 196 151 230]]
[[287 174 345 202]]
[[377 203 423 225]]
[[209 185 277 211]]
[[454 211 538 245]]
[[411 206 449 228]]
[[371 206 421 228]]
[[418 199 450 219]]
[[238 180 308 208]]
[[360 184 430 212]]
[[235 190 269 210]]
[[397 202 461 228]]
[[179 184 239 210]]
[[306 189 348 209]]
[[149 194 237 228]]
[[292 194 344 216]]
[[282 173 340 201]]
[[345 191 413 217]]
[[408 205 446 227]]
[[368 185 436 211]]
[[336 197 388 219]]
[[171 179 235 207]]
[[187 185 233 209]]
[[201 195 227 213]]
[[487 194 523 222]]
[[429 185 479 213]]
[[339 167 413 199]]
[[476 202 528 228]]
[[188 192 238 218]]
[[449 193 475 215]]
[[313 183 359 207]]
[[245 187 287 207]]
[[546 182 582 214]]
[[264 190 326 216]]
[[452 192 482 214]]
[[483 199 561 233]]
[[278 191 330 213]]
[[ 61 167  99 199]]
[[171 183 209 207]]
[[229 191 257 213]]
[[351 190 419 216]]
[[182 184 228 212]]
[[196 169 254 197]]
[[347 179 409 207]]
[[193 196 265 224]]
[[371 193 411 213]]
[[259 188 301 208]]
[[421 191 481 217]]
[[396 196 436 218]]
[[203 169 263 197]]
[[251 190 313 216]]
[[422 190 458 214]]
[[294 190 360 216]]
[[318 201 378 227]]
[[447 189 499 215]]
[[265 181 315 205]]
[[389 196 431 218]]
[[441 187 495 213]]
[[193 179 241 203]]
[[189 176 241 202]]
[[352 194 394 216]]
[[463 188 503 214]]
[[352 203 392 223]]
[[189 194 225 220]]
[[166 186 198 208]]
[[106 187 146 215]]
[[211 200 255 222]]
[[230 191 264 213]]
[[296 205 344 227]]
[[237 190 273 210]]
[[163 185 185 207]]
[[331 191 385 215]]
[[241 179 295 203]]
[[404 190 448 214]]
[[115 190 169 218]]
[[307 182 357 206]]
[[385 184 451 210]]
[[245 199 309 225]]
[[351 187 427 219]]
[[172 181 202 205]]
[[454 201 484 223]]
[[364 185 412 209]]
[[438 199 496 225]]
[[156 194 224 222]]
[[232 182 282 204]]
[[220 200 268 222]]
[[375 181 437 209]]
[[476 202 528 228]]
[[396 203 422 221]]
[[454 190 496 218]]
[[ 99 195 165 229]]
[[172 178 216 202]]
[[343 184 391 208]]
[[152 194 240 228]]
[[448 193 484 217]]
[[427 187 503 219]]
[[385 192 437 216]]
[[334 184 382 208]]
[[425 191 483 217]]
[[240 190 276 210]]
[[228 187 256 207]]
[[270 191 324 215]]
[[345 206 435 240]]
[[163 186 187 208]]
[[188 177 244 203]]
[[180 176 228 202]]
[[423 191 459 215]]
[[345 206 395 228]]
[[313 195 367 217]]
[[257 193 309 215]]
[[301 202 363 228]]
[[229 185 279 207]]
[[209 180 271 208]]
[[178 185 236 213]]
[[199 195 221 213]]
[[345 189 395 211]]
[[284 193 338 215]]
[[128 164 200 196]]
[[440 200 526 234]]
[[264 182 338 214]]
[[337 206 425 240]]
[[348 207 438 241]]
[[178 183 210 211]]
[[473 187 507 213]]
[[424 202 486 228]]
[[225 187 251 207]]
[[409 203 473 229]]
[[348 187 398 209]]
[[250 183 300 205]]
[[247 195 287 213]]
[[255 182 303 206]]
[[240 195 280 213]]
[[407 198 469 224]]
[[334 202 376 222]]
[[424 190 458 214]]
[[199 195 223 213]]
[[404 203 432 221]]
[[213 166 287 198]]
[[332 201 374 221]]
[[258 173 318 201]]
[[355 180 417 208]]
[[312 213 394 247]]
[[ 79 170 131 202]]
[[428 184 478 212]]
[[337 198 377 216]]
[[255 204 305 226]]
[[322 201 364 221]]
[[245 190 307 216]]
[[335 193 389 217]]
[[ 68 167 112 199]]
[[354 191 422 217]]
[[496 207 560 241]]
[[335 188 385 210]]
[[255 189 305 211]]
[[202 196 228 214]]
[[295 182 347 206]]
[[134 187 204 215]]
[[360 189 410 213]]
[[195 184 239 206]]
[[501 207 559 241]]
[[303 197 355 219]]
[[348 195 398 217]]
[[376 211 468 245]]
[[312 193 354 215]]
[[424 198 448 218]]
[[293 190 345 212]]
[[427 191 453 215]]
[[162 185 186 207]]
[[417 191 459 213]]
[[107 187 145 215]]
[[126 205 206 239]]
[[251 199 301 221]]
[[201 185 251 209]]
[[455 185 493 213]]
[[303 182 363 210]]
[[ 92 172 152 204]]
[[287 200 333 222]]
[[146 187 212 215]]
[[413 184 467 212]]
[[306 188 356 210]]
[[438 188 494 214]]
[[231 170 293 198]]
[[254 193 304 215]]
[[455 184 491 212]]
[[279 182 329 206]]
[[107 188 153 216]]
[[205 176 263 202]]
[[230 191 264 213]]
[[209 194 239 214]]
[[364 193 414 215]]
[[182 179 238 207]]
[[139 194 227 228]]
[[416 192 454 216]]
[[171 174 219 202]]
[[281 191 323 213]]
[[408 192 456 216]]
[[212 195 248 213]]
[[389 206 437 228]]
[[294 190 336 210]]
[[193 196 237 222]]
[[406 191 450 213]]
[[334 190 402 216]]
[[369 187 421 211]]
[[392 193 438 215]]
[[533 185 583 217]]
[[330 187 378 211]]
[[101 195 171 229]]
[[295 192 337 214]]
[[190 169 246 197]]
[[360 201 400 221]]
[[363 167 437 199]]
[[104 195 178 229]]
[[275 199 315 219]]
[[428 189 484 217]]
[[380 202 416 220]]
[[338 206 428 240]]
[[260 196 346 230]]
[[ 61 168  97 200]]
[[440 199 498 225]]
[[435 190 489 216]]
[[173 175 221 203]]
[[233 185 283 207]]
[[462 189 500 215]]
[[169 183 207 207]]
[[242 178 296 202]]
[[208 187 260 211]]
[[389 190 461 224]]
[[ 99 164 167 196]]
[[144 179 218 211]]
[[374 192 428 216]]
[[243 199 283 219]]
[[391 211 481 245]]
[[358 206 408 228]]
[[207 166 281 198]]
[[178 178 224 202]]
[[315 206 361 228]]
[[185 176 239 202]]
[[317 200 357 220]]
[[171 180 201 204]]
[[387 185 455 213]]
[[419 198 449 218]]
[[313 205 361 227]]
[[349 194 391 216]]
[[392 196 432 218]]
[[337 206 385 228]]
[[184 184 226 206]]
[[399 203 463 229]]
[[ 86 172 148 204]]
[[447 192 475 216]]
[[397 182 455 210]]
[[342 201 402 227]]
[[206 200 244 222]]
[[420 198 480 224]]
[[358 185 408 209]]
[[397 185 461 211]]
[[224 189 278 213]]
[[269 183 331 211]]
[[199 185 247 209]]
[[472 199 552 233]]
[[440 185 486 213]]
[[364 202 412 224]]
[[418 187 480 213]]
[[247 185 297 207]]
[[407 198 445 220]]
[[230 181 300 209]]
[[453 200 483 222]]
[[143 165 217 197]]
[[360 203 398 223]]
[[442 187 490 215]]
[[198 184 244 206]]
[[211 198 269 224]]
[[266 182 328 210]]
[[173 186 235 214]]
[[422 198 446 218]]
[[223 181 287 209]]
[[377 203 441 229]]
[[ 63 168  97 200]]
[[102 196 152 230]]
[[244 181 292 205]]
[[457 201 481 223]]
[[312 192 366 216]]
[[311 189 379 215]]
[[164 188 196 210]]
[[267 173 327 201]]
[[257 183 305 207]]
[[202 192 252 214]]
[[319 179 379 207]]
[[211 198 281 226]]
[[369 206 419 228]]
[[211 170 273 198]]
[[305 181 375 209]]
[[ 72 171 130 203]]
[[489 193 521 221]]
[[401 186 477 218]]
[[200 191 256 217]]
[[203 197 275 225]]
[[486 200 528 226]]
[[470 199 520 225]]
[[333 190 375 210]]
[[190 179 238 203]]
[[281 184 331 206]]
[[395 186 471 218]]
[[390 204 434 226]]
[[375 202 411 222]]
[[386 202 418 222]]
[[271 191 325 215]]
[[216 180 252 204]]
[[383 190 455 224]]
[[165 186 197 208]]
[[314 190 354 210]]
[[146 194 234 228]]
[[411 202 475 228]]
[[328 182 398 210]]
[[387 211 477 245]]
[[256 181 304 205]]
[[389 186 455 212]]
[[377 194 429 216]]
[[230 188 264 208]]
[[189 193 231 219]]
[[109 164 181 196]]
[[372 181 434 209]]
[[312 191 370 217]]
[[239 190 283 212]]
[[437 200 497 226]]
[[483 195 519 223]]
[[431 185 485 213]]
[[464 187 536 219]]
[[453 201 481 223]]
[[274 181 342 209]]
[[360 203 422 229]]
[[168 180 232 208]]
[[263 189 315 211]]
[[299 190 351 212]]
[[234 180 280 204]]
[[216 179 256 203]]
[[369 180 431 208]]
[[350 207 440 241]]
[[ 72 169 118 201]]
[[398 196 448 218]]
[[415 206 447 228]]
[[345 197 397 219]]
[[172 185 210 207]]
[[205 187 255 211]]
[[269 193 321 215]]
[[278 173 336 201]]
[[441 190 493 216]]
[[448 184 490 212]]
[[455 192 481 214]]
[[409 195 459 217]]
[[444 199 482 221]]
[[319 182 383 208]]
[[348 184 396 208]]
[[296 201 336 221]]
[[214 194 248 212]]
[[435 189 473 213]]
[[308 191 360 213]]
[[352 183 420 209]]
[[380 187 428 211]]
[[184 191 232 213]]
[[318 183 364 207]]
[[252 198 324 226]]
[[357 206 407 228]]
[[340 189 390 211]]
[[411 204 433 222]]
[[249 181 297 205]]
[[424 192 464 214]]
[[284 184 344 212]]
[[345 191 387 211]]
[[301 201 363 227]]
[[349 197 401 219]]
[[357 203 397 223]]
[[520 185 578 217]]
[[218 208 308 242]]
[[438 188 496 216]]
[[316 207 398 241]]
[[175 195 263 229]]
[[297 200 341 222]]
[[459 197 509 225]]
[[395 187 457 215]]
[[361 198 415 220]]
[[379 192 433 216]]
[[412 200 460 222]]
[[271 167 343 199]]
[[213 201 251 223]]
[[226 182 290 210]]
[[179 186 223 210]]
[[225 199 287 225]]
[[414 204 434 222]]
[[353 198 407 220]]
[[354 201 416 227]]
[[421 191 459 215]]
[[358 189 408 213]]
[[259 179 313 203]]
[[339 184 387 208]]
[[350 190 400 212]]
[[360 201 422 227]]
[[173 182 207 206]]
[[417 207 449 229]]
[[188 193 232 219]]
[[400 204 424 222]]
[[397 197 459 223]]
[[362 194 404 216]]
[[259 190 321 216]]
[[252 181 322 209]]
[[195 197 245 223]]
[[347 201 397 223]]
[[328 207 414 241]]
[[219 181 289 209]]
[[351 192 393 212]]
[[231 187 267 207]]
[[ 59 167 105 199]]
[[172 183 226 209]]
[[187 191 235 213]]
[[420 192 462 214]]
[[360 193 410 215]]
[[266 181 334 209]]
[[449 186 491 214]]
[[380 199 448 227]]
[[161 172 197 200]]
[[361 191 429 217]]
[[141 187 207 215]]
[[284 201 348 227]]
[[236 190 284 212]]
[[371 203 407 223]]
[[444 185 488 213]]
[[263 190 305 212]]
[[431 191 459 215]]
[[399 203 489 237]]
[[175 183 213 207]]
[[332 214 420 248]]
[[268 205 318 227]]
[[ 72 168 108 200]]
[[195 206 285 240]]
[[349 185 399 209]]
[[ 88 173 152 205]]
[[420 183 472 211]]
[[367 201 405 221]]
[[291 186 341 208]]
[[371 191 421 213]]
[[427 213 515 247]]
[[195 183 239 205]]
[[380 199 432 221]]
[[270 190 312 212]]
[[360 189 410 213]]
[[198 176 256 202]]
[[318 185 394 217]]
[[415 169 487 201]]
[[189 194 225 220]]
[[285 183 357 215]]
[[186 177 234 201]]
[[343 201 383 221]]
[[132 194 220 228]]
[[202 195 232 213]]
[[397 190 443 214]]
[[268 207 358 241]]
[[406 188 448 212]]
[[157 179 193 203]]
[[386 199 454 227]]
[[333 183 403 211]]
[[454 178 542 214]]
[[229 191 255 213]]
[[456 185 488 213]]
[[406 186 466 214]]
[[413 188 473 214]]
[[291 191 343 213]]
[[381 194 427 216]]
[[252 185 302 207]]
[[464 186 536 218]]
[[298 183 346 207]]
[[386 196 428 218]]
[[334 206 422 240]]
[[216 198 288 226]]
[[267 193 321 215]]
[[208 191 266 217]]
[[203 178 253 202]]
[[193 196 281 230]]
[[536 182 574 214]]
[[174 184 214 208]]
[[189 180 255 208]]
[[307 193 349 215]]
[[462 189 502 215]]
[[397 197 437 219]]
[[360 184 410 208]]
[[504 207 556 241]]
[[334 182 398 208]]
[[ 99 195 161 229]]
[[436 187 510 219]]
[[287 180 353 206]]
[[300 194 354 216]]
[[188 166 262 198]]
[[ 86 171 144 203]]
[[391 202 421 222]]
[[238 198 278 218]]
[[310 184 384 216]]
[[301 213 387 247]]
[[255 199 297 219]]
[[401 206 445 228]]
[[351 193 403 215]]
[[378 195 440 221]]
[[284 194 338 216]]
[[244 177 310 203]]
[[175 170 223 198]]
[[289 191 349 217]]
[[283 213 371 247]]
[[264 204 314 226]]
[[240 187 308 213]]
[[323 192 381 218]]
[[227 196 263 216]]
[[287 190 339 212]]
[[414 197 448 219]]
[[439 185 485 213]]
[[215 184 263 206]]
[[289 200 329 220]]
[[382 193 422 213]]
[[363 192 417 216]]
[[401 200 451 222]]
[[309 200 349 220]]
[[303 167 375 199]]
[[227 200 275 222]]
[[333 197 385 219]]
[[275 190 337 216]]
[[284 185 334 209]]
[[278 200 342 226]]
[[191 181 253 209]]
[[366 191 416 213]]
[[437 193 475 217]]
[[302 205 352 227]]
[[280 189 332 211]]
[[328 201 378 223]]
[[403 203 493 237]]
[[172 180 200 204]]
[[300 207 386 241]]
[[365 186 429 214]]
[[518 179 572 211]]
[[324 187 372 211]]
[[252 202 302 224]]
[[162 186 232 214]]
[[212 184 258 206]]
[[181 181 239 209]]
[[418 198 446 218]]
[[224 195 260 215]]
[[318 193 360 215]]
[[245 187 285 207]]
[[423 199 483 227]]
[[160 186 224 214]]
[[478 202 528 228]]
[[182 206 272 240]]
[[251 172 313 200]]
[[443 190 475 214]]
[[384 202 416 222]]
[[285 167 355 199]]
[[330 206 378 228]]
[[125 177 197 209]]
[[176 182 224 210]]
[[333 194 373 216]]
[[242 181 288 205]]
[[176 169 232 197]]
[[381 190 447 216]]
[[244 182 308 210]]
[[426 197 472 219]]
[[233 190 295 216]]
[[341 202 381 222]]
[[496 206 554 240]]
[[305 213 389 247]]
[[465 199 517 225]]
[[158 179 192 203]]
[[422 197 506 231]]
[[231 179 301 207]]
[[438 194 472 216]]
[[378 184 444 210]]
[[392 204 436 226]]
[[462 190 514 218]]
[[233 190 269 212]]
[[328 192 386 218]]
[[229 180 305 212]]
[[172 181 200 205]]
[[313 201 373 227]]
[[207 200 247 222]]
[[259 199 301 219]]
[[307 178 365 206]]
[[395 202 427 220]]
[[239 197 279 217]]
[[136 194 224 228]]
[[336 201 394 227]]
[[437 193 479 217]]
[[505 177 563 209]]
[[318 192 370 214]]
[[ 75 164 141 196]]
[[119 194 203 228]]
[[338 182 408 210]]
[[408 202 472 228]]
[[384 193 424 213]]
[[205 207 295 241]]
[[265 166 337 198]]
[[266 199 308 219]]
[[535 182 571 214]]
[[177 177 229 205]]
[[444 193 482 217]]
[[363 201 403 221]]
[[168 181 214 207]]
[[325 191 367 211]]
[[449 187 523 219]]
[[161 173 203 201]]
[[359 193 401 213]]
[[ 88 171 148 203]]
[[170 174 216 202]]
[[321 183 383 211]]
[[406 183 462 211]]
[[414 187 478 213]]
[[115 203 189 237]]
[[386 206 434 228]]
[[187 184 231 208]]
[[228 188 250 208]]
[[207 196 295 230]]
[[505 207 555 241]]
[[181 183 241 209]]
[[336 178 398 206]]
[[359 206 409 228]]
[[203 194 233 214]]
[[410 190 452 214]]
[[500 186 566 218]]
[[400 183 458 211]]
[[434 189 488 215]]
[[213 200 257 222]]
[[371 184 439 212]]
[[302 207 388 241]]
[[305 181 375 209]]
[[532 183 578 215]]
[[197 192 251 218]]
[[410 198 472 224]]
[[388 194 428 214]]
[[199 195 221 213]]
[[426 190 454 214]]
[[282 182 332 206]]
[[344 195 394 217]]
[[ 80 165 142 197]]
[[179 182 219 204]]
[[356 202 404 224]]
[[211 197 283 225]]
[[274 184 324 208]]
[[271 190 323 212]]
[[266 191 308 213]]
[[299 192 341 214]]
[[351 194 413 220]]
[[221 200 269 222]]
[[445 196 491 224]]
[[258 196 298 214]]
[[229 178 293 204]]
[[361 193 413 215]]
[[244 195 284 213]]
[[ 58 168 102 200]]
[[284 196 324 214]]
[[469 190 505 216]]
[[158 179 194 203]]
[[ 63 166 117 198]]
[[333 167 407 199]]
[[421 190 465 212]]
[[484 208 556 242]]
[[485 201 529 227]]
[[288 181 356 209]]
[[177 178 253 210]]
[[158 179 194 203]]
[[277 181 345 209]]
[[407 195 439 215]]
[[ 99 196 157 230]]
[[332 197 412 231]]
[[365 196 453 230]]
[[274 196 314 214]]
[[412 202 476 228]]
[[437 187 493 213]]
[[216 180 242 204]]
[[391 188 437 212]]
[[317 194 369 216]]
[[202 195 224 213]]
[[315 189 383 215]]
[[224 196 262 216]]
[[338 193 390 215]]
[[385 201 449 227]]
[[249 190 289 212]]
[[227 188 251 208]]
[[165 183 199 205]]
[[356 178 418 206]]
[[266 204 316 226]]
[[270 204 320 226]]
[[546 183 584 215]]
[[176 181 214 205]]
[[215 179 253 203]]
[[388 201 452 227]]
[[374 196 416 218]]
[[201 166 275 198]]
[[412 191 456 213]]
[[412 193 454 215]]
[[342 197 424 231]]
[[263 190 313 212]]
[[388 200 418 218]]
[[ 71 169 113 201]]
[[343 193 395 215]]
[[278 188 320 208]]
[[236 202 284 224]]
[[336 186 390 210]]
[[409 188 455 212]]
[[361 192 415 216]]
[[298 195 352 217]]
[[421 188 479 216]]
[[404 189 448 213]]
[[208 200 250 222]]
[[412 204 432 222]]
[[424 198 446 218]]
[[452 184 492 212]]
[[350 195 392 217]]
[[172 183 224 209]]
[[218 187 270 211]]
[[466 190 502 216]]
[[226 209 318 243]]
[[267 181 317 205]]
[[329 194 371 216]]
[[456 190 498 218]]
[[278 190 320 210]]
[[353 206 403 228]]
[[261 190 323 216]]
[[344 197 428 231]]
[[182 175 234 201]]
[[196 178 244 202]]
[[415 202 479 228]]
[[284 191 336 213]]
[[182 176 232 202]]
[[436 202 498 228]]
[[263 200 327 226]]
[[363 189 413 213]]
[[410 206 450 228]]
[[164 182 190 206]]
[[243 192 295 214]]
[[166 180 202 206]]
[[162 187 190 209]]
[[369 211 461 245]]
[[265 184 315 206]]
[[454 186 528 218]]
[[367 186 443 218]]
[[203 194 235 214]]
[[451 200 529 234]]
[[357 188 407 210]]
[[418 190 456 214]]
[[179 176 229 202]]
[[251 181 321 209]]
[[308 197 360 219]]
[[404 204 432 222]]
[[204 176 264 202]]
[[315 200 387 228]]
[[238 212 328 246]]
[[295 191 355 217]]
[[188 193 230 219]]
[[326 201 376 223]]
[[340 191 382 211]]
[[305 205 353 227]]
[[529 183 577 215]]
[[421 199 451 219]]
[[172 182 204 206]]
[[199 192 255 218]]
[[207 177 267 203]]
[[273 199 321 221]]
[[295 204 345 226]]
[[392 182 450 210]]
[[222 208 314 242]]
[[431 189 485 217]]
[[171 182 221 208]]
[[175 186 247 214]]
[[211 177 271 203]]
[[394 189 470 221]]
[[344 179 406 207]]
[[309 213 393 247]]
[[453 201 479 223]]
[[377 196 419 218]]
[[487 174 551 206]]
[[364 193 406 213]]
[[413 191 457 213]]
[[454 185 490 213]]
[[416 191 456 215]]
[[193 169 249 197]]
[[235 190 297 216]]
[[425 184 475 212]]
[[185 182 225 204]]
[[ 60 167 102 199]]
[[175 181 213 205]]
[[165 183 197 207]]
[[327 184 379 208]]
[[366 203 428 229]]
[[340 191 382 211]]
[[265 196 305 214]]
[[232 188 268 208]]
[[319 196 371 218]]
[[371 186 419 210]]
[[425 184 475 212]]
[[407 204 427 222]]
[[385 187 431 211]]
[[256 203 306 225]]
[[365 198 419 220]]
[[293 207 381 241]]
[[222 182 298 214]]
[[298 205 346 227]]
[[191 195 231 221]]
[[353 178 415 206]]
[[211 200 239 222]]
[[460 186 532 218]]
[[334 191 376 211]]
[[352 192 406 216]]
[[417 200 463 222]]
[[240 181 310 209]]
[[282 194 332 216]]
[[242 203 290 225]]
[[254 190 304 212]]
[[546 182 580 214]]
[[197 179 273 211]]
[[164 183 196 205]]
[[276 182 328 206]]
[[451 200 481 222]]
[[356 185 406 209]]
[[262 204 312 226]]
[[283 191 345 217]]
[[401 196 451 218]]
[[410 196 442 216]]
[[355 198 393 216]]
[[399 182 457 210]]
[[178 182 232 210]]
[[187 183 229 205]]
[[330 182 394 208]]
[[171 178 203 204]]
[[352 187 402 209]]
[[382 184 448 210]]
[[406 192 448 216]]
[[ 77 164 143 196]]
[[401 200 451 222]]
[[309 201 349 221]]
[[446 185 488 213]]
[[168 174 214 202]]
[[434 193 472 215]]
[[234 199 284 221]]
[[229 193 281 215]]
[[380 196 422 218]]
[[321 187 369 211]]
[[ 98 196 154 230]]
[[438 170 508 202]]
[[205 191 263 217]]
[[411 192 451 216]]
[[197 177 247 201]]
[[369 167 443 199]]
[[414 200 476 228]]
[[402 203 432 223]]
[[210 193 262 215]]
[[402 189 446 213]]
[[262 181 316 205]]
[[396 204 438 226]]
[[394 187 444 211]]
[[483 201 529 227]]
[[453 201 479 223]]
[[273 190 315 212]]
[[159 179 199 203]]
[[435 198 477 220]]
[[153 186 223 214]]
[[227 188 251 208]]
[[315 191 367 213]]
[[154 166 228 198]]
[[206 180 268 208]]
[[325 177 387 205]]
[[339 185 393 209]]
[[325 185 401 217]]
[[466 202 520 228]]
[[404 204 424 222]]
[[399 186 459 214]]
[[449 200 483 222]]
[[244 203 294 225]]
[[334 203 392 229]]
[[434 185 482 213]]
[[314 183 362 207]]
[[272 182 322 206]]
[[341 193 393 215]]
[[185 169 237 197]]
[[316 183 362 207]]
[[196 198 246 224]]
[[247 187 289 207]]
[[449 199 535 233]]
[[429 191 459 215]]
[[487 205 551 239]]
[[181 184 223 208]]
[[432 191 458 215]]
[[143 183 201 211]]
[[238 178 292 202]]
[[251 187 293 207]]
[[294 195 348 217]]
[[117 194 201 228]]
[[179 178 233 206]]
[[240 190 294 214]]
[[349 193 401 215]]
[[400 185 462 213]]
[[263 199 305 219]]
[[119 204 195 238]]
[[219 178 271 202]]
[[275 179 343 205]]
[[336 206 384 228]]
[[405 192 453 216]]
[[479 201 529 227]]
[[547 183 587 215]]
[[187 181 247 209]]
[[359 191 427 217]]
[[326 206 374 228]]
[[359 183 427 211]]
[[198 195 218 213]]
[[175 182 221 210]]
[[388 204 432 226]]
[[199 196 223 214]]
[[445 184 489 212]]
[[276 190 330 214]]
[[238 166 312 198]]
[[251 200 315 226]]
[[424 190 458 214]]
[[435 195 471 217]]
[[416 202 506 236]]
[[197 186 245 210]]
[[412 191 454 215]]
[[351 185 401 209]]
[[225 187 253 207]]
[[368 190 418 214]]
[[213 188 265 212]]
[[299 193 351 217]]
[[203 198 275 226]]
[[351 206 401 228]]
[[270 205 320 227]]
[[209 200 251 222]]
[[320 201 368 223]]
[[452 201 478 223]]
[[340 201 390 223]]
[[378 186 426 210]]
[[272 190 334 216]]
[[286 190 338 214]]
[[331 179 393 207]]
[[228 191 258 213]]
[[186 184 228 212]]
[[345 197 429 231]]
[[456 194 494 222]]
[[189 184 227 212]]
[[199 179 259 207]]
[[276 191 318 213]]
[[ 70 166 124 198]]
[[444 199 524 233]]
[[445 199 501 225]]
[[230 182 294 210]]
[[221 180 261 204]]
[[378 193 418 213]]
[[402 188 450 212]]
[[338 191 380 211]]
[[468 199 550 233]]
[[354 207 444 241]]
[[422 198 446 218]]
[[221 189 273 213]]
[[377 201 441 227]]
[[116 203 192 237]]
[[161 172 197 200]]
[[260 178 328 204]]
[[262 193 314 215]]
[[344 191 398 215]]
[[236 183 286 205]]
[[352 184 402 208]]
[[402 191 448 213]]
[[301 179 367 205]]
[[241 180 289 204]]
[[397 192 449 216]]
[[ 61 166 113 198]]
[[413 206 447 228]]
[[300 181 370 209]]
[[224 212 314 246]]
[[ 81 172 141 204]]
[[271 181 341 209]]
[[106 174 172 206]]
[[297 187 347 209]]
[[446 192 476 216]]
[[328 198 368 216]]
[[285 182 333 206]]
[[256 185 306 207]]
[[373 186 421 210]]
[[471 202 525 228]]
[[412 188 458 212]]
[[427 200 469 222]]
[[134 178 206 210]]
[[305 186 353 210]]
[[344 186 420 218]]
[[414 196 462 218]]
[[310 183 356 207]]
[[300 186 348 210]]
[[199 195 223 213]]
[[333 192 393 218]]
[[249 199 299 221]]
[[101 165 173 197]]
[[206 200 244 222]]
[[133 192 195 220]]
[[443 187 517 219]]
[[216 179 254 203]]
[[343 193 395 215]]
[[364 194 416 216]]
[[217 181 279 209]]
[[259 190 299 212]]
[[349 201 389 221]]
[[ 69 165 129 197]]
[[380 186 442 214]]
[[422 187 484 215]]
[[339 203 397 229]]
[[305 197 387 231]]
[[253 190 293 212]]
[[212 197 284 225]]
[[376 205 468 239]]
[[451 200 479 222]]
[[337 201 387 223]]
[[381 196 443 222]]
[[390 204 480 238]]
[[424 190 456 214]]
[[241 202 289 224]]
[[206 194 238 214]]
[[322 214 406 248]]
[[109 195 189 229]]
[[269 189 321 211]]
[[172 181 200 205]]
[[214 200 260 222]]
[[238 190 280 212]]
[[391 196 453 222]]
[[536 182 570 214]]
[[263 173 323 201]]
[[410 204 434 222]]
[[386 196 428 218]]
[[257 188 299 208]]
[[286 192 328 214]]
[[478 196 518 224]]
[[448 200 482 222]]
[[450 201 478 223]]
[[408 204 434 222]]
[[428 187 486 213]]
[[290 190 342 212]]
[[442 191 478 213]]
[[138 205 222 239]]
[[422 187 498 219]]
[[373 194 423 216]]
[[459 199 513 225]]
[[276 184 326 206]]
[[420 202 482 228]]
[[483 204 549 238]]
[[307 182 373 208]]
[[187 179 233 203]]
[[404 192 454 216]]
[[110 202 178 236]]
[[425 190 481 216]]
[[332 201 382 223]]
[[395 202 427 222]]
[[336 179 398 207]]
[[335 196 387 218]]
[[312 189 360 211]]
[[229 191 259 213]]
[[245 166 319 198]]
[[271 173 331 201]]
[[449 199 505 225]]
[[218 190 270 214]]
[[319 196 371 218]]
[[272 194 322 216]]
[[268 190 310 212]]
[[301 183 349 207]]
[[213 185 261 207]]
[[466 199 548 233]]
[[383 181 443 209]]
[[373 188 449 220]]
[[201 178 251 202]]
[[ 98 195 160 229]]
[[209 169 269 197]]
[[319 207 401 241]]
[[330 214 416 248]]
[[418 198 448 218]]
[[204 194 236 214]]
[[163 171 197 199]]
[[226 178 290 204]]
[[375 201 413 221]]
[[238 196 324 230]]
[[372 202 410 220]]
[[424 199 452 219]]
[[345 185 399 209]]
[[503 207 555 241]]
[[524 179 574 211]]
[[175 184 231 210]]
[[277 205 327 227]]
[[195 166 269 198]]
[[382 195 434 217]]
[[342 183 408 209]]
[[439 194 475 218]]
[[355 190 427 224]]
[[425 191 459 215]]
[[240 182 304 210]]
[[500 176 560 208]]
[[382 197 470 231]]
[[271 193 323 215]]
[[290 192 332 214]]
[[314 194 356 216]]
[[ 63 170 115 202]]
[[389 187 451 215]]
[[300 204 350 226]]
[[240 178 306 204]]
[[275 189 327 211]]
[[171 185 207 207]]
[[180 185 234 213]]
[[447 187 489 215]]
[[332 185 408 217]]
[[433 185 481 213]]
[[323 193 363 215]]
[[464 210 544 244]]
[[342 184 390 208]]
[[428 201 490 227]]
[[162 173 202 201]]
[[403 195 439 215]]
[[193 176 247 202]]
[[363 198 399 216]]
[[393 187 439 211]]
[[377 192 431 216]]
[[217 178 279 204]]
[[427 199 449 219]]
[[241 180 311 208]]
[[313 189 353 209]]
[[201 191 251 213]]
[[227 197 265 217]]
[[123 191 181 219]]
[[291 205 341 227]]
[[221 185 269 207]]
[[433 170 503 202]]
[[458 201 534 235]]
[[ 85 164 153 196]]
[[328 201 370 221]]
[[453 188 501 214]]
[[451 192 479 214]]
[[395 211 485 245]]
[[196 198 248 224]]
[[301 187 351 209]]
[[235 187 303 213]]
[[206 197 278 225]]
[[405 204 433 222]]
[[356 198 410 220]]
[[158 180 196 204]]
[[230 191 262 213]]
[[248 189 286 211]]
[[262 204 312 226]]
[[447 200 479 222]]
[[411 204 433 222]]
[[427 199 487 227]]
[[171 183 211 211]]
[[380 190 428 212]]
[[321 207 405 241]]
[[229 187 255 207]]
[[382 190 430 214]]
[[339 201 379 221]]
[[350 201 412 227]]
[[461 211 543 245]]
[[428 187 488 215]]
[[305 202 367 228]]
[[402 206 446 228]]
[[307 190 375 216]]
[[290 192 342 216]]
[[340 183 406 209]]
[[260 193 312 215]]
[[320 200 362 220]]
[[373 206 423 228]]
[[234 190 272 212]]
[[161 185 185 207]]
[[253 195 293 213]]
[[ 91 165 159 197]]
[[450 171 518 203]]
[[280 181 348 209]]
[[243 212 333 246]]
[[286 192 338 216]]
[[223 187 277 211]]
[[398 200 448 222]]
[[ 70 171 126 203]]
[[354 193 406 215]]
[[138 183 192 211]]
[[391 187 437 211]]
[[242 199 306 225]]
[[305 185 379 217]]
[[209 207 299 241]]
[[334 197 414 231]]
[[399 191 445 213]]
[[263 183 313 207]]
[[230 179 282 203]]
[[418 183 470 211]]
[[444 194 478 216]]
[[285 200 325 220]]
[[166 172 206 200]]
[[350 185 414 213]]
[[100 195 170 229]]
[[392 193 430 213]]
[[455 185 489 213]]
[[214 177 274 203]]
[[471 199 521 225]]
[[357 183 425 209]]
[[368 193 410 213]]
[[440 198 478 220]]
[[182 169 234 197]]
[[344 183 414 211]]
[[275 193 325 215]]
[[292 201 354 227]]
[[170 180 202 204]]
[[313 201 361 223]]
[[142 194 230 228]]
[[166 188 202 210]]
[[176 178 220 204]]
[[290 204 340 226]]
[[299 176 357 204]]
[[271 195 311 213]]
[[190 184 224 212]]
[[283 205 333 227]]
[[454 192 482 214]]
[[374 190 440 216]]
[[438 202 500 228]]
[[349 183 419 211]]
[[294 185 342 209]]
[[275 200 339 226]]
[[451 201 479 223]]
[[222 181 292 209]]
[[188 184 228 212]]
[[103 174 167 206]]
[[401 187 445 211]]
[[122 165 196 197]]
[[367 193 409 213]]
[[401 203 431 223]]
[[447 185 489 213]]
[[120 183 164 211]]
[[193 177 249 203]]
[[214 179 244 203]]
[[369 196 457 230]]
[[201 195 227 213]]
[[363 206 413 228]]
[[171 180 213 206]]
[[174 170 222 198]]
[[104 195 180 229]]
[[385 190 451 216]]
[[244 181 314 209]]
[[258 181 312 205]]
[[371 185 439 211]]
[[456 171 524 203]]
[[172 184 212 208]]
[[346 197 400 219]]
[[217 179 257 203]]
[[365 192 407 212]]
[[223 186 291 212]]
[[253 198 293 218]]
[[287 191 339 213]]
[[255 188 323 214]]
[[418 188 462 212]]
[[163 187 193 209]]
[[389 193 427 213]]
[[392 191 438 215]]
[[374 191 446 225]]
[[220 191 280 217]]
[[225 180 267 204]]
[[211 178 261 202]]
[[177 183 215 207]]
[[330 197 410 231]]
[[ 97 164 167 196]]
[[ 67 166 125 198]]
[[448 193 474 217]]
[[229 187 251 207]]
[[431 189 485 215]]
[[ 73 169 121 201]]
[[229 187 265 207]]
[[215 180 247 204]]
[[241 199 291 221]]
[[231 189 261 209]]
[[348 193 400 215]]
[[226 202 272 224]]
[[312 201 352 221]]
[[197 181 261 209]]
[[291 195 345 217]]
[[354 194 416 220]]
[[183 190 227 212]]
[[442 194 474 216]]
[[328 191 370 211]]
[[403 206 447 228]]
[[399 190 445 214]]
[[456 188 502 214]]
[[453 186 491 214]]
[[385 199 417 217]]
[[375 199 443 227]]
[[176 166 250 198]]
[[296 181 362 207]]
[[380 186 428 210]]
[[450 186 492 214]]
[[209 198 267 224]]
[[230 191 258 213]]
[[469 187 505 213]]
[[313 197 365 219]]
[[309 201 357 223]]
[[422 192 466 216]]
[[409 169 481 201]]
[[229 191 291 217]]
[[434 212 522 246]]
[[310 188 378 214]]
[[168 189 206 211]]
[[351 212 441 246]]
[[101 164 171 196]]
[[443 188 501 216]]
[[223 196 309 230]]
[[247 197 287 217]]
[[373 186 421 210]]
[[259 181 321 209]]
[[302 186 350 210]]
[[398 195 434 215]]
[[237 202 285 224]]
[[161 179 191 203]]
[[161 187 191 209]]
[[321 213 403 247]]
[[241 189 295 213]]
[[447 194 475 218]]
[[264 189 304 211]]
[[425 185 481 213]]
[[167 189 205 211]]
[[415 183 469 211]]
[[343 203 383 223]]
[[454 197 506 225]]
[[302 190 370 216]]
[[254 200 318 226]]
[[410 185 468 213]]
[[376 195 428 217]]
[[455 189 499 215]]
[[423 198 449 218]]
[[213 179 247 203]]
[[409 205 447 227]]
[[329 196 381 218]]
[[113 185 143 213]]
[[266 173 324 201]]
[[291 182 343 206]]
[[247 179 313 205]]
[[503 186 567 218]]
[[294 191 346 213]]
[[329 197 381 219]]
[[267 190 329 216]]
[[445 199 479 221]]
[[495 206 553 240]]
[[242 187 282 207]]
[[361 178 423 206]]
[[442 188 496 214]]
[[236 199 300 225]]
[[219 194 255 212]]
[[401 183 459 211]]
[[487 208 557 242]]
[[176 179 240 207]]
[[398 187 442 211]]
[[362 206 412 228]]
[[168 170 210 198]]
[[418 207 448 229]]
[[137 192 201 220]]
[[464 202 520 228]]
[[403 187 445 211]]
[[247 181 317 209]]
[[387 192 439 216]]
[[114 164 186 196]]
[[383 181 443 209]]
[[308 188 358 210]]
[[430 194 468 216]]
[[498 207 560 241]]
[[377 185 445 213]]
[[412 205 448 227]]
[[349 198 403 220]]
[[238 192 282 214]]
[[247 190 309 216]]
[[454 186 490 214]]
[[211 200 245 222]]
[[339 194 381 216]]
[[350 185 404 209]]
[[235 180 305 208]]
[[459 188 503 214]]
[[387 191 435 213]]
[[325 193 379 217]]
[[416 187 480 215]]
[[194 181 260 209]]
[[403 189 447 213]]
[[225 187 255 207]]
[[416 197 444 217]]
[[135 205 217 239]]
[[375 203 421 225]]
[[360 186 436 218]]
[[286 185 336 207]]
[[212 189 264 213]]
[[258 203 308 225]]
[[222 199 282 225]]
[[322 194 374 216]]
[[444 195 476 219]]
[[178 177 222 203]]
[[426 191 454 215]]
[[429 192 471 214]]
[[235 190 275 212]]
[[397 206 443 228]]
[[467 189 505 215]]
[[364 201 426 227]]
[[301 193 343 215]]
[[449 200 479 222]]
[[292 192 334 214]]
[[205 191 261 217]]
[[400 189 444 213]]
[[407 203 497 237]]
[[365 206 415 228]]
[[387 197 475 231]]
[[350 192 392 212]]
[[320 181 384 207]]
[[424 190 456 214]]
[[129 178 201 210]]
[[362 185 410 209]]
[[302 181 372 209]]
[[411 212 501 246]]
[[313 206 359 228]]
[[190 184 236 208]]
[[373 198 427 220]]
[[309 192 361 216]]
[[458 201 484 223]]
[[386 196 448 222]]
[[227 171 289 199]]
[[452 188 500 214]]
[[165 171 197 199]]
[[340 191 394 215]]
[[233 187 271 207]]
[[171 178 205 204]]
[[333 194 385 216]]
[[247 190 297 212]]
[[422 184 474 212]]
[[173 183 215 211]]
[[491 200 529 226]]
[[349 206 399 228]]
[[298 213 384 247]]
[[453 195 493 223]]
[[290 189 356 215]]
[[162 188 190 210]]
[[431 198 489 224]]
[[383 199 435 221]]
[[214 193 266 215]]
[[451 191 499 217]]
[[323 201 373 223]]
[[415 190 455 214]]
[[425 191 459 215]]
[[220 187 274 211]]
[[448 189 500 215]]
[[338 184 386 208]]
[[429 200 473 222]]
[[395 204 437 226]]
[[218 194 252 212]]
[[406 203 432 221]]
[[309 183 357 207]]
[[425 198 447 218]]
[[377 190 425 214]]
[[211 200 241 222]]
[[410 196 442 216]]
[[458 211 540 245]]
[[224 181 294 209]]
[[339 197 421 231]]
[[231 202 279 224]]
[[328 190 378 212]]
[[481 201 529 227]]
[[458 189 510 217]]
[[270 199 312 219]]
[[357 184 407 208]]
[[219 184 267 206]]
[[195 176 253 202]]
[[245 196 285 214]]
[[412 188 452 212]]
[[419 196 465 218]]
[[213 181 275 209]]
[[328 190 368 210]]
[[266 188 332 214]]
[[307 182 369 210]]
[[409 197 445 219]]
[[198 195 224 213]]
[[164 183 192 207]]
[[243 190 291 212]]
[[ 68 167 108 199]]
[[381 193 421 213]]
[[204 198 276 226]]
[[ 62 168  98 200]]
[[211 197 283 225]]
[[311 198 351 216]]
[[344 189 394 211]]
[[159 178 191 202]]
[[152 193 218 221]]
[[312 201 372 227]]
[[397 183 455 211]]
[[289 197 329 215]]
[[134 183 186 211]]
[[380 205 472 239]]
[[291 182 343 206]]
[[213 179 245 203]]
[[211 180 279 208]]
[[366 192 420 216]]
[[322 206 368 228]]
[[473 190 503 216]]
[[363 203 401 223]]
[[308 201 370 227]]
[[168 189 204 211]]
[[225 202 269 224]]
[[348 197 434 231]]
[[122 194 206 228]]
[[213 201 253 223]]
[[245 190 299 214]]
[[476 209 552 243]]
[[402 197 464 223]]
[[204 191 256 213]]
[[354 185 418 213]]
[[400 191 444 215]]
[[110 202 180 236]]
[[526 180 576 212]]
[[242 185 292 207]]
[[474 190 504 216]]
[[144 205 230 239]]
[[431 202 493 228]]
[[513 178 569 210]]
[[106 164 176 196]]
[[ 76 166 138 198]]
[[457 187 499 213]]
[[242 196 282 214]]
[[252 166 324 198]]
[[136 187 204 215]]
[[163 186 191 208]]
[[165 166 239 198]]
[[328 206 374 228]]
[[471 187 507 213]]
[[188 178 236 202]]
[[261 188 303 208]]
[[451 200 483 222]]
[[452 186 492 214]]
[[438 191 492 217]]
[[161 186 185 208]]
[[167 205 255 239]]
[[ 77 170 127 202]]
[[207 200 243 222]]
[[341 185 395 209]]
[[106 188 150 216]]
[[325 183 373 207]]
[[451 184 491 212]]
[[211 194 243 212]]
[[281 190 333 214]]
[[274 200 314 220]]
[[361 191 433 225]]
[[241 190 285 212]]
[[378 193 420 213]]
[[205 196 233 214]]
[[434 197 474 219]]
[[163 183 193 205]]
[[309 206 355 228]]
[[394 199 446 221]]
[[226 187 256 207]]
[[390 201 418 219]]
[[530 185 582 217]]
[[171 178 203 204]]
[[201 195 221 213]]
[[431 184 481 212]]
[[166 182 200 206]]
[[437 189 489 217]]
[[268 179 336 205]]
[[202 181 278 213]]
[[208 197 280 225]]
[[240 181 286 205]]
[[200 195 230 213]]
[[252 189 302 211]]
[[404 200 454 222]]
[[170 183 206 211]]
[[323 201 381 227]]
[[427 191 459 215]]
[[167 180 211 206]]
[[251 181 299 205]]
[[210 179 286 211]]
[[254 181 302 205]]
[[422 188 464 212]]
[[431 187 489 213]]
[[321 192 373 214]]
[[433 193 473 217]]
[[297 191 357 217]]
[[373 184 441 210]]
[[212 194 244 214]]
[[281 184 341 212]]
[[338 201 388 223]]
[[298 190 338 210]]
[[459 191 499 219]]
[[348 193 410 219]]
[[ 61 167 101 199]]
[[212 201 248 223]]
[[173 183 229 209]]
[[344 206 392 228]]
[[163 181 191 205]]
[[394 202 458 228]]
[[255 183 305 205]]
[[388 193 434 215]]
[[261 190 303 212]]
[[228 188 250 208]]
[[325 184 387 212]]
[[301 182 351 206]]
[[371 201 435 227]]
[[171 189 211 211]]
[[442 193 476 215]]
[[237 172 299 200]]
[[250 202 300 224]]
[[291 189 333 209]]
[[243 190 287 212]]
[[172 183 208 205]]
[[178 181 218 205]]
[[236 196 276 216]]
[[318 201 366 223]]
[[298 184 370 216]]
[[280 191 342 217]]
[[238 192 290 214]]
[[290 207 378 241]]
[[259 181 307 205]]
[[346 186 422 218]]
[[403 212 493 246]]
[[474 203 544 237]]
[[212 200 256 222]]
[[168 170 212 198]]
[[510 185 570 217]]
[[298 181 368 209]]
[[342 201 392 223]]
[[347 206 397 228]]
[[253 178 319 204]]
[[445 200 481 222]]
[[371 185 419 209]]
[[353 202 401 224]]
[[352 197 438 231]]
[[190 179 238 203]]
[[413 197 447 219]]
[[188 183 252 209]]
[[426 199 452 219]]
[[211 200 243 222]]
[[388 195 440 217]]
[[386 168 460 200]]
[[448 194 474 218]]
[[345 188 395 212]]
[[295 183 355 211]]
[[374 203 420 225]]
[[201 195 223 213]]
[[165 171 203 199]]
[[339 197 419 231]]
[[234 198 304 226]]
[[402 197 440 219]]
[[221 171 283 199]]
[[230 188 256 208]]
[[226 179 278 203]]
[[161 187 187 209]]
[[177 177 225 203]]
[[480 201 528 227]]
[[130 194 216 228]]
[[287 189 329 209]]
[[220 201 262 223]]
[[355 189 405 213]]
[[212 201 248 223]]
[[427 191 485 217]]
[[471 209 549 243]]
[[255 181 325 209]]
[[276 191 328 215]]
[[422 184 474 212]]
[[436 195 472 217]]
[[368 206 418 228]]
[[260 193 310 215]]
[[123 164 195 196]]
[[459 202 515 228]]
[[188 184 218 212]]
[[434 187 492 213]]
[[481 199 559 233]]
[[310 182 380 210]]
[[336 193 396 219]]
[[501 186 565 218]]
[[324 196 376 218]]
[[236 180 282 204]]
[[251 190 291 212]]
[[434 185 486 213]]
[[190 194 226 220]]
[[262 193 312 215]]
[[341 197 423 231]]
[[436 185 484 213]]
[[324 201 366 221]]
[[474 186 544 218]]
[[391 191 439 213]]
[[230 191 266 213]]
[[371 184 437 212]]
[[242 192 290 214]]
[[204 196 230 214]]
[[289 205 339 227]]
[[411 190 453 214]]
[[182 184 222 206]]
[[522 185 576 217]]
[[506 207 554 241]]
[[192 192 244 218]]
[[277 190 339 216]]
[[206 198 276 226]]
[[290 181 356 207]]
[[229 195 267 213]]
[[260 190 310 212]]
[[474 191 520 219]]
[[218 198 290 226]]
[[246 199 286 219]]
[[345 212 435 246]]
[[ 70 169 114 201]]
[[311 183 373 211]]
[[451 189 501 215]]
[[229 182 277 204]]
[[243 182 319 214]]
[[124 183 170 211]]
[[281 185 331 209]]
[[122 204 200 238]]
[[231 191 293 217]]
[[240 187 280 207]]
[[311 194 353 216]]
[[ 59 169 105 201]]
[[190 178 266 210]]
[[173 183 207 207]]
[[450 188 500 214]]
[[302 200 342 220]]
[[398 204 440 226]]
[[179 196 249 224]]
[[411 191 453 215]]
[[371 206 421 228]]
[[319 187 367 211]]
[[531 181 571 213]]
[[374 180 436 208]]
[[368 195 410 217]]
[[228 198 298 226]]
[[206 195 238 213]]
[[249 189 297 211]]
[[309 196 361 218]]
[[217 180 255 204]]
[[305 193 347 215]]
[[ 89 165 155 197]]
[[358 198 412 220]]
[[211 187 263 211]]
[[244 187 312 213]]
[[376 193 416 213]]
[[138 165 212 197]]
[[191 191 239 213]]
[[402 203 432 221]]
[[318 206 364 228]]
[[330 188 380 210]]
[[452 202 510 228]]
[[441 199 521 233]]
[[462 201 536 235]]
[[207 186 257 210]]
[[297 181 367 209]]
[[445 198 501 226]]
[[328 202 370 222]]
[[102 195 174 229]]
[[192 195 232 221]]
[[261 183 311 207]]
[[377 197 465 231]]
[[114 185 146 213]]
[[342 197 396 219]]
[[454 179 542 215]]
[[241 190 289 212]]
[[242 192 288 214]]
[[267 189 309 209]]
[[278 207 368 241]]
[[462 192 498 220]]
[[374 190 424 214]]
[[206 169 266 197]]
[[ 84 171 140 203]]
[[425 199 449 219]]
[[373 193 413 213]]
[[410 200 458 222]]
[[476 190 506 216]]
[[361 201 399 219]]
[[170 186 242 214]]
[[172 181 202 205]]
[[475 199 523 225]]
[[279 185 329 209]]
[[324 206 372 228]]
[[457 201 483 223]]
[[227 187 259 207]]
[[446 194 478 216]]
[[244 203 292 225]]
[[421 198 449 218]]
[[423 198 447 218]]
[[243 187 285 207]]
[[184 184 228 212]]
[[152 187 218 215]]
[[215 180 251 204]]
[[ 81 164 149 196]]
[[212 181 280 209]]
[[463 188 505 214]]
[[415 207 449 229]]
[[447 189 493 217]]
[[261 190 315 214]]
[[222 202 266 224]]
[[389 196 451 222]]
[[346 203 386 223]]
[[299 182 347 206]]
[[403 205 443 227]]
[[441 202 501 228]]
[[338 201 398 227]]
[[346 183 414 211]]
[[365 198 401 216]]
[[393 186 459 212]]
[[113 185 141 213]]
[[328 196 380 218]]
[[332 184 378 208]]
[[300 197 340 215]]
[[380 188 456 220]]
[[228 187 262 207]]
[[401 192 447 214]]
[[412 197 446 219]]
[[343 193 405 219]]
[[238 189 292 213]]
[[427 199 449 219]]
[[217 195 251 215]]
[[182 180 226 204]]
[[372 190 422 214]]
[[517 185 575 217]]
[[328 193 370 215]]
[[335 183 399 209]]
[[389 196 431 218]]
[[309 175 371 203]]
[[288 182 336 206]]
[[295 182 343 206]]
[[161 184 185 206]]
[[165 186 195 208]]
[[395 202 421 220]]
[[189 193 229 219]]
[[184 189 230 211]]
[[412 206 450 228]]
[[364 179 426 207]]
[[262 194 312 216]]
[[181 176 231 202]]
[[334 188 384 212]]
[[446 199 532 233]]
[[275 191 327 213]]
[[146 177 220 209]]
[[424 190 456 214]]
[[376 180 438 208]]
[[447 193 477 215]]
[[217 195 255 213]]
[[488 205 552 239]]
[[386 190 458 224]]
[[506 185 568 217]]
[[362 194 412 216]]
[[190 177 246 203]]
[[108 186 144 214]]
[[ 61 169 113 201]]
[[422 202 484 228]]
[[263 179 331 205]]
[[433 188 471 212]]
[[389 185 455 211]]
[[224 179 268 203]]
[[194 170 254 198]]
[[259 173 321 201]]
[[286 185 336 209]]
[[208 200 248 222]]
[[176 185 218 209]]
[[129 192 191 220]]
[[384 190 450 216]]
[[491 175 553 207]]
[[182 170 240 198]]
[[354 202 402 224]]
[[365 187 417 211]]
[[230 188 258 208]]
[[523 185 579 217]]
[[182 182 222 204]]
[[329 200 401 228]]
[[424 198 448 218]]
[[115 194 197 228]]
[[365 206 415 228]]
[[291 185 341 209]]
[[217 212 309 246]]
[[391 194 429 214]]
[[230 199 278 221]]
[[291 167 361 199]]
[[199 198 251 224]]
[[416 191 460 213]]
[[274 182 324 206]]
[[331 197 411 231]]
[[385 194 431 216]]
[[264 182 338 214]]
[[481 196 519 224]]
[[335 206 383 228]]
[[432 201 494 227]]
[[298 184 372 216]]
[[292 200 338 222]]
[[369 202 407 220]]
[[397 200 463 228]]
[[189 194 227 220]]
[[181 184 221 208]]
[[ 80 170 134 202]]
[[187 206 277 240]]
[[237 199 287 221]]
[[126 177 196 209]]
[[333 192 383 214]]
[[348 201 398 223]]
[[104 198 158 232]]
[[453 185 493 213]]
[[188 192 236 218]]
[[415 213 505 247]]
[[249 181 297 205]]
[[384 193 422 213]]
[[464 188 506 214]]
[[194 192 244 214]]
[[141 177 213 209]]
[[473 199 521 225]]
[[242 180 318 212]]
[[ 71 166 127 198]]
[[433 187 483 215]]
[[142 193 206 221]]
[[442 212 528 246]]
[[503 207 557 241]]
[[378 206 428 228]]
[[173 189 215 211]]
[[327 183 397 211]]
[[422 190 456 214]]
[[270 179 338 205]]
[[283 174 341 202]]
[[427 199 451 219]]
[[369 179 431 207]]
[[192 170 250 198]]
[[120 204 198 238]]
[[408 196 442 216]]
[[464 192 498 220]]
[[333 190 401 216]]
[[294 199 334 219]]
[[253 203 303 225]]
[[408 197 494 231]]
[[442 184 488 212]]
[[420 202 484 228]]
[[388 199 440 221]]
[[187 191 231 213]]
[[274 181 344 209]]
[[426 197 470 219]]
[[362 206 454 240]]
[[178 170 234 198]]
[[454 188 508 216]]
[[201 176 261 202]]
[[259 193 309 215]]
[[232 199 294 225]]
[[233 202 281 224]]
[[175 190 215 212]]
[[362 189 412 213]]
[[269 189 311 209]]
[[219 180 259 204]]
[[267 194 317 216]]
[[371 198 425 220]]
[[296 186 346 208]]
[[328 192 380 214]]
[[392 203 456 229]]
[[298 201 360 227]]
[[343 202 403 228]]
[[219 166 293 198]]
[[275 173 335 201]]
[[396 202 428 220]]
[[381 186 457 218]]
[[345 201 395 223]]
[[437 198 519 232]]
[[266 191 320 215]]
[[196 175 252 201]]
[[106 199 168 233]]
[[387 199 439 221]]
[[421 190 455 214]]
[[173 179 219 203]]
[[229 193 281 215]]
[[229 196 267 216]]
[[436 200 524 234]]
[[165 170 197 198]]
[[474 188 506 214]]
[[392 185 458 211]]
[[244 189 290 211]]
[[ 58 168  98 200]]
[[395 203 485 237]]
[[395 192 445 216]]
[[317 181 387 209]]
[[342 213 432 247]]
[[420 197 446 217]]
[[281 205 331 227]]
[[434 200 474 222]]
[[376 202 412 220]]
[[230 188 254 208]]
[[272 184 322 208]]
[[382 186 434 210]]
[[ 99 173 163 205]]
[[209 200 241 222]]
[[488 193 522 221]]
[[169 183 205 205]]
[[181 178 227 202]]
[[306 195 360 217]]
[[377 191 449 225]]
[[399 204 423 222]]
[[464 199 516 225]]
[[453 185 491 213]]
[[104 199 164 233]]
[[367 185 415 209]]
[[454 201 482 223]]
[[209 181 285 213]]
[[408 206 450 228]]
[[466 188 506 214]]
[[343 206 433 240]]
[[232 191 266 213]]
[[288 204 338 226]]
[[380 201 444 227]]
[[415 194 457 216]]
[[214 180 246 204]]
[[267 180 321 204]]
[[535 184 583 216]]
[[195 191 245 213]]
[[385 196 427 218]]
[[375 168 449 200]]
[[229 180 275 204]]
[[391 192 443 216]]
[[297 194 349 216]]
[[192 184 256 210]]
[[395 197 483 231]]
[[363 198 417 220]]
[[286 199 326 219]]
[[407 204 433 222]]
[[165 170 199 198]]
[[394 197 434 219]]
[[192 191 242 213]]
[[265 199 315 221]]
[[329 201 387 227]]
[[215 196 303 230]]
[[466 199 518 225]]
[[344 193 398 217]]
[[199 183 243 205]]
[[397 192 443 214]]
[[355 184 421 210]]
[[208 200 242 222]]
[[355 206 405 228]]
[[415 197 445 217]]
[[330 192 390 218]]
[[446 187 498 213]]
[[411 196 443 216]]
[[281 192 333 216]]
[[230 188 266 208]]
[[483 173 547 205]]
[[368 191 440 225]]
[[385 199 437 221]]
[[484 186 552 218]]
[[370 203 416 225]]
[[224 191 284 217]]
[[190 195 228 221]]
[[202 184 268 210]]
[[350 191 418 217]]
[[253 179 319 205]]
[[384 203 448 229]]
[[437 186 485 214]]
[[454 178 542 214]]
[[393 201 421 219]]
[[298 196 350 218]]
[[199 184 265 210]]
[[298 167 368 199]]
[[164 182 192 206]]
[[227 186 295 212]]
[[ 61 169 111 201]]
[[230 202 276 224]]
[[236 180 284 204]]
[[495 186 561 218]]
[[412 196 462 218]]
[[432 193 472 215]]
[[373 195 435 221]]
[[231 180 277 204]]
[[313 207 395 241]]
[[311 206 357 228]]
[[346 197 430 231]]
[[260 195 300 213]]
[[ 99 196 153 230]]
[[443 202 503 228]]
[[392 190 440 214]]
[[541 182 585 214]]
[[265 184 315 208]]
[[262 185 312 207]]
[[252 203 302 225]]
[[236 180 312 212]]
[[395 190 441 214]]
[[212 191 264 213]]
[[285 183 357 215]]
[[209 184 255 206]]
[[253 190 315 216]]
[[447 184 491 212]]
[[191 176 245 202]]
[[434 193 470 215]]
[[415 187 491 219]]
[[452 192 484 216]]
[[303 201 349 223]]
[[468 189 506 215]]
[[250 178 304 202]]
[[304 191 356 213]]
[[359 195 401 217]]
[[443 199 481 221]]
[[371 179 433 207]]
[[356 200 426 228]]
[[484 201 530 227]]
[[367 193 419 215]]
[[402 204 424 222]]
[[206 200 244 222]]
[[169 182 219 208]]
[[250 179 316 205]]
[[204 196 232 214]]
[[ 88 164 158 196]]
[[379 203 425 225]]
[[475 202 527 228]]
[[453 192 483 214]]
[[332 185 384 209]]
[[398 194 434 214]]
[[489 194 519 222]]
[[353 192 395 212]]
[[398 192 448 216]]
[[227 191 289 217]]
[[365 180 427 208]]
[[216 194 268 216]]
[[167 171 209 199]]
[[403 186 463 214]]
[[340 197 392 219]]
[[263 199 305 219]]
[[399 197 487 231]]
[[189 194 227 220]]
[[208 177 258 201]]
[[458 190 504 216]]
[[352 201 392 219]]
[[335 201 377 221]]
[[274 190 316 210]]
[[273 183 335 211]]
[[388 206 436 228]]
[[172 179 216 205]]
[[105 195 183 229]]
[[326 192 384 218]]
[[271 188 337 214]]
[[318 183 364 207]]
[[214 179 248 203]]
[[335 191 389 215]]
[[370 194 418 216]]
[[213 211 305 245]]
[[466 188 504 214]]
[[144 187 214 215]]
[[411 200 459 222]]
[[295 199 367 227]]
[[401 192 451 216]]
[[404 196 454 218]]
[[270 193 320 215]]
[[444 187 490 215]]
[[194 192 248 218]]
[[309 199 381 227]]
[[329 190 397 216]]
[[228 187 260 207]]
[[237 187 275 207]]
[[422 197 468 219]]
[[390 185 454 213]]
[[411 194 459 218]]
[[181 190 223 212]]
[[340 179 402 207]]
[[430 190 486 216]]
[[290 199 330 219]]
[[246 180 294 204]]
[[293 197 333 215]]
[[464 189 502 215]]
[[255 190 295 212]]
[[425 188 481 216]]
[[456 190 504 216]]
[[309 167 381 199]]
[[269 200 333 226]]
[[446 196 476 220]]
[[205 197 277 225]]
[[192 184 240 208]]
[[252 190 306 214]]
[[365 184 435 212]]
[[367 195 429 221]]
[[180 176 226 202]]
[[355 190 405 212]]
[[211 194 243 214]]
[[103 197 153 231]]
[[157 194 245 228]]
[[301 201 347 223]]
[[407 197 443 219]]
[[312 197 394 231]]
[[234 179 286 203]]
[[410 191 454 213]]
[[303 177 361 205]]
[[380 181 440 209]]
[[230 191 256 213]]
[[362 184 430 210]]
[[325 194 367 216]]
[[321 192 377 218]]
[[184 184 214 212]]
[[250 181 324 213]]
[[486 201 530 227]]
[[249 203 299 225]]
[[170 170 214 198]]
[[334 184 382 208]]
[[207 200 243 222]]
[[407 195 457 217]]
[[312 194 364 216]]
[[173 182 205 206]]
[[419 200 465 222]]
[[398 202 422 220]]
[[248 172 310 200]]
[[248 199 312 225]]
[[349 183 415 209]]
[[287 193 341 215]]
[[403 203 425 221]]
[[354 193 406 215]]
[[220 196 258 216]]
[[282 197 322 215]]
[[233 196 271 216]]
[[218 201 260 223]]
[[536 183 578 215]]
[[346 185 410 213]]
[[350 188 400 212]]
[[254 188 296 208]]
[[402 197 440 219]]
[[455 192 481 214]]
[[193 196 239 222]]
[[410 188 450 212]]
[[210 197 282 225]]
[[172 180 206 204]]
[[254 188 296 208]]
[[440 189 490 217]]
[[339 196 389 218]]
[[390 181 450 209]]
[[400 202 464 228]]
[[343 188 393 212]]
[[257 199 307 221]]
[[277 196 317 214]]
[[441 200 477 222]]
[[345 201 405 227]]
[[461 202 517 228]]
[[461 188 505 214]]
[[489 201 529 227]]
[[466 210 546 244]]
[[322 190 364 210]]
[[490 205 552 239]]
[[252 196 338 230]]
[[365 185 413 209]]
[[339 195 381 217]]
[[304 201 366 227]]
[[413 207 449 229]]
[[323 183 369 207]]
[[348 212 438 246]]
[[140 178 212 210]]
[[160 194 228 222]]
[[427 184 477 212]]
[[218 179 260 203]]
[[166 186 230 214]]
[[423 198 449 218]]
[[247 199 297 221]]
[[173 181 199 205]]
[[223 179 299 211]]
[[177 185 235 213]]
[[374 203 438 229]]
[[183 181 259 213]]
[[455 185 489 213]]
[[217 199 277 225]]
[[458 192 480 214]]
[[196 170 256 198]]
[[193 196 237 222]]
[[262 181 312 205]]
[[457 184 491 212]]
[[406 186 466 214]]
[[426 197 510 231]]
[[220 179 262 203]]
[[413 196 443 216]]
[[270 184 320 206]]
[[468 202 522 228]]
[[228 180 272 204]]
[[326 197 378 219]]
[[213 201 251 223]]
[[290 181 360 209]]
[[326 201 384 227]]
[[407 203 471 229]]
[[336 184 400 212]]
[[544 182 586 214]]
[[312 181 382 209]]
[[406 191 452 213]]
[[396 193 440 215]]
[[309 195 363 217]]
[[339 183 405 209]]
[[527 184 577 216]]
[[428 188 468 212]]
[[322 191 376 215]]
[[358 187 434 219]]
[[230 199 292 225]]
[[257 190 297 212]]
[[328 194 380 216]]
[[225 185 275 207]]
[[168 178 212 202]]
[[351 183 417 209]]
[[400 189 476 221]]
[[450 192 498 218]]
[[446 202 506 228]]
[[284 181 352 209]]
[[346 183 412 209]]
[[381 192 433 216]]
[[413 200 461 222]]
[[339 185 415 217]]
[[392 201 420 219]]
[[439 193 475 215]]
[[415 198 477 224]]
[[349 193 403 217]]
[[171 178 209 204]]
[[449 186 489 214]]
[[397 187 445 211]]
[[449 200 479 222]]
[[232 195 270 213]]
[[301 191 353 213]]
[[435 189 487 217]]
[[121 177 191 209]]
[[391 202 455 228]]
[[313 176 375 204]]
[[224 187 252 207]]
[[198 192 252 218]]
[[300 206 348 228]]
[[109 165 181 197]]
[[424 192 470 216]]
[[432 199 490 227]]
[[328 206 376 228]]
[[172 170 216 198]]
[[398 191 442 215]]
[[267 184 317 208]]
[[251 187 293 207]]
[[380 206 430 228]]
[[265 190 319 214]]
[[286 204 336 226]]
[[441 194 475 218]]
[[441 193 481 217]]
[[216 201 256 223]]
[[490 186 558 218]]
[[417 189 453 213]]
[[348 201 408 227]]
[[282 180 350 206]]
[[454 178 542 214]]
[[187 184 229 206]]
[[108 200 172 234]]
[[179 181 221 205]]
[[255 179 309 203]]
[[ 71 168 107 200]]
[[275 199 323 221]]
[[452 192 478 214]]
[[239 190 301 216]]
[[325 190 393 216]]
[[162 184 190 206]]
[[364 191 436 225]]
[[384 196 426 218]]
[[210 200 254 222]]
[[422 190 480 216]]
[[349 184 399 208]]
[[260 212 350 246]]
[[146 182 204 210]]
[[385 204 429 226]]
[[490 208 558 242]]
[[236 178 302 204]]
[[237 190 279 212]]
[[179 195 267 229]]
[[413 206 447 228]]
[[261 199 311 221]]
[[380 196 422 218]]
[[366 187 442 219]]
[[342 190 410 216]]
[[ 71 165 133 197]]
[[366 191 434 217]]
[[226 195 262 215]]
[[169 195 239 223]]
[[281 192 323 214]]
[[284 189 336 211]]
[[416 189 476 215]]
[[193 192 245 218]]
[[229 187 253 207]]
[[322 200 394 228]]
[[243 190 305 216]]
[[286 182 338 206]]
[[457 193 479 215]]
[[169 180 201 206]]
[[339 189 389 211]]
[[465 189 505 215]]
[[311 186 357 210]]
[[237 171 299 199]]
[[210 195 246 213]]
[[450 198 504 226]]
[[200 175 256 201]]
[[170 183 208 211]]
[[209 197 281 225]]
[[136 164 210 196]]
[[331 185 405 217]]
[[373 201 411 221]]
[[236 198 276 218]]
[[397 190 461 216]]
[[316 190 358 210]]
[[307 183 355 207]]
[[407 212 497 246]]
[[217 180 253 204]]
[[257 179 325 205]]
[[195 184 261 210]]
[[167 172 207 200]]
[[513 185 571 217]]
[[378 185 446 211]]
[[234 189 266 209]]
[[308 182 354 206]]
[[366 206 416 228]]
[[162 184 192 206]]
[[251 196 291 214]]
[[367 194 419 216]]
[[103 197 155 231]]
[[336 197 414 231]]
[[100 174 166 206]]
[[375 186 423 210]]
[[274 194 328 216]]
[[205 184 251 206]]
[[108 175 176 207]]
[[163 189 195 211]]
[[426 202 488 228]]
[[367 196 455 230]]
[[407 190 451 214]]
[[365 194 427 220]]
[[247 181 317 209]]
[[373 186 437 214]]
[[163 183 195 205]]
[[ 83 165 147 197]]
[[166 178 242 210]]
[[330 206 376 228]]
[[234 199 296 225]]
[[238 190 286 212]]
[[217 195 253 215]]
[[374 186 450 218]]
[[539 181 579 213]]
[[388 196 436 218]]
[[232 181 302 209]]
[[405 187 469 213]]
[[378 194 426 216]]
[[198 197 270 225]]
[[162 205 250 239]]
[[321 194 363 216]]
[[358 192 400 212]]
[[378 199 432 221]]
[[456 201 484 223]]
[[355 201 395 219]]
[[207 177 267 203]]
[[349 206 399 228]]
[[227 178 279 202]]
[[406 183 462 211]]
[[ 69 167 107 199]]
[[187 192 237 218]]
[[467 190 517 218]]
[[368 196 410 218]]
[[367 198 421 220]]
[[179 181 235 209]]
[[455 187 527 219]]
[[212 194 246 212]]
[[380 203 426 225]]
[[189 179 247 207]]
[[230 191 256 213]]
[[390 194 442 216]]
[[394 191 440 215]]
[[226 178 288 204]]
[[104 175 172 207]]
[[337 186 413 218]]
[[345 183 411 209]]
[[214 197 286 225]]
[[161 194 249 228]]
[[271 183 345 215]]
[[229 191 261 213]]
[[189 194 225 220]]
[[395 182 453 210]]
[[162 188 192 210]]
[[337 188 387 212]]
[[301 181 371 209]]
[[186 169 240 197]]
[[192 179 250 207]]
[[361 202 409 224]]
[[408 195 440 215]]
[[204 169 264 197]]
[[337 190 405 216]]
[[303 191 363 217]]
[[189 184 233 206]]
[[326 188 376 210]]
[[166 180 228 208]]
[[257 190 307 212]]
[[335 191 377 211]]
[[202 198 256 224]]
[[247 181 311 209]]
[[365 203 403 223]]
[[227 181 297 209]]
[[ 99 196 155 230]]
[[297 194 351 216]]
[[427 187 479 215]]
[[312 196 364 218]]
[[406 204 426 222]]
[[454 186 490 214]]
[[224 194 260 212]]
[[402 192 446 216]]
[[417 196 463 218]]
[[411 187 475 213]]
[[374 195 416 217]]
[[290 213 378 247]]
[[411 188 487 220]]
[[446 212 532 246]]
[[502 207 558 241]]
[[284 192 326 214]]
[[199 178 247 202]]
[[241 172 303 200]]
[[380 181 440 209]]
[[206 180 274 208]]
[[170 195 258 229]]
[[380 191 452 225]]
[[359 202 407 224]]
[[211 195 245 215]]
[[231 209 323 243]]
[[234 195 272 213]]
[[399 203 429 223]]
[[413 197 445 217]]
[[305 195 357 217]]
[[168 181 216 207]]
[[195 198 247 224]]
[[207 200 243 222]]
[[379 202 413 222]]
[[399 197 461 223]]
[[351 202 411 228]]
[[195 184 243 208]]
[[281 194 335 216]]
[[177 190 219 212]]
[[229 191 261 213]]
[[289 196 373 230]]
[[175 176 227 204]]
[[306 175 366 203]]
[[314 198 354 216]]
[[123 205 203 239]]
[[274 193 326 215]]
[[354 197 440 231]]
[[359 178 421 206]]
[[ 96 174 162 206]]
[[187 192 235 218]]
[[251 192 301 214]]
[[309 191 367 217]]
[[176 170 226 198]]
[[354 183 424 211]]
[[228 170 290 198]]
[[203 180 263 208]]
[[414 206 448 228]]
[[361 186 425 214]]
[[345 202 405 228]]
[[214 198 272 224]]
[[324 207 408 241]]
[[472 190 506 216]]
[[435 187 485 215]]
[[226 188 280 212]]
[[204 195 236 213]]
[[136 183 190 211]]
[[178 206 268 240]]
[[333 206 381 228]]
[[371 195 413 217]]
[[264 188 306 208]]
[[378 199 412 217]]
[[220 186 288 212]]
[[419 199 451 219]]
[[462 202 518 228]]
[[109 186 143 214]]
[[213 191 271 217]]
[[420 198 450 218]]
[[274 205 324 227]]
[[408 186 484 218]]
[[452 190 482 214]]
[[404 187 446 211]]
[[306 201 346 221]]
[[216 194 250 212]]
[[214 198 286 226]]
[[273 207 363 241]]
[[311 191 363 215]]
[[212 170 274 198]]
[[317 185 391 217]]
[[336 184 384 208]]
[[300 189 342 209]]
[[294 213 380 247]]
[[446 194 478 216]]
[[163 173 207 201]]
[[254 212 344 246]]
[[249 187 291 207]]
[[424 197 470 219]]
[[208 195 238 213]]
[[333 182 403 210]]
[[278 197 318 215]]
[[480 200 526 226]]
[[339 183 409 211]]
[[393 202 421 222]]
[[318 194 360 216]]
[[227 177 291 203]]
[[433 200 475 222]]
[[206 177 256 201]]
[[184 196 272 230]]
[[253 182 301 206]]
[[231 187 269 207]]
[[247 187 287 207]]
[[331 196 383 218]]
[[376 186 424 210]]
[[416 195 458 217]]
[[209 170 271 198]]
[[344 178 406 206]]
[[426 191 454 215]]
[[223 179 275 203]]
[[230 189 260 209]]
[[420 194 466 218]]
[[213 180 245 204]]
[[425 191 467 213]]
[[443 200 503 226]]
[[438 200 478 222]]
[[215 179 251 203]]
[[260 183 310 205]]
[[195 181 271 213]]
[[323 183 371 207]]
[[424 202 512 236]]
[[233 189 265 209]]
[[264 189 306 209]]
[[422 198 450 218]]
[[232 166 306 198]]
[[220 195 254 215]]
[[340 198 380 216]]
[[440 186 486 214]]
[[493 200 531 226]]
[[292 183 352 211]]
[[163 187 195 209]]
[[203 179 279 211]]
[[416 190 456 214]]
[[305 200 345 220]]
[[405 206 449 228]]
wrote gt roidb to /home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/data/cache/train_gt_roidb.pkl
load ss roi
wrote ss roidb to /home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/data/cache/train_selective_search_roidb.pkl
done
Preparing training data...
done
Output will be saved to `/home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/output/IR_Reg/train`
Computing bounding-box regression targets...
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0110 14:27:28.324502 10246 solver.cpp:32] Initializing solver from parameters: 
train_net: "models/VGG_CNN_M_1024/train.prototxt"
base_lr: 0.001
display: 100
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 30000
snapshot: 0
snapshot_prefix: "vgg_cnn_m_1024_fast_rcnn"
average_loss: 100
I0110 14:27:28.324519 10246 solver.cpp:61] Creating training net from train_net file: models/VGG_CNN_M_1024/train.prototxt
I0110 14:27:28.324736 10246 net.cpp:42] Initializing net from parameters: 
name: "VGG_CNN_M_1024"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Python"
  top: "data"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_loss_weights"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 5
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0005
    beta: 0.75
    k: 2
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 6
    pooled_w: 6
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_loss_weights"
  top: "loss_bbox"
  loss_weight: 1
}
I0110 14:27:28.324796 10246 layer_factory.hpp:74] Creating layer data
I0110 14:27:28.342154 10246 net.cpp:84] Creating Layer data
I0110 14:27:28.342166 10246 net.cpp:338] data -> data
I0110 14:27:28.342173 10246 net.cpp:338] data -> rois
I0110 14:27:28.342177 10246 net.cpp:338] data -> labels
I0110 14:27:28.342181 10246 net.cpp:338] data -> bbox_targets
I0110 14:27:28.342185 10246 net.cpp:338] data -> bbox_loss_weights
I0110 14:27:28.342188 10246 net.cpp:113] Setting up data
I0110 14:27:28.342464 10246 net.cpp:120] Top shape: 1 3 100 100 (30000)
I0110 14:27:28.342469 10246 net.cpp:120] Top shape: 1 5 (5)
I0110 14:27:28.342471 10246 net.cpp:120] Top shape: 1 (1)
I0110 14:27:28.342473 10246 net.cpp:120] Top shape: 1 8 (8)
I0110 14:27:28.342475 10246 net.cpp:120] Top shape: 1 8 (8)
I0110 14:27:28.342476 10246 layer_factory.hpp:74] Creating layer conv1
I0110 14:27:28.342481 10246 net.cpp:84] Creating Layer conv1
I0110 14:27:28.342483 10246 net.cpp:380] conv1 <- data
I0110 14:27:28.342486 10246 net.cpp:338] conv1 -> conv1
I0110 14:27:28.342490 10246 net.cpp:113] Setting up conv1
I0110 14:27:28.342509 10246 net.cpp:120] Top shape: 1 96 47 47 (212064)
I0110 14:27:28.342515 10246 layer_factory.hpp:74] Creating layer relu1
I0110 14:27:28.342519 10246 net.cpp:84] Creating Layer relu1
I0110 14:27:28.342520 10246 net.cpp:380] relu1 <- conv1
I0110 14:27:28.342522 10246 net.cpp:327] relu1 -> conv1 (in-place)
I0110 14:27:28.342525 10246 net.cpp:113] Setting up relu1
I0110 14:27:28.342527 10246 net.cpp:120] Top shape: 1 96 47 47 (212064)
I0110 14:27:28.342530 10246 layer_factory.hpp:74] Creating layer norm1
I0110 14:27:28.342532 10246 net.cpp:84] Creating Layer norm1
I0110 14:27:28.342533 10246 net.cpp:380] norm1 <- conv1
I0110 14:27:28.342535 10246 net.cpp:338] norm1 -> norm1
I0110 14:27:28.342538 10246 net.cpp:113] Setting up norm1
I0110 14:27:28.342542 10246 net.cpp:120] Top shape: 1 96 47 47 (212064)
I0110 14:27:28.342543 10246 layer_factory.hpp:74] Creating layer pool1
I0110 14:27:28.342547 10246 net.cpp:84] Creating Layer pool1
I0110 14:27:28.342548 10246 net.cpp:380] pool1 <- norm1
I0110 14:27:28.342550 10246 net.cpp:338] pool1 -> pool1
I0110 14:27:28.342553 10246 net.cpp:113] Setting up pool1
I0110 14:27:28.342558 10246 net.cpp:120] Top shape: 1 96 23 23 (50784)
I0110 14:27:28.342561 10246 layer_factory.hpp:74] Creating layer conv2
I0110 14:27:28.342564 10246 net.cpp:84] Creating Layer conv2
I0110 14:27:28.342566 10246 net.cpp:380] conv2 <- pool1
I0110 14:27:28.342569 10246 net.cpp:338] conv2 -> conv2
I0110 14:27:28.342576 10246 net.cpp:113] Setting up conv2
I0110 14:27:28.343029 10246 net.cpp:120] Top shape: 1 256 11 11 (30976)
I0110 14:27:28.343034 10246 layer_factory.hpp:74] Creating layer relu2
I0110 14:27:28.343036 10246 net.cpp:84] Creating Layer relu2
I0110 14:27:28.343037 10246 net.cpp:380] relu2 <- conv2
I0110 14:27:28.343040 10246 net.cpp:327] relu2 -> conv2 (in-place)
I0110 14:27:28.343042 10246 net.cpp:113] Setting up relu2
I0110 14:27:28.343045 10246 net.cpp:120] Top shape: 1 256 11 11 (30976)
I0110 14:27:28.343046 10246 layer_factory.hpp:74] Creating layer norm2
I0110 14:27:28.343050 10246 net.cpp:84] Creating Layer norm2
I0110 14:27:28.343050 10246 net.cpp:380] norm2 <- conv2
I0110 14:27:28.343052 10246 net.cpp:338] norm2 -> norm2
I0110 14:27:28.343055 10246 net.cpp:113] Setting up norm2
I0110 14:27:28.343058 10246 net.cpp:120] Top shape: 1 256 11 11 (30976)
I0110 14:27:28.343060 10246 layer_factory.hpp:74] Creating layer pool2
I0110 14:27:28.343063 10246 net.cpp:84] Creating Layer pool2
I0110 14:27:28.343065 10246 net.cpp:380] pool2 <- norm2
I0110 14:27:28.343068 10246 net.cpp:338] pool2 -> pool2
I0110 14:27:28.343071 10246 net.cpp:113] Setting up pool2
I0110 14:27:28.343075 10246 net.cpp:120] Top shape: 1 256 5 5 (6400)
I0110 14:27:28.343078 10246 layer_factory.hpp:74] Creating layer conv3
I0110 14:27:28.343081 10246 net.cpp:84] Creating Layer conv3
I0110 14:27:28.343082 10246 net.cpp:380] conv3 <- pool2
I0110 14:27:28.343086 10246 net.cpp:338] conv3 -> conv3
I0110 14:27:28.343088 10246 net.cpp:113] Setting up conv3
I0110 14:27:28.343865 10246 net.cpp:120] Top shape: 1 512 5 5 (12800)
I0110 14:27:28.343871 10246 layer_factory.hpp:74] Creating layer relu3
I0110 14:27:28.343874 10246 net.cpp:84] Creating Layer relu3
I0110 14:27:28.343875 10246 net.cpp:380] relu3 <- conv3
I0110 14:27:28.343878 10246 net.cpp:327] relu3 -> conv3 (in-place)
I0110 14:27:28.343880 10246 net.cpp:113] Setting up relu3
I0110 14:27:28.343883 10246 net.cpp:120] Top shape: 1 512 5 5 (12800)
I0110 14:27:28.343884 10246 layer_factory.hpp:74] Creating layer conv4
I0110 14:27:28.343888 10246 net.cpp:84] Creating Layer conv4
I0110 14:27:28.343889 10246 net.cpp:380] conv4 <- conv3
I0110 14:27:28.343891 10246 net.cpp:338] conv4 -> conv4
I0110 14:27:28.343894 10246 net.cpp:113] Setting up conv4
I0110 14:27:28.345049 10246 net.cpp:120] Top shape: 1 512 5 5 (12800)
I0110 14:27:28.345059 10246 layer_factory.hpp:74] Creating layer relu4
I0110 14:27:28.345063 10246 net.cpp:84] Creating Layer relu4
I0110 14:27:28.345065 10246 net.cpp:380] relu4 <- conv4
I0110 14:27:28.345068 10246 net.cpp:327] relu4 -> conv4 (in-place)
I0110 14:27:28.345072 10246 net.cpp:113] Setting up relu4
I0110 14:27:28.345073 10246 net.cpp:120] Top shape: 1 512 5 5 (12800)
I0110 14:27:28.345075 10246 layer_factory.hpp:74] Creating layer conv5
I0110 14:27:28.345078 10246 net.cpp:84] Creating Layer conv5
I0110 14:27:28.345079 10246 net.cpp:380] conv5 <- conv4
I0110 14:27:28.345082 10246 net.cpp:338] conv5 -> conv5
I0110 14:27:28.345085 10246 net.cpp:113] Setting up conv5
I0110 14:27:28.346448 10246 net.cpp:120] Top shape: 1 512 5 5 (12800)
I0110 14:27:28.346460 10246 layer_factory.hpp:74] Creating layer relu5
I0110 14:27:28.346463 10246 net.cpp:84] Creating Layer relu5
I0110 14:27:28.346465 10246 net.cpp:380] relu5 <- conv5
I0110 14:27:28.346468 10246 net.cpp:327] relu5 -> conv5 (in-place)
I0110 14:27:28.346472 10246 net.cpp:113] Setting up relu5
I0110 14:27:28.346474 10246 net.cpp:120] Top shape: 1 512 5 5 (12800)
I0110 14:27:28.346475 10246 layer_factory.hpp:74] Creating layer roi_pool5
I0110 14:27:28.346479 10246 net.cpp:84] Creating Layer roi_pool5
I0110 14:27:28.346480 10246 net.cpp:380] roi_pool5 <- conv5
I0110 14:27:28.346483 10246 net.cpp:380] roi_pool5 <- rois
I0110 14:27:28.346487 10246 net.cpp:338] roi_pool5 -> pool5
I0110 14:27:28.346489 10246 net.cpp:113] Setting up roi_pool5
I0110 14:27:28.346491 10246 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I0110 14:27:28.346501 10246 net.cpp:120] Top shape: 1 512 6 6 (18432)
I0110 14:27:28.346503 10246 layer_factory.hpp:74] Creating layer fc6
I0110 14:27:28.346508 10246 net.cpp:84] Creating Layer fc6
I0110 14:27:28.346508 10246 net.cpp:380] fc6 <- pool5
I0110 14:27:28.346511 10246 net.cpp:338] fc6 -> fc6
I0110 14:27:28.346514 10246 net.cpp:113] Setting up fc6
I0110 14:27:28.402639 10246 net.cpp:120] Top shape: 1 4096 (4096)
I0110 14:27:28.402658 10246 layer_factory.hpp:74] Creating layer relu6
I0110 14:27:28.402663 10246 net.cpp:84] Creating Layer relu6
I0110 14:27:28.402667 10246 net.cpp:380] relu6 <- fc6
I0110 14:27:28.402670 10246 net.cpp:327] relu6 -> fc6 (in-place)
I0110 14:27:28.402673 10246 net.cpp:113] Setting up relu6
I0110 14:27:28.402676 10246 net.cpp:120] Top shape: 1 4096 (4096)
I0110 14:27:28.402678 10246 layer_factory.hpp:74] Creating layer drop6
I0110 14:27:28.402683 10246 net.cpp:84] Creating Layer drop6
I0110 14:27:28.402683 10246 net.cpp:380] drop6 <- fc6
I0110 14:27:28.402688 10246 net.cpp:327] drop6 -> fc6 (in-place)
I0110 14:27:28.402689 10246 net.cpp:113] Setting up drop6
I0110 14:27:28.402693 10246 net.cpp:120] Top shape: 1 4096 (4096)
I0110 14:27:28.402693 10246 layer_factory.hpp:74] Creating layer fc7
I0110 14:27:28.402698 10246 net.cpp:84] Creating Layer fc7
I0110 14:27:28.402698 10246 net.cpp:380] fc7 <- fc6
I0110 14:27:28.402703 10246 net.cpp:338] fc7 -> fc7
I0110 14:27:28.402709 10246 net.cpp:113] Setting up fc7
I0110 14:27:28.418727 10246 net.cpp:120] Top shape: 1 1024 (1024)
I0110 14:27:28.418745 10246 layer_factory.hpp:74] Creating layer relu7
I0110 14:27:28.418751 10246 net.cpp:84] Creating Layer relu7
I0110 14:27:28.418752 10246 net.cpp:380] relu7 <- fc7
I0110 14:27:28.418756 10246 net.cpp:327] relu7 -> fc7 (in-place)
I0110 14:27:28.418761 10246 net.cpp:113] Setting up relu7
I0110 14:27:28.418763 10246 net.cpp:120] Top shape: 1 1024 (1024)
I0110 14:27:28.418764 10246 layer_factory.hpp:74] Creating layer drop7
I0110 14:27:28.418768 10246 net.cpp:84] Creating Layer drop7
I0110 14:27:28.418769 10246 net.cpp:380] drop7 <- fc7
I0110 14:27:28.418772 10246 net.cpp:327] drop7 -> fc7 (in-place)
I0110 14:27:28.418774 10246 net.cpp:113] Setting up drop7
I0110 14:27:28.418777 10246 net.cpp:120] Top shape: 1 1024 (1024)
I0110 14:27:28.418778 10246 layer_factory.hpp:74] Creating layer fc7_drop7_0_split
I0110 14:27:28.418782 10246 net.cpp:84] Creating Layer fc7_drop7_0_split
I0110 14:27:28.418783 10246 net.cpp:380] fc7_drop7_0_split <- fc7
I0110 14:27:28.418787 10246 net.cpp:338] fc7_drop7_0_split -> fc7_drop7_0_split_0
I0110 14:27:28.418790 10246 net.cpp:338] fc7_drop7_0_split -> fc7_drop7_0_split_1
I0110 14:27:28.418797 10246 net.cpp:113] Setting up fc7_drop7_0_split
I0110 14:27:28.418800 10246 net.cpp:120] Top shape: 1 1024 (1024)
I0110 14:27:28.418802 10246 net.cpp:120] Top shape: 1 1024 (1024)
I0110 14:27:28.418803 10246 layer_factory.hpp:74] Creating layer cls_score
I0110 14:27:28.418809 10246 net.cpp:84] Creating Layer cls_score
I0110 14:27:28.418812 10246 net.cpp:380] cls_score <- fc7_drop7_0_split_0
I0110 14:27:28.418814 10246 net.cpp:338] cls_score -> cls_score
I0110 14:27:28.418819 10246 net.cpp:113] Setting up cls_score
I0110 14:27:28.418843 10246 net.cpp:120] Top shape: 1 2 (2)
I0110 14:27:28.418848 10246 layer_factory.hpp:74] Creating layer bbox_pred
I0110 14:27:28.418851 10246 net.cpp:84] Creating Layer bbox_pred
I0110 14:27:28.418853 10246 net.cpp:380] bbox_pred <- fc7_drop7_0_split_1
I0110 14:27:28.418859 10246 net.cpp:338] bbox_pred -> bbox_pred
I0110 14:27:28.418864 10246 net.cpp:113] Setting up bbox_pred
I0110 14:27:28.418929 10246 net.cpp:120] Top shape: 1 8 (8)
I0110 14:27:28.418938 10246 layer_factory.hpp:74] Creating layer loss_cls
I0110 14:27:28.418943 10246 net.cpp:84] Creating Layer loss_cls
I0110 14:27:28.418946 10246 net.cpp:380] loss_cls <- cls_score
I0110 14:27:28.418949 10246 net.cpp:380] loss_cls <- labels
I0110 14:27:28.418956 10246 net.cpp:338] loss_cls -> loss_cls
I0110 14:27:28.418974 10246 net.cpp:113] Setting up loss_cls
I0110 14:27:28.418978 10246 layer_factory.hpp:74] Creating layer loss_cls
I0110 14:27:28.418989 10246 net.cpp:120] Top shape: (1)
I0110 14:27:28.418992 10246 net.cpp:122]     with loss weight 1
I0110 14:27:28.418998 10246 layer_factory.hpp:74] Creating layer loss_bbox
I0110 14:27:28.419003 10246 net.cpp:84] Creating Layer loss_bbox
I0110 14:27:28.419005 10246 net.cpp:380] loss_bbox <- bbox_pred
I0110 14:27:28.419008 10246 net.cpp:380] loss_bbox <- bbox_targets
I0110 14:27:28.419010 10246 net.cpp:380] loss_bbox <- bbox_loss_weights
I0110 14:27:28.419013 10246 net.cpp:338] loss_bbox -> loss_bbox
I0110 14:27:28.419018 10246 net.cpp:113] Setting up loss_bbox
I0110 14:27:28.419025 10246 net.cpp:120] Top shape: (1)
I0110 14:27:28.419028 10246 net.cpp:122]     with loss weight 1
I0110 14:27:28.419029 10246 net.cpp:167] loss_bbox needs backward computation.
I0110 14:27:28.419033 10246 net.cpp:167] loss_cls needs backward computation.
I0110 14:27:28.419034 10246 net.cpp:167] bbox_pred needs backward computation.
I0110 14:27:28.419036 10246 net.cpp:167] cls_score needs backward computation.
I0110 14:27:28.419039 10246 net.cpp:167] fc7_drop7_0_split needs backward computation.
I0110 14:27:28.419039 10246 net.cpp:167] drop7 needs backward computation.
I0110 14:27:28.419041 10246 net.cpp:167] relu7 needs backward computation.
I0110 14:27:28.419044 10246 net.cpp:167] fc7 needs backward computation.
I0110 14:27:28.419045 10246 net.cpp:167] drop6 needs backward computation.
I0110 14:27:28.419046 10246 net.cpp:167] relu6 needs backward computation.
I0110 14:27:28.419049 10246 net.cpp:167] fc6 needs backward computation.
I0110 14:27:28.419051 10246 net.cpp:167] roi_pool5 needs backward computation.
I0110 14:27:28.419054 10246 net.cpp:167] relu5 needs backward computation.
I0110 14:27:28.419056 10246 net.cpp:167] conv5 needs backward computation.
I0110 14:27:28.419057 10246 net.cpp:167] relu4 needs backward computation.
I0110 14:27:28.419059 10246 net.cpp:167] conv4 needs backward computation.
I0110 14:27:28.419062 10246 net.cpp:167] relu3 needs backward computation.
I0110 14:27:28.419065 10246 net.cpp:167] conv3 needs backward computation.
I0110 14:27:28.419067 10246 net.cpp:167] pool2 needs backward computation.
I0110 14:27:28.419070 10246 net.cpp:167] norm2 needs backward computation.
I0110 14:27:28.419072 10246 net.cpp:167] relu2 needs backward computation.
I0110 14:27:28.419075 10246 net.cpp:167] conv2 needs backward computation.
I0110 14:27:28.419076 10246 net.cpp:169] pool1 does not need backward computation.
I0110 14:27:28.419080 10246 net.cpp:169] norm1 does not need backward computation.
I0110 14:27:28.419081 10246 net.cpp:169] relu1 does not need backward computation.
I0110 14:27:28.419083 10246 net.cpp:169] conv1 does not need backward computation.
I0110 14:27:28.419085 10246 net.cpp:169] data does not need backward computation.
I0110 14:27:28.419087 10246 net.cpp:205] This network produces output loss_bbox
I0110 14:27:28.419088 10246 net.cpp:205] This network produces output loss_cls
I0110 14:27:28.419101 10246 net.cpp:447] Collecting Learning Rate and Weight Decay.
I0110 14:27:28.419106 10246 net.cpp:217] Network initialization done.
I0110 14:27:28.419108 10246 net.cpp:218] Memory required for data: 3715912
I0110 14:27:28.419198 10246 solver.cpp:42] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG_CNN_M_1024.v2.caffemodel
Solving...
/home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/tools/../lib/roi_data_layer/minibatch.py:84: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  replace=False)
/home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/tools/../lib/roi_data_layer/minibatch.py:97: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  replace=False)
/home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/tools/../lib/roi_data_layer/minibatch.py:104: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  labels[fg_rois_per_this_image:] = 0
/home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/tools/../lib/roi_data_layer/minibatch.py:161: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_targets[ind, start:end] = bbox_target_data[ind, 1:]
/home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/tools/../lib/roi_data_layer/minibatch.py:162: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  bbox_loss_weights[ind, start:end] = [1., 1., 1., 1.]
I0110 14:27:29.232080 10246 solver.cpp:189] Iteration 0, loss = 1.06533
I0110 14:27:29.232098 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.15286 (* 1 = 0.15286 loss)
I0110 14:27:29.232102 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.912471 (* 1 = 0.912471 loss)
I0110 14:27:29.232106 10246 solver.cpp:464] Iteration 0, lr = 0.001
I0110 14:27:38.525431 10246 solver.cpp:189] Iteration 100, loss = 0.0704174
I0110 14:27:38.525450 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00964499 (* 1 = 0.00964499 loss)
I0110 14:27:38.525455 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0607724 (* 1 = 0.0607724 loss)
I0110 14:27:38.525459 10246 solver.cpp:464] Iteration 100, lr = 0.001
I0110 14:27:47.112581 10246 solver.cpp:189] Iteration 200, loss = 0.176922
I0110 14:27:47.112599 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0719712 (* 1 = 0.0719712 loss)
I0110 14:27:47.112603 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.104951 (* 1 = 0.104951 loss)
I0110 14:27:47.112607 10246 solver.cpp:464] Iteration 200, lr = 0.001
I0110 14:27:55.673868 10246 solver.cpp:189] Iteration 300, loss = 0.136097
I0110 14:27:55.673887 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0507486 (* 1 = 0.0507486 loss)
I0110 14:27:55.673892 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0853482 (* 1 = 0.0853482 loss)
I0110 14:27:55.673894 10246 solver.cpp:464] Iteration 300, lr = 0.001
I0110 14:28:05.216420 10246 solver.cpp:189] Iteration 400, loss = 0.601308
I0110 14:28:05.216439 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.2459 (* 1 = 0.2459 loss)
I0110 14:28:05.216442 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.355407 (* 1 = 0.355407 loss)
I0110 14:28:05.216446 10246 solver.cpp:464] Iteration 400, lr = 0.001
I0110 14:28:13.982508 10246 solver.cpp:189] Iteration 500, loss = 0.598014
I0110 14:28:13.982525 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.153563 (* 1 = 0.153563 loss)
I0110 14:28:13.982529 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.444451 (* 1 = 0.444451 loss)
I0110 14:28:13.982532 10246 solver.cpp:464] Iteration 500, lr = 0.001
I0110 14:28:22.746382 10246 solver.cpp:189] Iteration 600, loss = 0.0720979
I0110 14:28:22.746400 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0173296 (* 1 = 0.0173296 loss)
I0110 14:28:22.746404 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0547683 (* 1 = 0.0547683 loss)
I0110 14:28:22.746407 10246 solver.cpp:464] Iteration 600, lr = 0.001
I0110 14:28:31.797941 10246 solver.cpp:189] Iteration 700, loss = 0.129603
I0110 14:28:31.797960 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0790074 (* 1 = 0.0790074 loss)
I0110 14:28:31.797965 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.050596 (* 1 = 0.050596 loss)
I0110 14:28:31.797967 10246 solver.cpp:464] Iteration 700, lr = 0.001
I0110 14:28:40.471150 10246 solver.cpp:189] Iteration 800, loss = 0.0382183
I0110 14:28:40.471168 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00155777 (* 1 = 0.00155777 loss)
I0110 14:28:40.471173 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0366606 (* 1 = 0.0366606 loss)
I0110 14:28:40.471175 10246 solver.cpp:464] Iteration 800, lr = 0.001
I0110 14:28:48.990180 10246 solver.cpp:189] Iteration 900, loss = 0.217191
I0110 14:28:48.990197 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0894389 (* 1 = 0.0894389 loss)
I0110 14:28:48.990201 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.127752 (* 1 = 0.127752 loss)
I0110 14:28:48.990206 10246 solver.cpp:464] Iteration 900, lr = 0.001
speed: 0.089s / iter
I0110 14:28:57.574653 10246 solver.cpp:189] Iteration 1000, loss = 0.177964
I0110 14:28:57.574671 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0818523 (* 1 = 0.0818523 loss)
I0110 14:28:57.574674 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0961122 (* 1 = 0.0961122 loss)
I0110 14:28:57.574678 10246 solver.cpp:464] Iteration 1000, lr = 0.001
I0110 14:29:06.097008 10246 solver.cpp:189] Iteration 1100, loss = 0.144969
I0110 14:29:06.097026 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0392275 (* 1 = 0.0392275 loss)
I0110 14:29:06.097030 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.105742 (* 1 = 0.105742 loss)
I0110 14:29:06.097033 10246 solver.cpp:464] Iteration 1100, lr = 0.001
I0110 14:29:14.593753 10246 solver.cpp:189] Iteration 1200, loss = 0.0252044
I0110 14:29:14.593771 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00847569 (* 1 = 0.00847569 loss)
I0110 14:29:14.593775 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0167287 (* 1 = 0.0167287 loss)
I0110 14:29:14.593778 10246 solver.cpp:464] Iteration 1200, lr = 0.001
I0110 14:29:23.086458 10246 solver.cpp:189] Iteration 1300, loss = 0.291677
I0110 14:29:23.086477 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.154323 (* 1 = 0.154323 loss)
I0110 14:29:23.086482 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.137354 (* 1 = 0.137354 loss)
I0110 14:29:23.086484 10246 solver.cpp:464] Iteration 1300, lr = 0.001
I0110 14:29:31.650848 10246 solver.cpp:189] Iteration 1400, loss = 0.173986
I0110 14:29:31.650867 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0596677 (* 1 = 0.0596677 loss)
I0110 14:29:31.650871 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.114318 (* 1 = 0.114318 loss)
I0110 14:29:31.650876 10246 solver.cpp:464] Iteration 1400, lr = 0.001
I0110 14:29:40.576812 10246 solver.cpp:189] Iteration 1500, loss = 0.0741881
I0110 14:29:40.576830 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0244412 (* 1 = 0.0244412 loss)
I0110 14:29:40.576834 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0497468 (* 1 = 0.0497468 loss)
I0110 14:29:40.576838 10246 solver.cpp:464] Iteration 1500, lr = 0.001
I0110 14:29:49.323084 10246 solver.cpp:189] Iteration 1600, loss = 0.101089
I0110 14:29:49.323103 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0510265 (* 1 = 0.0510265 loss)
I0110 14:29:49.323107 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0500627 (* 1 = 0.0500627 loss)
I0110 14:29:49.323112 10246 solver.cpp:464] Iteration 1600, lr = 0.001
I0110 14:29:57.895777 10246 solver.cpp:189] Iteration 1700, loss = 0.383137
I0110 14:29:57.895794 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.176782 (* 1 = 0.176782 loss)
I0110 14:29:57.895798 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.206355 (* 1 = 0.206355 loss)
I0110 14:29:57.895802 10246 solver.cpp:464] Iteration 1700, lr = 0.001
I0110 14:30:06.441841 10246 solver.cpp:189] Iteration 1800, loss = 0.00869078
I0110 14:30:06.441861 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00578295 (* 1 = 0.00578295 loss)
I0110 14:30:06.441865 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00290784 (* 1 = 0.00290784 loss)
I0110 14:30:06.441869 10246 solver.cpp:464] Iteration 1800, lr = 0.001
I0110 14:30:15.571735 10246 solver.cpp:189] Iteration 1900, loss = 0.1974
I0110 14:30:15.571755 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0525702 (* 1 = 0.0525702 loss)
I0110 14:30:15.571759 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.14483 (* 1 = 0.14483 loss)
I0110 14:30:15.571763 10246 solver.cpp:464] Iteration 1900, lr = 0.001
speed: 0.088s / iter
I0110 14:30:25.012070 10246 solver.cpp:189] Iteration 2000, loss = 0.273289
I0110 14:30:25.012087 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.182913 (* 1 = 0.182913 loss)
I0110 14:30:25.012092 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0903753 (* 1 = 0.0903753 loss)
I0110 14:30:25.012095 10246 solver.cpp:464] Iteration 2000, lr = 0.001
I0110 14:30:33.768013 10246 solver.cpp:189] Iteration 2100, loss = 0.487512
I0110 14:30:33.768031 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.237637 (* 1 = 0.237637 loss)
I0110 14:30:33.768035 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.249875 (* 1 = 0.249875 loss)
I0110 14:30:33.768038 10246 solver.cpp:464] Iteration 2100, lr = 0.001
I0110 14:30:42.320881 10246 solver.cpp:189] Iteration 2200, loss = 0.0193686
I0110 14:30:42.320901 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00477736 (* 1 = 0.00477736 loss)
I0110 14:30:42.320905 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0145913 (* 1 = 0.0145913 loss)
I0110 14:30:42.320909 10246 solver.cpp:464] Iteration 2200, lr = 0.001
I0110 14:30:51.233767 10246 solver.cpp:189] Iteration 2300, loss = 0.216191
I0110 14:30:51.233786 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0532147 (* 1 = 0.0532147 loss)
I0110 14:30:51.233790 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.162976 (* 1 = 0.162976 loss)
I0110 14:30:51.233794 10246 solver.cpp:464] Iteration 2300, lr = 0.001
I0110 14:30:59.911331 10246 solver.cpp:189] Iteration 2400, loss = 0.018215
I0110 14:30:59.911350 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00248608 (* 1 = 0.00248608 loss)
I0110 14:30:59.911355 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.015729 (* 1 = 0.015729 loss)
I0110 14:30:59.911358 10246 solver.cpp:464] Iteration 2400, lr = 0.001
I0110 14:31:08.566143 10246 solver.cpp:189] Iteration 2500, loss = 0.109638
I0110 14:31:08.566160 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0282984 (* 1 = 0.0282984 loss)
I0110 14:31:08.566164 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0813396 (* 1 = 0.0813396 loss)
I0110 14:31:08.566169 10246 solver.cpp:464] Iteration 2500, lr = 0.001
I0110 14:31:17.629582 10246 solver.cpp:189] Iteration 2600, loss = 0.0540219
I0110 14:31:17.629601 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00491829 (* 1 = 0.00491829 loss)
I0110 14:31:17.629606 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0491036 (* 1 = 0.0491036 loss)
I0110 14:31:17.629608 10246 solver.cpp:464] Iteration 2600, lr = 0.001
I0110 14:31:26.765522 10246 solver.cpp:189] Iteration 2700, loss = 0.265928
I0110 14:31:26.765542 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0828434 (* 1 = 0.0828434 loss)
I0110 14:31:26.765545 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.183084 (* 1 = 0.183084 loss)
I0110 14:31:26.765548 10246 solver.cpp:464] Iteration 2700, lr = 0.001
I0110 14:31:35.573835 10246 solver.cpp:189] Iteration 2800, loss = 0.174191
I0110 14:31:35.573854 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.09911 (* 1 = 0.09911 loss)
I0110 14:31:35.573858 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0750807 (* 1 = 0.0750807 loss)
I0110 14:31:35.573861 10246 solver.cpp:464] Iteration 2800, lr = 0.001
I0110 14:31:44.673454 10246 solver.cpp:189] Iteration 2900, loss = 0.254945
I0110 14:31:44.673472 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.230067 (* 1 = 0.230067 loss)
I0110 14:31:44.673477 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0248779 (* 1 = 0.0248779 loss)
I0110 14:31:44.673480 10246 solver.cpp:464] Iteration 2900, lr = 0.001
speed: 0.088s / iter
I0110 14:31:53.351604 10246 solver.cpp:189] Iteration 3000, loss = 0.158512
I0110 14:31:53.351624 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0824663 (* 1 = 0.0824663 loss)
I0110 14:31:53.351627 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0760455 (* 1 = 0.0760455 loss)
I0110 14:31:53.351630 10246 solver.cpp:464] Iteration 3000, lr = 0.001
I0110 14:32:02.135197 10246 solver.cpp:189] Iteration 3100, loss = 0.235297
I0110 14:32:02.135215 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.148559 (* 1 = 0.148559 loss)
I0110 14:32:02.135220 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0867381 (* 1 = 0.0867381 loss)
I0110 14:32:02.135223 10246 solver.cpp:464] Iteration 3100, lr = 0.001
I0110 14:32:10.687538 10246 solver.cpp:189] Iteration 3200, loss = 0.25816
I0110 14:32:10.687556 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.173451 (* 1 = 0.173451 loss)
I0110 14:32:10.687561 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0847091 (* 1 = 0.0847091 loss)
I0110 14:32:10.687563 10246 solver.cpp:464] Iteration 3200, lr = 0.001
I0110 14:32:19.499672 10246 solver.cpp:189] Iteration 3300, loss = 0.104129
I0110 14:32:19.499691 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0367788 (* 1 = 0.0367788 loss)
I0110 14:32:19.499696 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0673504 (* 1 = 0.0673504 loss)
I0110 14:32:19.499698 10246 solver.cpp:464] Iteration 3300, lr = 0.001
I0110 14:32:28.105134 10246 solver.cpp:189] Iteration 3400, loss = 0.114493
I0110 14:32:28.105152 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0622565 (* 1 = 0.0622565 loss)
I0110 14:32:28.105156 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.052236 (* 1 = 0.052236 loss)
I0110 14:32:28.105159 10246 solver.cpp:464] Iteration 3400, lr = 0.001
I0110 14:32:36.649045 10246 solver.cpp:189] Iteration 3500, loss = 0.217814
I0110 14:32:36.649063 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0525345 (* 1 = 0.0525345 loss)
I0110 14:32:36.649067 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.165279 (* 1 = 0.165279 loss)
I0110 14:32:36.649071 10246 solver.cpp:464] Iteration 3500, lr = 0.001
I0110 14:32:45.361330 10246 solver.cpp:189] Iteration 3600, loss = 0.0126116
I0110 14:32:45.361347 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00457383 (* 1 = 0.00457383 loss)
I0110 14:32:45.361351 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00803777 (* 1 = 0.00803777 loss)
I0110 14:32:45.361354 10246 solver.cpp:464] Iteration 3600, lr = 0.001
I0110 14:32:54.045665 10246 solver.cpp:189] Iteration 3700, loss = 0.190336
I0110 14:32:54.045683 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0919597 (* 1 = 0.0919597 loss)
I0110 14:32:54.045687 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0983759 (* 1 = 0.0983759 loss)
I0110 14:32:54.045691 10246 solver.cpp:464] Iteration 3700, lr = 0.001
I0110 14:33:02.728551 10246 solver.cpp:189] Iteration 3800, loss = 0.123356
I0110 14:33:02.728569 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0718297 (* 1 = 0.0718297 loss)
I0110 14:33:02.728574 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.051526 (* 1 = 0.051526 loss)
I0110 14:33:02.728577 10246 solver.cpp:464] Iteration 3800, lr = 0.001
I0110 14:33:11.384237 10246 solver.cpp:189] Iteration 3900, loss = 0.0348765
I0110 14:33:11.384258 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0114548 (* 1 = 0.0114548 loss)
I0110 14:33:11.384263 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0234217 (* 1 = 0.0234217 loss)
I0110 14:33:11.384266 10246 solver.cpp:464] Iteration 3900, lr = 0.001
speed: 0.088s / iter
I0110 14:33:20.026156 10246 solver.cpp:189] Iteration 4000, loss = 0.108625
I0110 14:33:20.026175 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0495705 (* 1 = 0.0495705 loss)
I0110 14:33:20.026180 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0590541 (* 1 = 0.0590541 loss)
I0110 14:33:20.026182 10246 solver.cpp:464] Iteration 4000, lr = 0.001
I0110 14:33:28.545518 10246 solver.cpp:189] Iteration 4100, loss = 0.0421187
I0110 14:33:28.545536 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00345563 (* 1 = 0.00345563 loss)
I0110 14:33:28.545541 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0386631 (* 1 = 0.0386631 loss)
I0110 14:33:28.545543 10246 solver.cpp:464] Iteration 4100, lr = 0.001
I0110 14:33:36.996079 10246 solver.cpp:189] Iteration 4200, loss = 0.0544694
I0110 14:33:36.996098 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0425059 (* 1 = 0.0425059 loss)
I0110 14:33:36.996101 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0119634 (* 1 = 0.0119634 loss)
I0110 14:33:36.996104 10246 solver.cpp:464] Iteration 4200, lr = 0.001
I0110 14:33:45.748672 10246 solver.cpp:189] Iteration 4300, loss = 0.0917156
I0110 14:33:45.748692 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0540782 (* 1 = 0.0540782 loss)
I0110 14:33:45.748695 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0376374 (* 1 = 0.0376374 loss)
I0110 14:33:45.748698 10246 solver.cpp:464] Iteration 4300, lr = 0.001
I0110 14:33:54.209616 10246 solver.cpp:189] Iteration 4400, loss = 0.175851
I0110 14:33:54.209635 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0620717 (* 1 = 0.0620717 loss)
I0110 14:33:54.209638 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.113779 (* 1 = 0.113779 loss)
I0110 14:33:54.209641 10246 solver.cpp:464] Iteration 4400, lr = 0.001
I0110 14:34:02.680338 10246 solver.cpp:189] Iteration 4500, loss = 0.06273
I0110 14:34:02.680356 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0295421 (* 1 = 0.0295421 loss)
I0110 14:34:02.680361 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0331879 (* 1 = 0.0331879 loss)
I0110 14:34:02.680363 10246 solver.cpp:464] Iteration 4500, lr = 0.001
I0110 14:34:11.150624 10246 solver.cpp:189] Iteration 4600, loss = 0.0219744
I0110 14:34:11.150643 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0111436 (* 1 = 0.0111436 loss)
I0110 14:34:11.150647 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0108308 (* 1 = 0.0108308 loss)
I0110 14:34:11.150650 10246 solver.cpp:464] Iteration 4600, lr = 0.001
I0110 14:34:19.646478 10246 solver.cpp:189] Iteration 4700, loss = 0.20021
I0110 14:34:19.646497 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0539445 (* 1 = 0.0539445 loss)
I0110 14:34:19.646502 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.146265 (* 1 = 0.146265 loss)
I0110 14:34:19.646504 10246 solver.cpp:464] Iteration 4700, lr = 0.001
I0110 14:34:28.158103 10246 solver.cpp:189] Iteration 4800, loss = 0.093742
I0110 14:34:28.158123 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0289957 (* 1 = 0.0289957 loss)
I0110 14:34:28.158126 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0647463 (* 1 = 0.0647463 loss)
I0110 14:34:28.158130 10246 solver.cpp:464] Iteration 4800, lr = 0.001
I0110 14:34:36.624346 10246 solver.cpp:189] Iteration 4900, loss = 0.482763
I0110 14:34:36.624364 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.177932 (* 1 = 0.177932 loss)
I0110 14:34:36.624368 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.304831 (* 1 = 0.304831 loss)
I0110 14:34:36.624372 10246 solver.cpp:464] Iteration 4900, lr = 0.001
speed: 0.087s / iter
I0110 14:34:45.377204 10246 solver.cpp:189] Iteration 5000, loss = 0.114618
I0110 14:34:45.377223 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0992272 (* 1 = 0.0992272 loss)
I0110 14:34:45.377226 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0153904 (* 1 = 0.0153904 loss)
I0110 14:34:45.377229 10246 solver.cpp:464] Iteration 5000, lr = 0.001
I0110 14:34:53.927008 10246 solver.cpp:189] Iteration 5100, loss = 0.117183
I0110 14:34:53.927026 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0438436 (* 1 = 0.0438436 loss)
I0110 14:34:53.927031 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0733397 (* 1 = 0.0733397 loss)
I0110 14:34:53.927033 10246 solver.cpp:464] Iteration 5100, lr = 0.001
I0110 14:35:02.454566 10246 solver.cpp:189] Iteration 5200, loss = 0.231807
I0110 14:35:02.454584 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.159855 (* 1 = 0.159855 loss)
I0110 14:35:02.454589 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0719525 (* 1 = 0.0719525 loss)
I0110 14:35:02.454592 10246 solver.cpp:464] Iteration 5200, lr = 0.001
I0110 14:35:10.979113 10246 solver.cpp:189] Iteration 5300, loss = 0.1512
I0110 14:35:10.979132 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0945665 (* 1 = 0.0945665 loss)
I0110 14:35:10.979136 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0566339 (* 1 = 0.0566339 loss)
I0110 14:35:10.979140 10246 solver.cpp:464] Iteration 5300, lr = 0.001
I0110 14:35:19.519927 10246 solver.cpp:189] Iteration 5400, loss = 0.296124
I0110 14:35:19.519944 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.176233 (* 1 = 0.176233 loss)
I0110 14:35:19.519948 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.119891 (* 1 = 0.119891 loss)
I0110 14:35:19.519951 10246 solver.cpp:464] Iteration 5400, lr = 0.001
I0110 14:35:27.991266 10246 solver.cpp:189] Iteration 5500, loss = 0.0292893
I0110 14:35:27.991284 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000509091 (* 1 = 0.000509091 loss)
I0110 14:35:27.991288 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0287802 (* 1 = 0.0287802 loss)
I0110 14:35:27.991291 10246 solver.cpp:464] Iteration 5500, lr = 0.001
I0110 14:35:36.699815 10246 solver.cpp:189] Iteration 5600, loss = 0.0911757
I0110 14:35:36.699834 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0185558 (* 1 = 0.0185558 loss)
I0110 14:35:36.699838 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0726199 (* 1 = 0.0726199 loss)
I0110 14:35:36.699841 10246 solver.cpp:464] Iteration 5600, lr = 0.001
I0110 14:35:45.370162 10246 solver.cpp:189] Iteration 5700, loss = 0.26834
I0110 14:35:45.370180 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.219968 (* 1 = 0.219968 loss)
I0110 14:35:45.370184 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0483727 (* 1 = 0.0483727 loss)
I0110 14:35:45.370187 10246 solver.cpp:464] Iteration 5700, lr = 0.001
I0110 14:35:54.008702 10246 solver.cpp:189] Iteration 5800, loss = 0.331562
I0110 14:35:54.008721 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0883798 (* 1 = 0.0883798 loss)
I0110 14:35:54.008724 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.243182 (* 1 = 0.243182 loss)
I0110 14:35:54.008728 10246 solver.cpp:464] Iteration 5800, lr = 0.001
I0110 14:36:02.893759 10246 solver.cpp:189] Iteration 5900, loss = 0.303735
I0110 14:36:02.893780 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.219419 (* 1 = 0.219419 loss)
I0110 14:36:02.893784 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0843159 (* 1 = 0.0843159 loss)
I0110 14:36:02.893788 10246 solver.cpp:464] Iteration 5900, lr = 0.001
speed: 0.087s / iter
I0110 14:36:11.762384 10246 solver.cpp:189] Iteration 6000, loss = 0.00717976
I0110 14:36:11.762403 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00120609 (* 1 = 0.00120609 loss)
I0110 14:36:11.762406 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00597367 (* 1 = 0.00597367 loss)
I0110 14:36:11.762409 10246 solver.cpp:464] Iteration 6000, lr = 0.001
I0110 14:36:20.614251 10246 solver.cpp:189] Iteration 6100, loss = 0.12957
I0110 14:36:20.614272 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0437763 (* 1 = 0.0437763 loss)
I0110 14:36:20.614277 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0857939 (* 1 = 0.0857939 loss)
I0110 14:36:20.614281 10246 solver.cpp:464] Iteration 6100, lr = 0.001
I0110 14:36:29.227504 10246 solver.cpp:189] Iteration 6200, loss = 0.179221
I0110 14:36:29.227521 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0600362 (* 1 = 0.0600362 loss)
I0110 14:36:29.227525 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.119185 (* 1 = 0.119185 loss)
I0110 14:36:29.227529 10246 solver.cpp:464] Iteration 6200, lr = 0.001
I0110 14:36:37.815541 10246 solver.cpp:189] Iteration 6300, loss = 0.0219184
I0110 14:36:37.815558 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00323667 (* 1 = 0.00323667 loss)
I0110 14:36:37.815562 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0186817 (* 1 = 0.0186817 loss)
I0110 14:36:37.815565 10246 solver.cpp:464] Iteration 6300, lr = 0.001
I0110 14:36:46.538724 10246 solver.cpp:189] Iteration 6400, loss = 0.174417
I0110 14:36:46.538741 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.10415 (* 1 = 0.10415 loss)
I0110 14:36:46.538745 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0702671 (* 1 = 0.0702671 loss)
I0110 14:36:46.538748 10246 solver.cpp:464] Iteration 6400, lr = 0.001
I0110 14:36:55.126698 10246 solver.cpp:189] Iteration 6500, loss = 0.0900545
I0110 14:36:55.126715 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0452835 (* 1 = 0.0452835 loss)
I0110 14:36:55.126719 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.044771 (* 1 = 0.044771 loss)
I0110 14:36:55.126723 10246 solver.cpp:464] Iteration 6500, lr = 0.001
I0110 14:37:03.758255 10246 solver.cpp:189] Iteration 6600, loss = 0.0295823
I0110 14:37:03.758271 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0103628 (* 1 = 0.0103628 loss)
I0110 14:37:03.758275 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0192196 (* 1 = 0.0192196 loss)
I0110 14:37:03.758278 10246 solver.cpp:464] Iteration 6600, lr = 0.001
I0110 14:37:12.205842 10246 solver.cpp:189] Iteration 6700, loss = 0.0353263
I0110 14:37:12.205858 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00942149 (* 1 = 0.00942149 loss)
I0110 14:37:12.205862 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0259048 (* 1 = 0.0259048 loss)
I0110 14:37:12.205865 10246 solver.cpp:464] Iteration 6700, lr = 0.001
I0110 14:37:20.710319 10246 solver.cpp:189] Iteration 6800, loss = 0.248968
I0110 14:37:20.710338 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.131484 (* 1 = 0.131484 loss)
I0110 14:37:20.710343 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.117484 (* 1 = 0.117484 loss)
I0110 14:37:20.710347 10246 solver.cpp:464] Iteration 6800, lr = 0.001
I0110 14:37:29.305860 10246 solver.cpp:189] Iteration 6900, loss = 0.0136096
I0110 14:37:29.305881 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000637272 (* 1 = 0.000637272 loss)
I0110 14:37:29.305886 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0129724 (* 1 = 0.0129724 loss)
I0110 14:37:29.305891 10246 solver.cpp:464] Iteration 6900, lr = 0.001
speed: 0.087s / iter
I0110 14:37:38.092654 10246 solver.cpp:189] Iteration 7000, loss = 0.196004
I0110 14:37:38.092674 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.125995 (* 1 = 0.125995 loss)
I0110 14:37:38.092677 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0700089 (* 1 = 0.0700089 loss)
I0110 14:37:38.092680 10246 solver.cpp:464] Iteration 7000, lr = 0.001
I0110 14:37:47.136853 10246 solver.cpp:189] Iteration 7100, loss = 0.298666
I0110 14:37:47.136871 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.112025 (* 1 = 0.112025 loss)
I0110 14:37:47.136875 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.186642 (* 1 = 0.186642 loss)
I0110 14:37:47.136878 10246 solver.cpp:464] Iteration 7100, lr = 0.001
I0110 14:37:55.913321 10246 solver.cpp:189] Iteration 7200, loss = 0.136208
I0110 14:37:55.913339 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.100832 (* 1 = 0.100832 loss)
I0110 14:37:55.913343 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0353762 (* 1 = 0.0353762 loss)
I0110 14:37:55.913347 10246 solver.cpp:464] Iteration 7200, lr = 0.001
I0110 14:38:04.439157 10246 solver.cpp:189] Iteration 7300, loss = 0.194808
I0110 14:38:04.439174 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.166102 (* 1 = 0.166102 loss)
I0110 14:38:04.439178 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0287055 (* 1 = 0.0287055 loss)
I0110 14:38:04.439182 10246 solver.cpp:464] Iteration 7300, lr = 0.001
I0110 14:38:13.058168 10246 solver.cpp:189] Iteration 7400, loss = 0.204123
I0110 14:38:13.058185 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.063984 (* 1 = 0.063984 loss)
I0110 14:38:13.058189 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.140139 (* 1 = 0.140139 loss)
I0110 14:38:13.058193 10246 solver.cpp:464] Iteration 7400, lr = 0.001
I0110 14:38:21.517782 10246 solver.cpp:189] Iteration 7500, loss = 0.00689396
I0110 14:38:21.517801 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000863026 (* 1 = 0.000863026 loss)
I0110 14:38:21.517804 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00603093 (* 1 = 0.00603093 loss)
I0110 14:38:21.517807 10246 solver.cpp:464] Iteration 7500, lr = 0.001
I0110 14:38:30.114212 10246 solver.cpp:189] Iteration 7600, loss = 0.00790191
I0110 14:38:30.114229 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00247941 (* 1 = 0.00247941 loss)
I0110 14:38:30.114233 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0054225 (* 1 = 0.0054225 loss)
I0110 14:38:30.114236 10246 solver.cpp:464] Iteration 7600, lr = 0.001
I0110 14:38:38.671239 10246 solver.cpp:189] Iteration 7700, loss = 0.0128307
I0110 14:38:38.671258 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00267605 (* 1 = 0.00267605 loss)
I0110 14:38:38.671262 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0101547 (* 1 = 0.0101547 loss)
I0110 14:38:38.671265 10246 solver.cpp:464] Iteration 7700, lr = 0.001
I0110 14:38:47.328953 10246 solver.cpp:189] Iteration 7800, loss = 0.0528501
I0110 14:38:47.328971 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0025285 (* 1 = 0.0025285 loss)
I0110 14:38:47.328975 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0503216 (* 1 = 0.0503216 loss)
I0110 14:38:47.328979 10246 solver.cpp:464] Iteration 7800, lr = 0.001
I0110 14:38:55.780649 10246 solver.cpp:189] Iteration 7900, loss = 0.038757
I0110 14:38:55.780666 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0291856 (* 1 = 0.0291856 loss)
I0110 14:38:55.780670 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00957138 (* 1 = 0.00957138 loss)
I0110 14:38:55.780674 10246 solver.cpp:464] Iteration 7900, lr = 0.001
speed: 0.087s / iter
I0110 14:39:04.350430 10246 solver.cpp:189] Iteration 8000, loss = 0.101119
I0110 14:39:04.350448 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0554031 (* 1 = 0.0554031 loss)
I0110 14:39:04.350452 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.045716 (* 1 = 0.045716 loss)
I0110 14:39:04.350455 10246 solver.cpp:464] Iteration 8000, lr = 0.001
I0110 14:39:13.160588 10246 solver.cpp:189] Iteration 8100, loss = 0.00903931
I0110 14:39:13.160606 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000394718 (* 1 = 0.000394718 loss)
I0110 14:39:13.160610 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00864459 (* 1 = 0.00864459 loss)
I0110 14:39:13.160614 10246 solver.cpp:464] Iteration 8100, lr = 0.001
I0110 14:39:21.726629 10246 solver.cpp:189] Iteration 8200, loss = 0.0245916
I0110 14:39:21.726649 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00943853 (* 1 = 0.00943853 loss)
I0110 14:39:21.726655 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0151531 (* 1 = 0.0151531 loss)
I0110 14:39:21.726657 10246 solver.cpp:464] Iteration 8200, lr = 0.001
I0110 14:39:30.296144 10246 solver.cpp:189] Iteration 8300, loss = 0.0301673
I0110 14:39:30.296162 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0174509 (* 1 = 0.0174509 loss)
I0110 14:39:30.296166 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0127165 (* 1 = 0.0127165 loss)
I0110 14:39:30.296169 10246 solver.cpp:464] Iteration 8300, lr = 0.001
I0110 14:39:39.106228 10246 solver.cpp:189] Iteration 8400, loss = 0.0367723
I0110 14:39:39.106246 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0205062 (* 1 = 0.0205062 loss)
I0110 14:39:39.106251 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0162661 (* 1 = 0.0162661 loss)
I0110 14:39:39.106254 10246 solver.cpp:464] Iteration 8400, lr = 0.001
I0110 14:39:47.838598 10246 solver.cpp:189] Iteration 8500, loss = 0.0882564
I0110 14:39:47.838614 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0102323 (* 1 = 0.0102323 loss)
I0110 14:39:47.838618 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0780241 (* 1 = 0.0780241 loss)
I0110 14:39:47.838621 10246 solver.cpp:464] Iteration 8500, lr = 0.001
I0110 14:39:56.356555 10246 solver.cpp:189] Iteration 8600, loss = 0.0565087
I0110 14:39:56.356573 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0168831 (* 1 = 0.0168831 loss)
I0110 14:39:56.356577 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0396256 (* 1 = 0.0396256 loss)
I0110 14:39:56.356580 10246 solver.cpp:464] Iteration 8600, lr = 0.001
I0110 14:40:04.942538 10246 solver.cpp:189] Iteration 8700, loss = 0.0278772
I0110 14:40:04.942555 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00341078 (* 1 = 0.00341078 loss)
I0110 14:40:04.942559 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0244664 (* 1 = 0.0244664 loss)
I0110 14:40:04.942564 10246 solver.cpp:464] Iteration 8700, lr = 0.001
I0110 14:40:13.437579 10246 solver.cpp:189] Iteration 8800, loss = 0.125535
I0110 14:40:13.437600 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.049463 (* 1 = 0.049463 loss)
I0110 14:40:13.437605 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0760723 (* 1 = 0.0760723 loss)
I0110 14:40:13.437610 10246 solver.cpp:464] Iteration 8800, lr = 0.001
I0110 14:40:21.923090 10246 solver.cpp:189] Iteration 8900, loss = 0.0838228
I0110 14:40:21.923108 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0565605 (* 1 = 0.0565605 loss)
I0110 14:40:21.923112 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0272623 (* 1 = 0.0272623 loss)
I0110 14:40:21.923115 10246 solver.cpp:464] Iteration 8900, lr = 0.001
speed: 0.087s / iter
I0110 14:40:30.545284 10246 solver.cpp:189] Iteration 9000, loss = 0.0406882
I0110 14:40:30.545301 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00390048 (* 1 = 0.00390048 loss)
I0110 14:40:30.545305 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0367877 (* 1 = 0.0367877 loss)
I0110 14:40:30.545308 10246 solver.cpp:464] Iteration 9000, lr = 0.001
I0110 14:40:39.193485 10246 solver.cpp:189] Iteration 9100, loss = 0.0977626
I0110 14:40:39.193503 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0561566 (* 1 = 0.0561566 loss)
I0110 14:40:39.193507 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.041606 (* 1 = 0.041606 loss)
I0110 14:40:39.193511 10246 solver.cpp:464] Iteration 9100, lr = 0.001
I0110 14:40:47.783246 10246 solver.cpp:189] Iteration 9200, loss = 0.16317
I0110 14:40:47.783264 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.102143 (* 1 = 0.102143 loss)
I0110 14:40:47.783268 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0610274 (* 1 = 0.0610274 loss)
I0110 14:40:47.783272 10246 solver.cpp:464] Iteration 9200, lr = 0.001
I0110 14:40:56.284121 10246 solver.cpp:189] Iteration 9300, loss = 0.250935
I0110 14:40:56.284138 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0834077 (* 1 = 0.0834077 loss)
I0110 14:40:56.284142 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.167527 (* 1 = 0.167527 loss)
I0110 14:40:56.284145 10246 solver.cpp:464] Iteration 9300, lr = 0.001
I0110 14:41:04.816365 10246 solver.cpp:189] Iteration 9400, loss = 0.115036
I0110 14:41:04.816385 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0489354 (* 1 = 0.0489354 loss)
I0110 14:41:04.816390 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0661002 (* 1 = 0.0661002 loss)
I0110 14:41:04.816395 10246 solver.cpp:464] Iteration 9400, lr = 0.001
I0110 14:41:13.450011 10246 solver.cpp:189] Iteration 9500, loss = 0.185083
I0110 14:41:13.450029 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.132809 (* 1 = 0.132809 loss)
I0110 14:41:13.450033 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.052274 (* 1 = 0.052274 loss)
I0110 14:41:13.450037 10246 solver.cpp:464] Iteration 9500, lr = 0.001
I0110 14:41:21.979802 10246 solver.cpp:189] Iteration 9600, loss = 0.0536579
I0110 14:41:21.979820 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0141814 (* 1 = 0.0141814 loss)
I0110 14:41:21.979823 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0394765 (* 1 = 0.0394765 loss)
I0110 14:41:21.979827 10246 solver.cpp:464] Iteration 9600, lr = 0.001
I0110 14:41:30.492779 10246 solver.cpp:189] Iteration 9700, loss = 0.0728825
I0110 14:41:30.492796 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0210639 (* 1 = 0.0210639 loss)
I0110 14:41:30.492800 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0518186 (* 1 = 0.0518186 loss)
I0110 14:41:30.492804 10246 solver.cpp:464] Iteration 9700, lr = 0.001
I0110 14:41:38.985309 10246 solver.cpp:189] Iteration 9800, loss = 0.0644184
I0110 14:41:38.985327 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0427867 (* 1 = 0.0427867 loss)
I0110 14:41:38.985330 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0216318 (* 1 = 0.0216318 loss)
I0110 14:41:38.985333 10246 solver.cpp:464] Iteration 9800, lr = 0.001
I0110 14:41:47.485981 10246 solver.cpp:189] Iteration 9900, loss = 0.0045419
I0110 14:41:47.485998 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000838822 (* 1 = 0.000838822 loss)
I0110 14:41:47.486002 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00370308 (* 1 = 0.00370308 loss)
I0110 14:41:47.486006 10246 solver.cpp:464] Iteration 9900, lr = 0.001
speed: 0.087s / iter
Wrote snapshot to: /home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/output/IR_Reg/train/vgg_cnn_m_1024_fast_rcnn_iter_10000.caffemodel
I0110 14:41:57.056917 10246 solver.cpp:189] Iteration 10000, loss = 0.0143323
I0110 14:41:57.056936 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00192338 (* 1 = 0.00192338 loss)
I0110 14:41:57.056939 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0124089 (* 1 = 0.0124089 loss)
I0110 14:41:57.056942 10246 solver.cpp:464] Iteration 10000, lr = 0.001
I0110 14:42:05.582983 10246 solver.cpp:189] Iteration 10100, loss = 0.00756143
I0110 14:42:05.583000 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00399448 (* 1 = 0.00399448 loss)
I0110 14:42:05.583003 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00356695 (* 1 = 0.00356695 loss)
I0110 14:42:05.583008 10246 solver.cpp:464] Iteration 10100, lr = 0.001
I0110 14:42:14.318032 10246 solver.cpp:189] Iteration 10200, loss = 0.0131619
I0110 14:42:14.318053 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00385098 (* 1 = 0.00385098 loss)
I0110 14:42:14.318058 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00931093 (* 1 = 0.00931093 loss)
I0110 14:42:14.318061 10246 solver.cpp:464] Iteration 10200, lr = 0.001
I0110 14:42:22.919184 10246 solver.cpp:189] Iteration 10300, loss = 0.16372
I0110 14:42:22.919203 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0749644 (* 1 = 0.0749644 loss)
I0110 14:42:22.919206 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0887557 (* 1 = 0.0887557 loss)
I0110 14:42:22.919209 10246 solver.cpp:464] Iteration 10300, lr = 0.001
I0110 14:42:31.732538 10246 solver.cpp:189] Iteration 10400, loss = 0.0211583
I0110 14:42:31.732556 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00838754 (* 1 = 0.00838754 loss)
I0110 14:42:31.732560 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0127708 (* 1 = 0.0127708 loss)
I0110 14:42:31.732563 10246 solver.cpp:464] Iteration 10400, lr = 0.001
I0110 14:42:40.435791 10246 solver.cpp:189] Iteration 10500, loss = 0.0268088
I0110 14:42:40.435808 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0162677 (* 1 = 0.0162677 loss)
I0110 14:42:40.435812 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0105411 (* 1 = 0.0105411 loss)
I0110 14:42:40.435816 10246 solver.cpp:464] Iteration 10500, lr = 0.001
I0110 14:42:49.054193 10246 solver.cpp:189] Iteration 10600, loss = 0.00520915
I0110 14:42:49.054211 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00426054 (* 1 = 0.00426054 loss)
I0110 14:42:49.054216 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.000948609 (* 1 = 0.000948609 loss)
I0110 14:42:49.054220 10246 solver.cpp:464] Iteration 10600, lr = 0.001
I0110 14:42:57.726320 10246 solver.cpp:189] Iteration 10700, loss = 0.0595102
I0110 14:42:57.726336 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0203547 (* 1 = 0.0203547 loss)
I0110 14:42:57.726341 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0391555 (* 1 = 0.0391555 loss)
I0110 14:42:57.726343 10246 solver.cpp:464] Iteration 10700, lr = 0.001
I0110 14:43:06.284780 10246 solver.cpp:189] Iteration 10800, loss = 0.145169
I0110 14:43:06.284799 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0548776 (* 1 = 0.0548776 loss)
I0110 14:43:06.284803 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0902916 (* 1 = 0.0902916 loss)
I0110 14:43:06.284806 10246 solver.cpp:464] Iteration 10800, lr = 0.001
I0110 14:43:15.011042 10246 solver.cpp:189] Iteration 10900, loss = 0.421798
I0110 14:43:15.011060 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.232337 (* 1 = 0.232337 loss)
I0110 14:43:15.011065 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.189461 (* 1 = 0.189461 loss)
I0110 14:43:15.011067 10246 solver.cpp:464] Iteration 10900, lr = 0.001
speed: 0.087s / iter
I0110 14:43:23.659518 10246 solver.cpp:189] Iteration 11000, loss = 0.0498523
I0110 14:43:23.659538 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0194064 (* 1 = 0.0194064 loss)
I0110 14:43:23.659541 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0304459 (* 1 = 0.0304459 loss)
I0110 14:43:23.659544 10246 solver.cpp:464] Iteration 11000, lr = 0.001
I0110 14:43:32.267915 10246 solver.cpp:189] Iteration 11100, loss = 0.00350656
I0110 14:43:32.267933 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00172755 (* 1 = 0.00172755 loss)
I0110 14:43:32.267937 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00177901 (* 1 = 0.00177901 loss)
I0110 14:43:32.267940 10246 solver.cpp:464] Iteration 11100, lr = 0.001
I0110 14:43:40.813246 10246 solver.cpp:189] Iteration 11200, loss = 0.126714
I0110 14:43:40.813262 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0872552 (* 1 = 0.0872552 loss)
I0110 14:43:40.813266 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.039459 (* 1 = 0.039459 loss)
I0110 14:43:40.813271 10246 solver.cpp:464] Iteration 11200, lr = 0.001
I0110 14:43:49.493969 10246 solver.cpp:189] Iteration 11300, loss = 0.084019
I0110 14:43:49.493988 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.016775 (* 1 = 0.016775 loss)
I0110 14:43:49.493991 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.067244 (* 1 = 0.067244 loss)
I0110 14:43:49.493994 10246 solver.cpp:464] Iteration 11300, lr = 0.001
I0110 14:43:58.024873 10246 solver.cpp:189] Iteration 11400, loss = 0.0182862
I0110 14:43:58.024890 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000465824 (* 1 = 0.000465824 loss)
I0110 14:43:58.024894 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0178203 (* 1 = 0.0178203 loss)
I0110 14:43:58.024897 10246 solver.cpp:464] Iteration 11400, lr = 0.001
I0110 14:44:06.592061 10246 solver.cpp:189] Iteration 11500, loss = 0.00420656
I0110 14:44:06.592079 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000285503 (* 1 = 0.000285503 loss)
I0110 14:44:06.592083 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00392106 (* 1 = 0.00392106 loss)
I0110 14:44:06.592087 10246 solver.cpp:464] Iteration 11500, lr = 0.001
I0110 14:44:15.082967 10246 solver.cpp:189] Iteration 11600, loss = 0.183012
I0110 14:44:15.082984 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.134006 (* 1 = 0.134006 loss)
I0110 14:44:15.082988 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0490055 (* 1 = 0.0490055 loss)
I0110 14:44:15.082993 10246 solver.cpp:464] Iteration 11600, lr = 0.001
I0110 14:44:23.575371 10246 solver.cpp:189] Iteration 11700, loss = 0.0756974
I0110 14:44:23.575388 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.024686 (* 1 = 0.024686 loss)
I0110 14:44:23.575392 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0510114 (* 1 = 0.0510114 loss)
I0110 14:44:23.575395 10246 solver.cpp:464] Iteration 11700, lr = 0.001
I0110 14:44:32.157018 10246 solver.cpp:189] Iteration 11800, loss = 0.013715
I0110 14:44:32.157037 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00515097 (* 1 = 0.00515097 loss)
I0110 14:44:32.157039 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00856401 (* 1 = 0.00856401 loss)
I0110 14:44:32.157043 10246 solver.cpp:464] Iteration 11800, lr = 0.001
I0110 14:44:40.691264 10246 solver.cpp:189] Iteration 11900, loss = 0.180841
I0110 14:44:40.691282 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.116941 (* 1 = 0.116941 loss)
I0110 14:44:40.691285 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0639002 (* 1 = 0.0639002 loss)
I0110 14:44:40.691288 10246 solver.cpp:464] Iteration 11900, lr = 0.001
speed: 0.087s / iter
I0110 14:44:49.242785 10246 solver.cpp:189] Iteration 12000, loss = 0.0417837
I0110 14:44:49.242804 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0118602 (* 1 = 0.0118602 loss)
I0110 14:44:49.242806 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0299235 (* 1 = 0.0299235 loss)
I0110 14:44:49.242810 10246 solver.cpp:464] Iteration 12000, lr = 0.001
I0110 14:44:57.758875 10246 solver.cpp:189] Iteration 12100, loss = 0.0563167
I0110 14:44:57.758896 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0109022 (* 1 = 0.0109022 loss)
I0110 14:44:57.758900 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0454144 (* 1 = 0.0454144 loss)
I0110 14:44:57.758904 10246 solver.cpp:464] Iteration 12100, lr = 0.001
I0110 14:45:06.269168 10246 solver.cpp:189] Iteration 12200, loss = 0.0948887
I0110 14:45:06.269186 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0498124 (* 1 = 0.0498124 loss)
I0110 14:45:06.269189 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0450764 (* 1 = 0.0450764 loss)
I0110 14:45:06.269193 10246 solver.cpp:464] Iteration 12200, lr = 0.001
I0110 14:45:14.965867 10246 solver.cpp:189] Iteration 12300, loss = 0.00332673
I0110 14:45:14.965884 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00133465 (* 1 = 0.00133465 loss)
I0110 14:45:14.965888 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00199208 (* 1 = 0.00199208 loss)
I0110 14:45:14.965891 10246 solver.cpp:464] Iteration 12300, lr = 0.001
I0110 14:45:23.621835 10246 solver.cpp:189] Iteration 12400, loss = 0.149579
I0110 14:45:23.621856 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0370561 (* 1 = 0.0370561 loss)
I0110 14:45:23.621861 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.112523 (* 1 = 0.112523 loss)
I0110 14:45:23.621865 10246 solver.cpp:464] Iteration 12400, lr = 0.001
I0110 14:45:32.261142 10246 solver.cpp:189] Iteration 12500, loss = 0.0154217
I0110 14:45:32.261160 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00659543 (* 1 = 0.00659543 loss)
I0110 14:45:32.261164 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0088263 (* 1 = 0.0088263 loss)
I0110 14:45:32.261168 10246 solver.cpp:464] Iteration 12500, lr = 0.001
I0110 14:45:40.826493 10246 solver.cpp:189] Iteration 12600, loss = 0.16796
I0110 14:45:40.826511 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0738675 (* 1 = 0.0738675 loss)
I0110 14:45:40.826515 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.094092 (* 1 = 0.094092 loss)
I0110 14:45:40.826519 10246 solver.cpp:464] Iteration 12600, lr = 0.001
I0110 14:45:49.534867 10246 solver.cpp:189] Iteration 12700, loss = 0.0263909
I0110 14:45:49.534884 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0116269 (* 1 = 0.0116269 loss)
I0110 14:45:49.534888 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.014764 (* 1 = 0.014764 loss)
I0110 14:45:49.534893 10246 solver.cpp:464] Iteration 12700, lr = 0.001
I0110 14:45:58.157269 10246 solver.cpp:189] Iteration 12800, loss = 0.0598099
I0110 14:45:58.157285 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0282631 (* 1 = 0.0282631 loss)
I0110 14:45:58.157289 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0315467 (* 1 = 0.0315467 loss)
I0110 14:45:58.157292 10246 solver.cpp:464] Iteration 12800, lr = 0.001
I0110 14:46:06.801481 10246 solver.cpp:189] Iteration 12900, loss = 0.0310933
I0110 14:46:06.801501 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000400586 (* 1 = 0.000400586 loss)
I0110 14:46:06.801506 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0306927 (* 1 = 0.0306927 loss)
I0110 14:46:06.801509 10246 solver.cpp:464] Iteration 12900, lr = 0.001
speed: 0.087s / iter
I0110 14:46:15.391994 10246 solver.cpp:189] Iteration 13000, loss = 0.127577
I0110 14:46:15.392014 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0461261 (* 1 = 0.0461261 loss)
I0110 14:46:15.392019 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0814508 (* 1 = 0.0814508 loss)
I0110 14:46:15.392022 10246 solver.cpp:464] Iteration 13000, lr = 0.001
I0110 14:46:23.957854 10246 solver.cpp:189] Iteration 13100, loss = 0.0111125
I0110 14:46:23.957872 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00113149 (* 1 = 0.00113149 loss)
I0110 14:46:23.957876 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00998099 (* 1 = 0.00998099 loss)
I0110 14:46:23.957880 10246 solver.cpp:464] Iteration 13100, lr = 0.001
I0110 14:46:32.466568 10246 solver.cpp:189] Iteration 13200, loss = 0.323012
I0110 14:46:32.466588 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.187019 (* 1 = 0.187019 loss)
I0110 14:46:32.466590 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.135993 (* 1 = 0.135993 loss)
I0110 14:46:32.466594 10246 solver.cpp:464] Iteration 13200, lr = 0.001
I0110 14:46:41.147861 10246 solver.cpp:189] Iteration 13300, loss = 0.0700596
I0110 14:46:41.147881 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00298164 (* 1 = 0.00298164 loss)
I0110 14:46:41.147886 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.067078 (* 1 = 0.067078 loss)
I0110 14:46:41.147889 10246 solver.cpp:464] Iteration 13300, lr = 0.001
I0110 14:46:49.659112 10246 solver.cpp:189] Iteration 13400, loss = 0.0156154
I0110 14:46:49.659129 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00822604 (* 1 = 0.00822604 loss)
I0110 14:46:49.659133 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00738934 (* 1 = 0.00738934 loss)
I0110 14:46:49.659137 10246 solver.cpp:464] Iteration 13400, lr = 0.001
I0110 14:46:58.292383 10246 solver.cpp:189] Iteration 13500, loss = 0.0328641
I0110 14:46:58.292404 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0200918 (* 1 = 0.0200918 loss)
I0110 14:46:58.292408 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0127723 (* 1 = 0.0127723 loss)
I0110 14:46:58.292412 10246 solver.cpp:464] Iteration 13500, lr = 0.001
I0110 14:47:06.921396 10246 solver.cpp:189] Iteration 13600, loss = 0.14939
I0110 14:47:06.921416 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.051464 (* 1 = 0.051464 loss)
I0110 14:47:06.921419 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0979265 (* 1 = 0.0979265 loss)
I0110 14:47:06.921423 10246 solver.cpp:464] Iteration 13600, lr = 0.001
I0110 14:47:15.614696 10246 solver.cpp:189] Iteration 13700, loss = 0.115661
I0110 14:47:15.614713 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00376534 (* 1 = 0.00376534 loss)
I0110 14:47:15.614718 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.111895 (* 1 = 0.111895 loss)
I0110 14:47:15.614722 10246 solver.cpp:464] Iteration 13700, lr = 0.001
I0110 14:47:24.399161 10246 solver.cpp:189] Iteration 13800, loss = 0.158183
I0110 14:47:24.399179 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.049344 (* 1 = 0.049344 loss)
I0110 14:47:24.399183 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.108839 (* 1 = 0.108839 loss)
I0110 14:47:24.399186 10246 solver.cpp:464] Iteration 13800, lr = 0.001
I0110 14:47:33.233629 10246 solver.cpp:189] Iteration 13900, loss = 0.176647
I0110 14:47:33.233650 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0914898 (* 1 = 0.0914898 loss)
I0110 14:47:33.233655 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0851574 (* 1 = 0.0851574 loss)
I0110 14:47:33.233659 10246 solver.cpp:464] Iteration 13900, lr = 0.001
speed: 0.087s / iter
I0110 14:47:42.017693 10246 solver.cpp:189] Iteration 14000, loss = 0.0759863
I0110 14:47:42.017711 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0340826 (* 1 = 0.0340826 loss)
I0110 14:47:42.017714 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0419037 (* 1 = 0.0419037 loss)
I0110 14:47:42.017719 10246 solver.cpp:464] Iteration 14000, lr = 0.001
I0110 14:47:50.666271 10246 solver.cpp:189] Iteration 14100, loss = 0.102129
I0110 14:47:50.666291 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0535829 (* 1 = 0.0535829 loss)
I0110 14:47:50.666297 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0485465 (* 1 = 0.0485465 loss)
I0110 14:47:50.666301 10246 solver.cpp:464] Iteration 14100, lr = 0.001
I0110 14:47:59.498479 10246 solver.cpp:189] Iteration 14200, loss = 0.00750901
I0110 14:47:59.498497 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00185685 (* 1 = 0.00185685 loss)
I0110 14:47:59.498500 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00565216 (* 1 = 0.00565216 loss)
I0110 14:47:59.498504 10246 solver.cpp:464] Iteration 14200, lr = 0.001
I0110 14:48:08.373703 10246 solver.cpp:189] Iteration 14300, loss = 0.1166
I0110 14:48:08.373721 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.050247 (* 1 = 0.050247 loss)
I0110 14:48:08.373724 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0663526 (* 1 = 0.0663526 loss)
I0110 14:48:08.373728 10246 solver.cpp:464] Iteration 14300, lr = 0.001
I0110 14:48:17.087579 10246 solver.cpp:189] Iteration 14400, loss = 0.0705843
I0110 14:48:17.087596 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0322569 (* 1 = 0.0322569 loss)
I0110 14:48:17.087600 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0383274 (* 1 = 0.0383274 loss)
I0110 14:48:17.087604 10246 solver.cpp:464] Iteration 14400, lr = 0.001
I0110 14:48:25.710551 10246 solver.cpp:189] Iteration 14500, loss = 0.141097
I0110 14:48:25.710569 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0772869 (* 1 = 0.0772869 loss)
I0110 14:48:25.710573 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0638103 (* 1 = 0.0638103 loss)
I0110 14:48:25.710577 10246 solver.cpp:464] Iteration 14500, lr = 0.001
I0110 14:48:34.736057 10246 solver.cpp:189] Iteration 14600, loss = 0.0669104
I0110 14:48:34.736075 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00119041 (* 1 = 0.00119041 loss)
I0110 14:48:34.736079 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.06572 (* 1 = 0.06572 loss)
I0110 14:48:34.736083 10246 solver.cpp:464] Iteration 14600, lr = 0.001
I0110 14:48:43.768910 10246 solver.cpp:189] Iteration 14700, loss = 0.172101
I0110 14:48:43.768931 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0651157 (* 1 = 0.0651157 loss)
I0110 14:48:43.768936 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.106986 (* 1 = 0.106986 loss)
I0110 14:48:43.768939 10246 solver.cpp:464] Iteration 14700, lr = 0.001
I0110 14:48:52.825762 10246 solver.cpp:189] Iteration 14800, loss = 0.189866
I0110 14:48:52.825779 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.127026 (* 1 = 0.127026 loss)
I0110 14:48:52.825783 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0628399 (* 1 = 0.0628399 loss)
I0110 14:48:52.825786 10246 solver.cpp:464] Iteration 14800, lr = 0.001
I0110 14:49:01.960054 10246 solver.cpp:189] Iteration 14900, loss = 0.112206
I0110 14:49:01.960072 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0656515 (* 1 = 0.0656515 loss)
I0110 14:49:01.960075 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0465545 (* 1 = 0.0465545 loss)
I0110 14:49:01.960079 10246 solver.cpp:464] Iteration 14900, lr = 0.001
speed: 0.087s / iter
I0110 14:49:10.859547 10246 solver.cpp:189] Iteration 15000, loss = 0.0526408
I0110 14:49:10.859565 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0314738 (* 1 = 0.0314738 loss)
I0110 14:49:10.859570 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.021167 (* 1 = 0.021167 loss)
I0110 14:49:10.859572 10246 solver.cpp:464] Iteration 15000, lr = 0.001
I0110 14:49:19.562371 10246 solver.cpp:189] Iteration 15100, loss = 0.00417938
I0110 14:49:19.562388 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00128244 (* 1 = 0.00128244 loss)
I0110 14:49:19.562392 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00289694 (* 1 = 0.00289694 loss)
I0110 14:49:19.562396 10246 solver.cpp:464] Iteration 15100, lr = 0.001
I0110 14:49:28.099251 10246 solver.cpp:189] Iteration 15200, loss = 0.134357
I0110 14:49:28.099269 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0758453 (* 1 = 0.0758453 loss)
I0110 14:49:28.099272 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0585121 (* 1 = 0.0585121 loss)
I0110 14:49:28.099277 10246 solver.cpp:464] Iteration 15200, lr = 0.001
I0110 14:49:36.607733 10246 solver.cpp:189] Iteration 15300, loss = 0.10477
I0110 14:49:36.607751 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0370878 (* 1 = 0.0370878 loss)
I0110 14:49:36.607755 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0676819 (* 1 = 0.0676819 loss)
I0110 14:49:36.607758 10246 solver.cpp:464] Iteration 15300, lr = 0.001
I0110 14:49:45.168853 10246 solver.cpp:189] Iteration 15400, loss = 0.0420116
I0110 14:49:45.168872 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00116842 (* 1 = 0.00116842 loss)
I0110 14:49:45.168877 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0408432 (* 1 = 0.0408432 loss)
I0110 14:49:45.168881 10246 solver.cpp:464] Iteration 15400, lr = 0.001
I0110 14:49:53.744983 10246 solver.cpp:189] Iteration 15500, loss = 0.0203923
I0110 14:49:53.745004 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00379216 (* 1 = 0.00379216 loss)
I0110 14:49:53.745009 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0166002 (* 1 = 0.0166002 loss)
I0110 14:49:53.745012 10246 solver.cpp:464] Iteration 15500, lr = 0.001
I0110 14:50:02.244184 10246 solver.cpp:189] Iteration 15600, loss = 0.0107122
I0110 14:50:02.244201 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00449434 (* 1 = 0.00449434 loss)
I0110 14:50:02.244205 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00621786 (* 1 = 0.00621786 loss)
I0110 14:50:02.244209 10246 solver.cpp:464] Iteration 15600, lr = 0.001
I0110 14:50:10.849067 10246 solver.cpp:189] Iteration 15700, loss = 0.172721
I0110 14:50:10.849084 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0845539 (* 1 = 0.0845539 loss)
I0110 14:50:10.849088 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0881673 (* 1 = 0.0881673 loss)
I0110 14:50:10.849092 10246 solver.cpp:464] Iteration 15700, lr = 0.001
I0110 14:50:19.383910 10246 solver.cpp:189] Iteration 15800, loss = 0.000729149
I0110 14:50:19.383927 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00039138 (* 1 = 0.00039138 loss)
I0110 14:50:19.383931 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.000337769 (* 1 = 0.000337769 loss)
I0110 14:50:19.383934 10246 solver.cpp:464] Iteration 15800, lr = 0.001
I0110 14:50:28.308413 10246 solver.cpp:189] Iteration 15900, loss = 0.050336
I0110 14:50:28.308430 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0153009 (* 1 = 0.0153009 loss)
I0110 14:50:28.308434 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0350351 (* 1 = 0.0350351 loss)
I0110 14:50:28.308437 10246 solver.cpp:464] Iteration 15900, lr = 0.001
speed: 0.087s / iter
I0110 14:50:37.113060 10246 solver.cpp:189] Iteration 16000, loss = 0.109645
I0110 14:50:37.113077 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0273583 (* 1 = 0.0273583 loss)
I0110 14:50:37.113081 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0822872 (* 1 = 0.0822872 loss)
I0110 14:50:37.113085 10246 solver.cpp:464] Iteration 16000, lr = 0.001
I0110 14:50:45.952065 10246 solver.cpp:189] Iteration 16100, loss = 0.0665761
I0110 14:50:45.952085 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00298608 (* 1 = 0.00298608 loss)
I0110 14:50:45.952090 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.06359 (* 1 = 0.06359 loss)
I0110 14:50:45.952092 10246 solver.cpp:464] Iteration 16100, lr = 0.001
I0110 14:50:54.666798 10246 solver.cpp:189] Iteration 16200, loss = 0.00831035
I0110 14:50:54.666816 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000902529 (* 1 = 0.000902529 loss)
I0110 14:50:54.666820 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00740782 (* 1 = 0.00740782 loss)
I0110 14:50:54.666822 10246 solver.cpp:464] Iteration 16200, lr = 0.001
I0110 14:51:03.305681 10246 solver.cpp:189] Iteration 16300, loss = 0.039882
I0110 14:51:03.305699 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00457157 (* 1 = 0.00457157 loss)
I0110 14:51:03.305703 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0353105 (* 1 = 0.0353105 loss)
I0110 14:51:03.305706 10246 solver.cpp:464] Iteration 16300, lr = 0.001
I0110 14:51:12.132829 10246 solver.cpp:189] Iteration 16400, loss = 0.0252243
I0110 14:51:12.132846 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00890033 (* 1 = 0.00890033 loss)
I0110 14:51:12.132851 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0163239 (* 1 = 0.0163239 loss)
I0110 14:51:12.132854 10246 solver.cpp:464] Iteration 16400, lr = 0.001
I0110 14:51:20.869355 10246 solver.cpp:189] Iteration 16500, loss = 0.14879
I0110 14:51:20.869376 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0610254 (* 1 = 0.0610254 loss)
I0110 14:51:20.869381 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0877649 (* 1 = 0.0877649 loss)
I0110 14:51:20.869385 10246 solver.cpp:464] Iteration 16500, lr = 0.001
I0110 14:51:29.449753 10246 solver.cpp:189] Iteration 16600, loss = 0.0686674
I0110 14:51:29.449770 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.049935 (* 1 = 0.049935 loss)
I0110 14:51:29.449774 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0187324 (* 1 = 0.0187324 loss)
I0110 14:51:29.449777 10246 solver.cpp:464] Iteration 16600, lr = 0.001
I0110 14:51:38.033432 10246 solver.cpp:189] Iteration 16700, loss = 0.0355148
I0110 14:51:38.033449 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0211735 (* 1 = 0.0211735 loss)
I0110 14:51:38.033453 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0143412 (* 1 = 0.0143412 loss)
I0110 14:51:38.033457 10246 solver.cpp:464] Iteration 16700, lr = 0.001
I0110 14:51:46.663563 10246 solver.cpp:189] Iteration 16800, loss = 0.0604904
I0110 14:51:46.663581 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0445225 (* 1 = 0.0445225 loss)
I0110 14:51:46.663585 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0159679 (* 1 = 0.0159679 loss)
I0110 14:51:46.663589 10246 solver.cpp:464] Iteration 16800, lr = 0.001
I0110 14:51:55.191613 10246 solver.cpp:189] Iteration 16900, loss = 0.150532
I0110 14:51:55.191632 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0356057 (* 1 = 0.0356057 loss)
I0110 14:51:55.191635 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.114927 (* 1 = 0.114927 loss)
I0110 14:51:55.191639 10246 solver.cpp:464] Iteration 16900, lr = 0.001
speed: 0.087s / iter
I0110 14:52:03.805434 10246 solver.cpp:189] Iteration 17000, loss = 0.116336
I0110 14:52:03.805452 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0769893 (* 1 = 0.0769893 loss)
I0110 14:52:03.805455 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.039347 (* 1 = 0.039347 loss)
I0110 14:52:03.805459 10246 solver.cpp:464] Iteration 17000, lr = 0.001
I0110 14:52:12.445197 10246 solver.cpp:189] Iteration 17100, loss = 0.0543528
I0110 14:52:12.445214 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0222068 (* 1 = 0.0222068 loss)
I0110 14:52:12.445219 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.032146 (* 1 = 0.032146 loss)
I0110 14:52:12.445221 10246 solver.cpp:464] Iteration 17100, lr = 0.001
I0110 14:52:21.063719 10246 solver.cpp:189] Iteration 17200, loss = 0.127543
I0110 14:52:21.063735 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0608579 (* 1 = 0.0608579 loss)
I0110 14:52:21.063740 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0666848 (* 1 = 0.0666848 loss)
I0110 14:52:21.063742 10246 solver.cpp:464] Iteration 17200, lr = 0.001
I0110 14:52:29.683151 10246 solver.cpp:189] Iteration 17300, loss = 0.101737
I0110 14:52:29.683168 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0131062 (* 1 = 0.0131062 loss)
I0110 14:52:29.683172 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0886305 (* 1 = 0.0886305 loss)
I0110 14:52:29.683176 10246 solver.cpp:464] Iteration 17300, lr = 0.001
I0110 14:52:38.174319 10246 solver.cpp:189] Iteration 17400, loss = 0.038038
I0110 14:52:38.174336 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00832448 (* 1 = 0.00832448 loss)
I0110 14:52:38.174340 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0297135 (* 1 = 0.0297135 loss)
I0110 14:52:38.174343 10246 solver.cpp:464] Iteration 17400, lr = 0.001
I0110 14:52:46.795426 10246 solver.cpp:189] Iteration 17500, loss = 0.0447791
I0110 14:52:46.795444 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0102263 (* 1 = 0.0102263 loss)
I0110 14:52:46.795447 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0345528 (* 1 = 0.0345528 loss)
I0110 14:52:46.795450 10246 solver.cpp:464] Iteration 17500, lr = 0.001
I0110 14:52:55.361953 10246 solver.cpp:189] Iteration 17600, loss = 0.311087
I0110 14:52:55.361969 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.179852 (* 1 = 0.179852 loss)
I0110 14:52:55.361974 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.131236 (* 1 = 0.131236 loss)
I0110 14:52:55.361977 10246 solver.cpp:464] Iteration 17600, lr = 0.001
I0110 14:53:04.200810 10246 solver.cpp:189] Iteration 17700, loss = 0.00411069
I0110 14:53:04.200827 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00109119 (* 1 = 0.00109119 loss)
I0110 14:53:04.200831 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00301951 (* 1 = 0.00301951 loss)
I0110 14:53:04.200834 10246 solver.cpp:464] Iteration 17700, lr = 0.001
I0110 14:53:12.808784 10246 solver.cpp:189] Iteration 17800, loss = 0.144129
I0110 14:53:12.808804 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0694398 (* 1 = 0.0694398 loss)
I0110 14:53:12.808809 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0746887 (* 1 = 0.0746887 loss)
I0110 14:53:12.808811 10246 solver.cpp:464] Iteration 17800, lr = 0.001
I0110 14:53:21.377064 10246 solver.cpp:189] Iteration 17900, loss = 0.0864416
I0110 14:53:21.377081 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0388901 (* 1 = 0.0388901 loss)
I0110 14:53:21.377085 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0475515 (* 1 = 0.0475515 loss)
I0110 14:53:21.377089 10246 solver.cpp:464] Iteration 17900, lr = 0.001
speed: 0.087s / iter
I0110 14:53:30.110410 10246 solver.cpp:189] Iteration 18000, loss = 0.163111
I0110 14:53:30.110430 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0742247 (* 1 = 0.0742247 loss)
I0110 14:53:30.110435 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0888866 (* 1 = 0.0888866 loss)
I0110 14:53:30.110438 10246 solver.cpp:464] Iteration 18000, lr = 0.001
I0110 14:53:38.918393 10246 solver.cpp:189] Iteration 18100, loss = 0.162494
I0110 14:53:38.918414 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0389596 (* 1 = 0.0389596 loss)
I0110 14:53:38.918419 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.123535 (* 1 = 0.123535 loss)
I0110 14:53:38.918423 10246 solver.cpp:464] Iteration 18100, lr = 0.001
I0110 14:53:47.406988 10246 solver.cpp:189] Iteration 18200, loss = 0.0947021
I0110 14:53:47.407006 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0262038 (* 1 = 0.0262038 loss)
I0110 14:53:47.407011 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0684983 (* 1 = 0.0684983 loss)
I0110 14:53:47.407014 10246 solver.cpp:464] Iteration 18200, lr = 0.001
I0110 14:53:56.098441 10246 solver.cpp:189] Iteration 18300, loss = 0.00177327
I0110 14:53:56.098459 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00047864 (* 1 = 0.00047864 loss)
I0110 14:53:56.098464 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00129464 (* 1 = 0.00129464 loss)
I0110 14:53:56.098466 10246 solver.cpp:464] Iteration 18300, lr = 0.001
I0110 14:54:04.914999 10246 solver.cpp:189] Iteration 18400, loss = 0.0125568
I0110 14:54:04.915019 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00213888 (* 1 = 0.00213888 loss)
I0110 14:54:04.915024 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0104179 (* 1 = 0.0104179 loss)
I0110 14:54:04.915026 10246 solver.cpp:464] Iteration 18400, lr = 0.001
I0110 14:54:13.815986 10246 solver.cpp:189] Iteration 18500, loss = 0.0725586
I0110 14:54:13.816007 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0552399 (* 1 = 0.0552399 loss)
I0110 14:54:13.816011 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0173187 (* 1 = 0.0173187 loss)
I0110 14:54:13.816015 10246 solver.cpp:464] Iteration 18500, lr = 0.001
I0110 14:54:22.364460 10246 solver.cpp:189] Iteration 18600, loss = 0.130917
I0110 14:54:22.364478 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0128093 (* 1 = 0.0128093 loss)
I0110 14:54:22.364482 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.118108 (* 1 = 0.118108 loss)
I0110 14:54:22.364486 10246 solver.cpp:464] Iteration 18600, lr = 0.001
I0110 14:54:30.893131 10246 solver.cpp:189] Iteration 18700, loss = 0.176081
I0110 14:54:30.893147 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0446338 (* 1 = 0.0446338 loss)
I0110 14:54:30.893151 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.131447 (* 1 = 0.131447 loss)
I0110 14:54:30.893156 10246 solver.cpp:464] Iteration 18700, lr = 0.001
I0110 14:54:39.471140 10246 solver.cpp:189] Iteration 18800, loss = 0.0372864
I0110 14:54:39.471158 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00207674 (* 1 = 0.00207674 loss)
I0110 14:54:39.471163 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0352096 (* 1 = 0.0352096 loss)
I0110 14:54:39.471165 10246 solver.cpp:464] Iteration 18800, lr = 0.001
I0110 14:54:48.652056 10246 solver.cpp:189] Iteration 18900, loss = 0.0581787
I0110 14:54:48.652078 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0542387 (* 1 = 0.0542387 loss)
I0110 14:54:48.652083 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00393992 (* 1 = 0.00393992 loss)
I0110 14:54:48.652086 10246 solver.cpp:464] Iteration 18900, lr = 0.001
speed: 0.087s / iter
I0110 14:54:57.213430 10246 solver.cpp:189] Iteration 19000, loss = 0.214281
I0110 14:54:57.213449 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0941155 (* 1 = 0.0941155 loss)
I0110 14:54:57.213451 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.120165 (* 1 = 0.120165 loss)
I0110 14:54:57.213455 10246 solver.cpp:464] Iteration 19000, lr = 0.001
I0110 14:55:05.707978 10246 solver.cpp:189] Iteration 19100, loss = 0.19337
I0110 14:55:05.707995 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0245374 (* 1 = 0.0245374 loss)
I0110 14:55:05.707999 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.168833 (* 1 = 0.168833 loss)
I0110 14:55:05.708003 10246 solver.cpp:464] Iteration 19100, lr = 0.001
I0110 14:55:14.205874 10246 solver.cpp:189] Iteration 19200, loss = 0.0995104
I0110 14:55:14.205894 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0372525 (* 1 = 0.0372525 loss)
I0110 14:55:14.205899 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.062258 (* 1 = 0.062258 loss)
I0110 14:55:14.205902 10246 solver.cpp:464] Iteration 19200, lr = 0.001
I0110 14:55:22.664125 10246 solver.cpp:189] Iteration 19300, loss = 0.112855
I0110 14:55:22.664146 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0796705 (* 1 = 0.0796705 loss)
I0110 14:55:22.664151 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0331849 (* 1 = 0.0331849 loss)
I0110 14:55:22.664155 10246 solver.cpp:464] Iteration 19300, lr = 0.001
I0110 14:55:31.149449 10246 solver.cpp:189] Iteration 19400, loss = 0.138219
I0110 14:55:31.149471 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0564935 (* 1 = 0.0564935 loss)
I0110 14:55:31.149477 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0817257 (* 1 = 0.0817257 loss)
I0110 14:55:31.149479 10246 solver.cpp:464] Iteration 19400, lr = 0.001
I0110 14:55:39.616278 10246 solver.cpp:189] Iteration 19500, loss = 0.0947924
I0110 14:55:39.616294 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0474554 (* 1 = 0.0474554 loss)
I0110 14:55:39.616298 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.047337 (* 1 = 0.047337 loss)
I0110 14:55:39.616302 10246 solver.cpp:464] Iteration 19500, lr = 0.001
I0110 14:55:48.048414 10246 solver.cpp:189] Iteration 19600, loss = 0.160802
I0110 14:55:48.048432 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.110293 (* 1 = 0.110293 loss)
I0110 14:55:48.048436 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0505095 (* 1 = 0.0505095 loss)
I0110 14:55:48.048439 10246 solver.cpp:464] Iteration 19600, lr = 0.001
I0110 14:55:56.558099 10246 solver.cpp:189] Iteration 19700, loss = 0.108334
I0110 14:55:56.558116 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0495998 (* 1 = 0.0495998 loss)
I0110 14:55:56.558120 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0587344 (* 1 = 0.0587344 loss)
I0110 14:55:56.558123 10246 solver.cpp:464] Iteration 19700, lr = 0.001
I0110 14:56:05.059295 10246 solver.cpp:189] Iteration 19800, loss = 0.143191
I0110 14:56:05.059312 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0860314 (* 1 = 0.0860314 loss)
I0110 14:56:05.059316 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0571598 (* 1 = 0.0571598 loss)
I0110 14:56:05.059319 10246 solver.cpp:464] Iteration 19800, lr = 0.001
I0110 14:56:13.550952 10246 solver.cpp:189] Iteration 19900, loss = 0.0277403
I0110 14:56:13.550976 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.01248 (* 1 = 0.01248 loss)
I0110 14:56:13.550981 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0152603 (* 1 = 0.0152603 loss)
I0110 14:56:13.550984 10246 solver.cpp:464] Iteration 19900, lr = 0.001
speed: 0.087s / iter
Wrote snapshot to: /home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/output/IR_Reg/train/vgg_cnn_m_1024_fast_rcnn_iter_20000.caffemodel
I0110 14:56:23.108094 10246 solver.cpp:189] Iteration 20000, loss = 0.0197013
I0110 14:56:23.108113 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00115428 (* 1 = 0.00115428 loss)
I0110 14:56:23.108116 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.018547 (* 1 = 0.018547 loss)
I0110 14:56:23.108119 10246 solver.cpp:464] Iteration 20000, lr = 0.001
I0110 14:56:31.713800 10246 solver.cpp:189] Iteration 20100, loss = 0.0442631
I0110 14:56:31.713820 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0352772 (* 1 = 0.0352772 loss)
I0110 14:56:31.713825 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00898583 (* 1 = 0.00898583 loss)
I0110 14:56:31.713829 10246 solver.cpp:464] Iteration 20100, lr = 0.001
I0110 14:56:40.270508 10246 solver.cpp:189] Iteration 20200, loss = 0.0566188
I0110 14:56:40.270524 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00750037 (* 1 = 0.00750037 loss)
I0110 14:56:40.270527 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0491184 (* 1 = 0.0491184 loss)
I0110 14:56:40.270530 10246 solver.cpp:464] Iteration 20200, lr = 0.001
I0110 14:56:48.898874 10246 solver.cpp:189] Iteration 20300, loss = 0.245402
I0110 14:56:48.898890 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0966599 (* 1 = 0.0966599 loss)
I0110 14:56:48.898895 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.148743 (* 1 = 0.148743 loss)
I0110 14:56:48.898897 10246 solver.cpp:464] Iteration 20300, lr = 0.001
I0110 14:56:57.484272 10246 solver.cpp:189] Iteration 20400, loss = 0.11474
I0110 14:56:57.484292 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0618072 (* 1 = 0.0618072 loss)
I0110 14:56:57.484295 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0529332 (* 1 = 0.0529332 loss)
I0110 14:56:57.484298 10246 solver.cpp:464] Iteration 20400, lr = 0.001
I0110 14:57:06.015802 10246 solver.cpp:189] Iteration 20500, loss = 0.00681285
I0110 14:57:06.015820 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00172157 (* 1 = 0.00172157 loss)
I0110 14:57:06.015825 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00509128 (* 1 = 0.00509128 loss)
I0110 14:57:06.015827 10246 solver.cpp:464] Iteration 20500, lr = 0.001
I0110 14:57:14.657819 10246 solver.cpp:189] Iteration 20600, loss = 0.122872
I0110 14:57:14.657835 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0426421 (* 1 = 0.0426421 loss)
I0110 14:57:14.657840 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0802299 (* 1 = 0.0802299 loss)
I0110 14:57:14.657842 10246 solver.cpp:464] Iteration 20600, lr = 0.001
I0110 14:57:23.088984 10246 solver.cpp:189] Iteration 20700, loss = 0.0328236
I0110 14:57:23.089002 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0132496 (* 1 = 0.0132496 loss)
I0110 14:57:23.089006 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.019574 (* 1 = 0.019574 loss)
I0110 14:57:23.089010 10246 solver.cpp:464] Iteration 20700, lr = 0.001
I0110 14:57:31.682221 10246 solver.cpp:189] Iteration 20800, loss = 0.102286
I0110 14:57:31.682238 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0347861 (* 1 = 0.0347861 loss)
I0110 14:57:31.682242 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0675001 (* 1 = 0.0675001 loss)
I0110 14:57:31.682245 10246 solver.cpp:464] Iteration 20800, lr = 0.001
I0110 14:57:40.191611 10246 solver.cpp:189] Iteration 20900, loss = 0.127426
I0110 14:57:40.191628 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.104466 (* 1 = 0.104466 loss)
I0110 14:57:40.191632 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0229605 (* 1 = 0.0229605 loss)
I0110 14:57:40.191635 10246 solver.cpp:464] Iteration 20900, lr = 0.001
speed: 0.087s / iter
I0110 14:57:48.714608 10246 solver.cpp:189] Iteration 21000, loss = 0.250066
I0110 14:57:48.714627 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.199294 (* 1 = 0.199294 loss)
I0110 14:57:48.714632 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0507718 (* 1 = 0.0507718 loss)
I0110 14:57:48.714634 10246 solver.cpp:464] Iteration 21000, lr = 0.001
I0110 14:57:57.227108 10246 solver.cpp:189] Iteration 21100, loss = 0.193435
I0110 14:57:57.227126 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0754059 (* 1 = 0.0754059 loss)
I0110 14:57:57.227130 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.118029 (* 1 = 0.118029 loss)
I0110 14:57:57.227133 10246 solver.cpp:464] Iteration 21100, lr = 0.001
I0110 14:58:05.703759 10246 solver.cpp:189] Iteration 21200, loss = 0.123454
I0110 14:58:05.703778 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0532013 (* 1 = 0.0532013 loss)
I0110 14:58:05.703783 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0702523 (* 1 = 0.0702523 loss)
I0110 14:58:05.703786 10246 solver.cpp:464] Iteration 21200, lr = 0.001
I0110 14:58:14.176841 10246 solver.cpp:189] Iteration 21300, loss = 0.0435533
I0110 14:58:14.176861 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00554809 (* 1 = 0.00554809 loss)
I0110 14:58:14.176864 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0380052 (* 1 = 0.0380052 loss)
I0110 14:58:14.176867 10246 solver.cpp:464] Iteration 21300, lr = 0.001
I0110 14:58:22.693769 10246 solver.cpp:189] Iteration 21400, loss = 0.0772469
I0110 14:58:22.693788 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0422991 (* 1 = 0.0422991 loss)
I0110 14:58:22.693791 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0349478 (* 1 = 0.0349478 loss)
I0110 14:58:22.693795 10246 solver.cpp:464] Iteration 21400, lr = 0.001
I0110 14:58:31.174105 10246 solver.cpp:189] Iteration 21500, loss = 0.00235445
I0110 14:58:31.174124 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000245704 (* 1 = 0.000245704 loss)
I0110 14:58:31.174127 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00210875 (* 1 = 0.00210875 loss)
I0110 14:58:31.174130 10246 solver.cpp:464] Iteration 21500, lr = 0.001
I0110 14:58:39.606065 10246 solver.cpp:189] Iteration 21600, loss = 0.0894883
I0110 14:58:39.606083 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0740894 (* 1 = 0.0740894 loss)
I0110 14:58:39.606086 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0153989 (* 1 = 0.0153989 loss)
I0110 14:58:39.606091 10246 solver.cpp:464] Iteration 21600, lr = 0.001
I0110 14:58:48.089447 10246 solver.cpp:189] Iteration 21700, loss = 0.0783395
I0110 14:58:48.089464 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0384976 (* 1 = 0.0384976 loss)
I0110 14:58:48.089468 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0398419 (* 1 = 0.0398419 loss)
I0110 14:58:48.089473 10246 solver.cpp:464] Iteration 21700, lr = 0.001
I0110 14:58:56.558326 10246 solver.cpp:189] Iteration 21800, loss = 0.00469545
I0110 14:58:56.558344 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000822892 (* 1 = 0.000822892 loss)
I0110 14:58:56.558348 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00387255 (* 1 = 0.00387255 loss)
I0110 14:58:56.558351 10246 solver.cpp:464] Iteration 21800, lr = 0.001
I0110 14:59:05.042383 10246 solver.cpp:189] Iteration 21900, loss = 0.0663934
I0110 14:59:05.042402 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0304378 (* 1 = 0.0304378 loss)
I0110 14:59:05.042404 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0359556 (* 1 = 0.0359556 loss)
I0110 14:59:05.042407 10246 solver.cpp:464] Iteration 21900, lr = 0.001
speed: 0.086s / iter
I0110 14:59:13.558300 10246 solver.cpp:189] Iteration 22000, loss = 0.160216
I0110 14:59:13.558317 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0750621 (* 1 = 0.0750621 loss)
I0110 14:59:13.558321 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0851543 (* 1 = 0.0851543 loss)
I0110 14:59:13.558326 10246 solver.cpp:464] Iteration 22000, lr = 0.001
I0110 14:59:22.085583 10246 solver.cpp:189] Iteration 22100, loss = 0.192014
I0110 14:59:22.085602 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.075479 (* 1 = 0.075479 loss)
I0110 14:59:22.085605 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.116535 (* 1 = 0.116535 loss)
I0110 14:59:22.085609 10246 solver.cpp:464] Iteration 22100, lr = 0.001
I0110 14:59:30.562173 10246 solver.cpp:189] Iteration 22200, loss = 0.0146508
I0110 14:59:30.562191 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00010838 (* 1 = 0.00010838 loss)
I0110 14:59:30.562196 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0145425 (* 1 = 0.0145425 loss)
I0110 14:59:30.562198 10246 solver.cpp:464] Iteration 22200, lr = 0.001
I0110 14:59:39.000893 10246 solver.cpp:189] Iteration 22300, loss = 0.131384
I0110 14:59:39.000911 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0548308 (* 1 = 0.0548308 loss)
I0110 14:59:39.000916 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0765532 (* 1 = 0.0765532 loss)
I0110 14:59:39.000918 10246 solver.cpp:464] Iteration 22300, lr = 0.001
I0110 14:59:47.504870 10246 solver.cpp:189] Iteration 22400, loss = 0.104865
I0110 14:59:47.504889 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0529431 (* 1 = 0.0529431 loss)
I0110 14:59:47.504892 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0519223 (* 1 = 0.0519223 loss)
I0110 14:59:47.504897 10246 solver.cpp:464] Iteration 22400, lr = 0.001
I0110 14:59:55.993827 10246 solver.cpp:189] Iteration 22500, loss = 0.0150866
I0110 14:59:55.993845 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000446702 (* 1 = 0.000446702 loss)
I0110 14:59:55.993849 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0146399 (* 1 = 0.0146399 loss)
I0110 14:59:55.993852 10246 solver.cpp:464] Iteration 22500, lr = 0.001
I0110 15:00:04.573263 10246 solver.cpp:189] Iteration 22600, loss = 0.0432198
I0110 15:00:04.573282 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000756475 (* 1 = 0.000756475 loss)
I0110 15:00:04.573285 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0424633 (* 1 = 0.0424633 loss)
I0110 15:00:04.573288 10246 solver.cpp:464] Iteration 22600, lr = 0.001
I0110 15:00:13.102936 10246 solver.cpp:189] Iteration 22700, loss = 0.0910124
I0110 15:00:13.102954 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0438789 (* 1 = 0.0438789 loss)
I0110 15:00:13.102962 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0471336 (* 1 = 0.0471336 loss)
I0110 15:00:13.102965 10246 solver.cpp:464] Iteration 22700, lr = 0.001
I0110 15:00:21.587910 10246 solver.cpp:189] Iteration 22800, loss = 0.0660552
I0110 15:00:21.587927 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0371449 (* 1 = 0.0371449 loss)
I0110 15:00:21.587931 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0289102 (* 1 = 0.0289102 loss)
I0110 15:00:21.587935 10246 solver.cpp:464] Iteration 22800, lr = 0.001
I0110 15:00:30.281873 10246 solver.cpp:189] Iteration 22900, loss = 0.0444127
I0110 15:00:30.281891 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.036684 (* 1 = 0.036684 loss)
I0110 15:00:30.281895 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00772874 (* 1 = 0.00772874 loss)
I0110 15:00:30.281898 10246 solver.cpp:464] Iteration 22900, lr = 0.001
speed: 0.086s / iter
I0110 15:00:38.892369 10246 solver.cpp:189] Iteration 23000, loss = 0.0767122
I0110 15:00:38.892386 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0590482 (* 1 = 0.0590482 loss)
I0110 15:00:38.892390 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.017664 (* 1 = 0.017664 loss)
I0110 15:00:38.892393 10246 solver.cpp:464] Iteration 23000, lr = 0.001
I0110 15:00:47.352777 10246 solver.cpp:189] Iteration 23100, loss = 0.0134655
I0110 15:00:47.352794 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00793747 (* 1 = 0.00793747 loss)
I0110 15:00:47.352798 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00552802 (* 1 = 0.00552802 loss)
I0110 15:00:47.352802 10246 solver.cpp:464] Iteration 23100, lr = 0.001
I0110 15:00:55.970355 10246 solver.cpp:189] Iteration 23200, loss = 0.17163
I0110 15:00:55.970372 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0711387 (* 1 = 0.0711387 loss)
I0110 15:00:55.970376 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.100491 (* 1 = 0.100491 loss)
I0110 15:00:55.970379 10246 solver.cpp:464] Iteration 23200, lr = 0.001
I0110 15:01:04.556542 10246 solver.cpp:189] Iteration 23300, loss = 0.0773382
I0110 15:01:04.556560 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0501212 (* 1 = 0.0501212 loss)
I0110 15:01:04.556565 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.027217 (* 1 = 0.027217 loss)
I0110 15:01:04.556568 10246 solver.cpp:464] Iteration 23300, lr = 0.001
I0110 15:01:13.057812 10246 solver.cpp:189] Iteration 23400, loss = 0.0449777
I0110 15:01:13.057833 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0185453 (* 1 = 0.0185453 loss)
I0110 15:01:13.057838 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0264324 (* 1 = 0.0264324 loss)
I0110 15:01:13.057842 10246 solver.cpp:464] Iteration 23400, lr = 0.001
I0110 15:01:21.557081 10246 solver.cpp:189] Iteration 23500, loss = 0.0153972
I0110 15:01:21.557101 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0136906 (* 1 = 0.0136906 loss)
I0110 15:01:21.557106 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0017066 (* 1 = 0.0017066 loss)
I0110 15:01:21.557111 10246 solver.cpp:464] Iteration 23500, lr = 0.001
I0110 15:01:30.050936 10246 solver.cpp:189] Iteration 23600, loss = 0.00840509
I0110 15:01:30.050954 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000580991 (* 1 = 0.000580991 loss)
I0110 15:01:30.050961 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0078241 (* 1 = 0.0078241 loss)
I0110 15:01:30.050963 10246 solver.cpp:464] Iteration 23600, lr = 0.001
I0110 15:01:38.585470 10246 solver.cpp:189] Iteration 23700, loss = 0.0442455
I0110 15:01:38.585487 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00501788 (* 1 = 0.00501788 loss)
I0110 15:01:38.585491 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0392277 (* 1 = 0.0392277 loss)
I0110 15:01:38.585494 10246 solver.cpp:464] Iteration 23700, lr = 0.001
I0110 15:01:47.099845 10246 solver.cpp:189] Iteration 23800, loss = 0.0358353
I0110 15:01:47.099864 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0188425 (* 1 = 0.0188425 loss)
I0110 15:01:47.099867 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0169928 (* 1 = 0.0169928 loss)
I0110 15:01:47.099870 10246 solver.cpp:464] Iteration 23800, lr = 0.001
I0110 15:01:55.580446 10246 solver.cpp:189] Iteration 23900, loss = 0.0780228
I0110 15:01:55.580461 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0253882 (* 1 = 0.0253882 loss)
I0110 15:01:55.580466 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0526346 (* 1 = 0.0526346 loss)
I0110 15:01:55.580468 10246 solver.cpp:464] Iteration 23900, lr = 0.001
speed: 0.086s / iter
I0110 15:02:04.048254 10246 solver.cpp:189] Iteration 24000, loss = 0.0424202
I0110 15:02:04.048270 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0154873 (* 1 = 0.0154873 loss)
I0110 15:02:04.048274 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0269329 (* 1 = 0.0269329 loss)
I0110 15:02:04.048277 10246 solver.cpp:464] Iteration 24000, lr = 0.001
I0110 15:02:12.567972 10246 solver.cpp:189] Iteration 24100, loss = 0.114356
I0110 15:02:12.567989 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0195619 (* 1 = 0.0195619 loss)
I0110 15:02:12.567993 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0947939 (* 1 = 0.0947939 loss)
I0110 15:02:12.567996 10246 solver.cpp:464] Iteration 24100, lr = 0.001
I0110 15:02:21.100478 10246 solver.cpp:189] Iteration 24200, loss = 0.17153
I0110 15:02:21.100495 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0815298 (* 1 = 0.0815298 loss)
I0110 15:02:21.100499 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.09 (* 1 = 0.09 loss)
I0110 15:02:21.100502 10246 solver.cpp:464] Iteration 24200, lr = 0.001
I0110 15:02:29.686945 10246 solver.cpp:189] Iteration 24300, loss = 0.151248
I0110 15:02:29.686965 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0617333 (* 1 = 0.0617333 loss)
I0110 15:02:29.686969 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0895144 (* 1 = 0.0895144 loss)
I0110 15:02:29.686972 10246 solver.cpp:464] Iteration 24300, lr = 0.001
I0110 15:02:38.268856 10246 solver.cpp:189] Iteration 24400, loss = 0.0585845
I0110 15:02:38.268873 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0349699 (* 1 = 0.0349699 loss)
I0110 15:02:38.268877 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0236146 (* 1 = 0.0236146 loss)
I0110 15:02:38.268880 10246 solver.cpp:464] Iteration 24400, lr = 0.001
I0110 15:02:46.826247 10246 solver.cpp:189] Iteration 24500, loss = 0.0809539
I0110 15:02:46.826266 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0312593 (* 1 = 0.0312593 loss)
I0110 15:02:46.826269 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0496946 (* 1 = 0.0496946 loss)
I0110 15:02:46.826273 10246 solver.cpp:464] Iteration 24500, lr = 0.001
I0110 15:02:55.362124 10246 solver.cpp:189] Iteration 24600, loss = 0.0215187
I0110 15:02:55.362145 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00356318 (* 1 = 0.00356318 loss)
I0110 15:02:55.362149 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0179555 (* 1 = 0.0179555 loss)
I0110 15:02:55.362154 10246 solver.cpp:464] Iteration 24600, lr = 0.001
I0110 15:03:03.817646 10246 solver.cpp:189] Iteration 24700, loss = 0.0811678
I0110 15:03:03.817664 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00119789 (* 1 = 0.00119789 loss)
I0110 15:03:03.817668 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0799699 (* 1 = 0.0799699 loss)
I0110 15:03:03.817672 10246 solver.cpp:464] Iteration 24700, lr = 0.001
I0110 15:03:12.308552 10246 solver.cpp:189] Iteration 24800, loss = 0.0151292
I0110 15:03:12.308569 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000370465 (* 1 = 0.000370465 loss)
I0110 15:03:12.308573 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0147587 (* 1 = 0.0147587 loss)
I0110 15:03:12.308576 10246 solver.cpp:464] Iteration 24800, lr = 0.001
I0110 15:03:20.752709 10246 solver.cpp:189] Iteration 24900, loss = 0.00120248
I0110 15:03:20.752727 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000388526 (* 1 = 0.000388526 loss)
I0110 15:03:20.752730 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.000813957 (* 1 = 0.000813957 loss)
I0110 15:03:20.752733 10246 solver.cpp:464] Iteration 24900, lr = 0.001
speed: 0.086s / iter
I0110 15:03:29.193722 10246 solver.cpp:189] Iteration 25000, loss = 0.0530641
I0110 15:03:29.193740 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.009455 (* 1 = 0.009455 loss)
I0110 15:03:29.193744 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0436091 (* 1 = 0.0436091 loss)
I0110 15:03:29.193747 10246 solver.cpp:464] Iteration 25000, lr = 0.001
I0110 15:03:37.719329 10246 solver.cpp:189] Iteration 25100, loss = 0.0606906
I0110 15:03:37.719348 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00402722 (* 1 = 0.00402722 loss)
I0110 15:03:37.719352 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0566634 (* 1 = 0.0566634 loss)
I0110 15:03:37.719355 10246 solver.cpp:464] Iteration 25100, lr = 0.001
I0110 15:03:46.246695 10246 solver.cpp:189] Iteration 25200, loss = 0.160048
I0110 15:03:46.246713 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0443105 (* 1 = 0.0443105 loss)
I0110 15:03:46.246717 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.115737 (* 1 = 0.115737 loss)
I0110 15:03:46.246721 10246 solver.cpp:464] Iteration 25200, lr = 0.001
I0110 15:03:54.771729 10246 solver.cpp:189] Iteration 25300, loss = 0.282965
I0110 15:03:54.771747 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.131711 (* 1 = 0.131711 loss)
I0110 15:03:54.771751 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.151255 (* 1 = 0.151255 loss)
I0110 15:03:54.771754 10246 solver.cpp:464] Iteration 25300, lr = 0.001
I0110 15:04:03.251679 10246 solver.cpp:189] Iteration 25400, loss = 0.0917791
I0110 15:04:03.251698 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0650573 (* 1 = 0.0650573 loss)
I0110 15:04:03.251703 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0267219 (* 1 = 0.0267219 loss)
I0110 15:04:03.251705 10246 solver.cpp:464] Iteration 25400, lr = 0.001
I0110 15:04:11.803819 10246 solver.cpp:189] Iteration 25500, loss = 0.0452518
I0110 15:04:11.803838 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0384798 (* 1 = 0.0384798 loss)
I0110 15:04:11.803841 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00677192 (* 1 = 0.00677192 loss)
I0110 15:04:11.803844 10246 solver.cpp:464] Iteration 25500, lr = 0.001
I0110 15:04:20.396111 10246 solver.cpp:189] Iteration 25600, loss = 0.192295
I0110 15:04:20.396131 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0872248 (* 1 = 0.0872248 loss)
I0110 15:04:20.396136 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.10507 (* 1 = 0.10507 loss)
I0110 15:04:20.396138 10246 solver.cpp:464] Iteration 25600, lr = 0.001
I0110 15:04:29.154871 10246 solver.cpp:189] Iteration 25700, loss = 0.160909
I0110 15:04:29.154889 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0640386 (* 1 = 0.0640386 loss)
I0110 15:04:29.154893 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0968708 (* 1 = 0.0968708 loss)
I0110 15:04:29.154896 10246 solver.cpp:464] Iteration 25700, lr = 0.001
I0110 15:04:37.724807 10246 solver.cpp:189] Iteration 25800, loss = 0.0874791
I0110 15:04:37.724825 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0298013 (* 1 = 0.0298013 loss)
I0110 15:04:37.724829 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0576777 (* 1 = 0.0576777 loss)
I0110 15:04:37.724833 10246 solver.cpp:464] Iteration 25800, lr = 0.001
I0110 15:04:46.276589 10246 solver.cpp:189] Iteration 25900, loss = 0.0577373
I0110 15:04:46.276607 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0227678 (* 1 = 0.0227678 loss)
I0110 15:04:46.276610 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0349695 (* 1 = 0.0349695 loss)
I0110 15:04:46.276613 10246 solver.cpp:464] Iteration 25900, lr = 0.001
speed: 0.086s / iter
I0110 15:04:54.862300 10246 solver.cpp:189] Iteration 26000, loss = 0.0848743
I0110 15:04:54.862318 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0357477 (* 1 = 0.0357477 loss)
I0110 15:04:54.862323 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0491266 (* 1 = 0.0491266 loss)
I0110 15:04:54.862326 10246 solver.cpp:464] Iteration 26000, lr = 0.001
I0110 15:05:03.330366 10246 solver.cpp:189] Iteration 26100, loss = 0.234923
I0110 15:05:03.330385 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.128742 (* 1 = 0.128742 loss)
I0110 15:05:03.330389 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.106181 (* 1 = 0.106181 loss)
I0110 15:05:03.330392 10246 solver.cpp:464] Iteration 26100, lr = 0.001
I0110 15:05:11.821203 10246 solver.cpp:189] Iteration 26200, loss = 0.0298477
I0110 15:05:11.821221 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0260704 (* 1 = 0.0260704 loss)
I0110 15:05:11.821225 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00377734 (* 1 = 0.00377734 loss)
I0110 15:05:11.821228 10246 solver.cpp:464] Iteration 26200, lr = 0.001
I0110 15:05:20.308528 10246 solver.cpp:189] Iteration 26300, loss = 0.0494944
I0110 15:05:20.308547 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00507786 (* 1 = 0.00507786 loss)
I0110 15:05:20.308550 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0444165 (* 1 = 0.0444165 loss)
I0110 15:05:20.308553 10246 solver.cpp:464] Iteration 26300, lr = 0.001
I0110 15:05:28.822218 10246 solver.cpp:189] Iteration 26400, loss = 0.0596955
I0110 15:05:28.822235 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.036165 (* 1 = 0.036165 loss)
I0110 15:05:28.822239 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0235304 (* 1 = 0.0235304 loss)
I0110 15:05:28.822242 10246 solver.cpp:464] Iteration 26400, lr = 0.001
I0110 15:05:37.350005 10246 solver.cpp:189] Iteration 26500, loss = 0.127166
I0110 15:05:37.350024 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0374876 (* 1 = 0.0374876 loss)
I0110 15:05:37.350028 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.089678 (* 1 = 0.089678 loss)
I0110 15:05:37.350031 10246 solver.cpp:464] Iteration 26500, lr = 0.001
I0110 15:05:45.797010 10246 solver.cpp:189] Iteration 26600, loss = 0.0470188
I0110 15:05:45.797030 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00208173 (* 1 = 0.00208173 loss)
I0110 15:05:45.797035 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0449371 (* 1 = 0.0449371 loss)
I0110 15:05:45.797039 10246 solver.cpp:464] Iteration 26600, lr = 0.001
I0110 15:05:54.283903 10246 solver.cpp:189] Iteration 26700, loss = 0.0369354
I0110 15:05:54.283926 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00674328 (* 1 = 0.00674328 loss)
I0110 15:05:54.283931 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0301921 (* 1 = 0.0301921 loss)
I0110 15:05:54.283934 10246 solver.cpp:464] Iteration 26700, lr = 0.001
I0110 15:06:02.762677 10246 solver.cpp:189] Iteration 26800, loss = 0.0517784
I0110 15:06:02.762696 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0160869 (* 1 = 0.0160869 loss)
I0110 15:06:02.762699 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0356915 (* 1 = 0.0356915 loss)
I0110 15:06:02.762703 10246 solver.cpp:464] Iteration 26800, lr = 0.001
I0110 15:06:11.209646 10246 solver.cpp:189] Iteration 26900, loss = 0.00129265
I0110 15:06:11.209664 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000562725 (* 1 = 0.000562725 loss)
I0110 15:06:11.209668 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.000729925 (* 1 = 0.000729925 loss)
I0110 15:06:11.209671 10246 solver.cpp:464] Iteration 26900, lr = 0.001
speed: 0.086s / iter
I0110 15:06:19.723207 10246 solver.cpp:189] Iteration 27000, loss = 0.108375
I0110 15:06:19.723225 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0293529 (* 1 = 0.0293529 loss)
I0110 15:06:19.723228 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0790221 (* 1 = 0.0790221 loss)
I0110 15:06:19.723232 10246 solver.cpp:464] Iteration 27000, lr = 0.001
I0110 15:06:28.248873 10246 solver.cpp:189] Iteration 27100, loss = 0.0230365
I0110 15:06:28.248891 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000355932 (* 1 = 0.000355932 loss)
I0110 15:06:28.248895 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0226806 (* 1 = 0.0226806 loss)
I0110 15:06:28.248898 10246 solver.cpp:464] Iteration 27100, lr = 0.001
I0110 15:06:36.790329 10246 solver.cpp:189] Iteration 27200, loss = 0.0740497
I0110 15:06:36.790347 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000356758 (* 1 = 0.000356758 loss)
I0110 15:06:36.790351 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.073693 (* 1 = 0.073693 loss)
I0110 15:06:36.790355 10246 solver.cpp:464] Iteration 27200, lr = 0.001
I0110 15:06:45.372840 10246 solver.cpp:189] Iteration 27300, loss = 0.149853
I0110 15:06:45.372859 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0250256 (* 1 = 0.0250256 loss)
I0110 15:06:45.372862 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.124827 (* 1 = 0.124827 loss)
I0110 15:06:45.372865 10246 solver.cpp:464] Iteration 27300, lr = 0.001
I0110 15:06:54.006216 10246 solver.cpp:189] Iteration 27400, loss = 0.133566
I0110 15:06:54.006233 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.101124 (* 1 = 0.101124 loss)
I0110 15:06:54.006237 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0324418 (* 1 = 0.0324418 loss)
I0110 15:06:54.006240 10246 solver.cpp:464] Iteration 27400, lr = 0.001
I0110 15:07:02.667706 10246 solver.cpp:189] Iteration 27500, loss = 0.279854
I0110 15:07:02.667724 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.14774 (* 1 = 0.14774 loss)
I0110 15:07:02.667728 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.132114 (* 1 = 0.132114 loss)
I0110 15:07:02.667732 10246 solver.cpp:464] Iteration 27500, lr = 0.001
I0110 15:07:11.217701 10246 solver.cpp:189] Iteration 27600, loss = 0.095858
I0110 15:07:11.217720 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0507762 (* 1 = 0.0507762 loss)
I0110 15:07:11.217723 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0450818 (* 1 = 0.0450818 loss)
I0110 15:07:11.217726 10246 solver.cpp:464] Iteration 27600, lr = 0.001
I0110 15:07:19.775451 10246 solver.cpp:189] Iteration 27700, loss = 0.0902129
I0110 15:07:19.775468 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0596623 (* 1 = 0.0596623 loss)
I0110 15:07:19.775472 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0305506 (* 1 = 0.0305506 loss)
I0110 15:07:19.775475 10246 solver.cpp:464] Iteration 27700, lr = 0.001
I0110 15:07:28.346438 10246 solver.cpp:189] Iteration 27800, loss = 0.074837
I0110 15:07:28.346456 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.024247 (* 1 = 0.024247 loss)
I0110 15:07:28.346459 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.05059 (* 1 = 0.05059 loss)
I0110 15:07:28.346462 10246 solver.cpp:464] Iteration 27800, lr = 0.001
I0110 15:07:36.949071 10246 solver.cpp:189] Iteration 27900, loss = 0.216595
I0110 15:07:36.949090 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.159713 (* 1 = 0.159713 loss)
I0110 15:07:36.949093 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0568826 (* 1 = 0.0568826 loss)
I0110 15:07:36.949096 10246 solver.cpp:464] Iteration 27900, lr = 0.001
speed: 0.086s / iter
I0110 15:07:45.514269 10246 solver.cpp:189] Iteration 28000, loss = 0.127175
I0110 15:07:45.514287 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.107156 (* 1 = 0.107156 loss)
I0110 15:07:45.514292 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0200191 (* 1 = 0.0200191 loss)
I0110 15:07:45.514294 10246 solver.cpp:464] Iteration 28000, lr = 0.001
I0110 15:07:54.056293 10246 solver.cpp:189] Iteration 28100, loss = 0.175008
I0110 15:07:54.056313 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.121278 (* 1 = 0.121278 loss)
I0110 15:07:54.056318 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0537305 (* 1 = 0.0537305 loss)
I0110 15:07:54.056323 10246 solver.cpp:464] Iteration 28100, lr = 0.001
I0110 15:08:02.685672 10246 solver.cpp:189] Iteration 28200, loss = 0.148445
I0110 15:08:02.685689 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0603278 (* 1 = 0.0603278 loss)
I0110 15:08:02.685693 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0881176 (* 1 = 0.0881176 loss)
I0110 15:08:02.685695 10246 solver.cpp:464] Iteration 28200, lr = 0.001
I0110 15:08:11.267427 10246 solver.cpp:189] Iteration 28300, loss = 0.038994
I0110 15:08:11.267444 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00646546 (* 1 = 0.00646546 loss)
I0110 15:08:11.267448 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0325285 (* 1 = 0.0325285 loss)
I0110 15:08:11.267452 10246 solver.cpp:464] Iteration 28300, lr = 0.001
I0110 15:08:19.835230 10246 solver.cpp:189] Iteration 28400, loss = 0.00563013
I0110 15:08:19.835248 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00118478 (* 1 = 0.00118478 loss)
I0110 15:08:19.835253 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00444535 (* 1 = 0.00444535 loss)
I0110 15:08:19.835255 10246 solver.cpp:464] Iteration 28400, lr = 0.001
I0110 15:08:28.384858 10246 solver.cpp:189] Iteration 28500, loss = 0.00507264
I0110 15:08:28.384876 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00221004 (* 1 = 0.00221004 loss)
I0110 15:08:28.384879 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0028626 (* 1 = 0.0028626 loss)
I0110 15:08:28.384882 10246 solver.cpp:464] Iteration 28500, lr = 0.001
I0110 15:08:37.085674 10246 solver.cpp:189] Iteration 28600, loss = 0.00175122
I0110 15:08:37.085691 10246 solver.cpp:204]     Train net output #0: loss_bbox = 7.40948e-05 (* 1 = 7.40948e-05 loss)
I0110 15:08:37.085695 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00167712 (* 1 = 0.00167712 loss)
I0110 15:08:37.085698 10246 solver.cpp:464] Iteration 28600, lr = 0.001
I0110 15:08:45.705907 10246 solver.cpp:189] Iteration 28700, loss = 0.147111
I0110 15:08:45.705925 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.129593 (* 1 = 0.129593 loss)
I0110 15:08:45.705929 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0175177 (* 1 = 0.0175177 loss)
I0110 15:08:45.705934 10246 solver.cpp:464] Iteration 28700, lr = 0.001
I0110 15:08:54.221403 10246 solver.cpp:189] Iteration 28800, loss = 0.145385
I0110 15:08:54.221421 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0589321 (* 1 = 0.0589321 loss)
I0110 15:08:54.221424 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0864533 (* 1 = 0.0864533 loss)
I0110 15:08:54.221427 10246 solver.cpp:464] Iteration 28800, lr = 0.001
I0110 15:09:02.736333 10246 solver.cpp:189] Iteration 28900, loss = 0.0598927
I0110 15:09:02.736351 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0117486 (* 1 = 0.0117486 loss)
I0110 15:09:02.736356 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.048144 (* 1 = 0.048144 loss)
I0110 15:09:02.736358 10246 solver.cpp:464] Iteration 28900, lr = 0.001
speed: 0.086s / iter
I0110 15:09:11.296875 10246 solver.cpp:189] Iteration 29000, loss = 0.0801081
I0110 15:09:11.296892 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00500489 (* 1 = 0.00500489 loss)
I0110 15:09:11.296896 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0751032 (* 1 = 0.0751032 loss)
I0110 15:09:11.296900 10246 solver.cpp:464] Iteration 29000, lr = 0.001
I0110 15:09:19.881248 10246 solver.cpp:189] Iteration 29100, loss = 0.00197867
I0110 15:09:19.881266 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00036251 (* 1 = 0.00036251 loss)
I0110 15:09:19.881269 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00161616 (* 1 = 0.00161616 loss)
I0110 15:09:19.881273 10246 solver.cpp:464] Iteration 29100, lr = 0.001
I0110 15:09:28.452293 10246 solver.cpp:189] Iteration 29200, loss = 0.0491996
I0110 15:09:28.452311 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00931575 (* 1 = 0.00931575 loss)
I0110 15:09:28.452316 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0398839 (* 1 = 0.0398839 loss)
I0110 15:09:28.452318 10246 solver.cpp:464] Iteration 29200, lr = 0.001
I0110 15:09:37.087746 10246 solver.cpp:189] Iteration 29300, loss = 0.00912093
I0110 15:09:37.087767 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00568739 (* 1 = 0.00568739 loss)
I0110 15:09:37.087772 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00343354 (* 1 = 0.00343354 loss)
I0110 15:09:37.087776 10246 solver.cpp:464] Iteration 29300, lr = 0.001
I0110 15:09:46.064560 10246 solver.cpp:189] Iteration 29400, loss = 0.11645
I0110 15:09:46.064579 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0537422 (* 1 = 0.0537422 loss)
I0110 15:09:46.064582 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0627074 (* 1 = 0.0627074 loss)
I0110 15:09:46.064586 10246 solver.cpp:464] Iteration 29400, lr = 0.001
I0110 15:09:54.732024 10246 solver.cpp:189] Iteration 29500, loss = 0.00133008
I0110 15:09:54.732043 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000674936 (* 1 = 0.000674936 loss)
I0110 15:09:54.732048 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.000655147 (* 1 = 0.000655147 loss)
I0110 15:09:54.732050 10246 solver.cpp:464] Iteration 29500, lr = 0.001
I0110 15:10:03.389555 10246 solver.cpp:189] Iteration 29600, loss = 0.130005
I0110 15:10:03.389575 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0709986 (* 1 = 0.0709986 loss)
I0110 15:10:03.389578 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0590062 (* 1 = 0.0590062 loss)
I0110 15:10:03.389581 10246 solver.cpp:464] Iteration 29600, lr = 0.001
I0110 15:10:11.944744 10246 solver.cpp:189] Iteration 29700, loss = 0.216805
I0110 15:10:11.944762 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0703414 (* 1 = 0.0703414 loss)
I0110 15:10:11.944766 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.146464 (* 1 = 0.146464 loss)
I0110 15:10:11.944769 10246 solver.cpp:464] Iteration 29700, lr = 0.001
I0110 15:10:20.458055 10246 solver.cpp:189] Iteration 29800, loss = 0.0631476
I0110 15:10:20.458072 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0248289 (* 1 = 0.0248289 loss)
I0110 15:10:20.458076 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0383187 (* 1 = 0.0383187 loss)
I0110 15:10:20.458079 10246 solver.cpp:464] Iteration 29800, lr = 0.001
I0110 15:10:29.072197 10246 solver.cpp:189] Iteration 29900, loss = 0.269944
I0110 15:10:29.072216 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0974005 (* 1 = 0.0974005 loss)
I0110 15:10:29.072219 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.172544 (* 1 = 0.172544 loss)
I0110 15:10:29.072223 10246 solver.cpp:464] Iteration 29900, lr = 0.001
speed: 0.086s / iter
Wrote snapshot to: /home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/output/IR_Reg/train/vgg_cnn_m_1024_fast_rcnn_iter_30000.caffemodel
I0110 15:10:38.836737 10246 solver.cpp:189] Iteration 30000, loss = 0.102122
I0110 15:10:38.836755 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0432486 (* 1 = 0.0432486 loss)
I0110 15:10:38.836760 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.058873 (* 1 = 0.058873 loss)
I0110 15:10:38.836763 10246 solver.cpp:464] Iteration 30000, lr = 0.0001
I0110 15:10:47.456120 10246 solver.cpp:189] Iteration 30100, loss = 0.0453263
I0110 15:10:47.456138 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0119618 (* 1 = 0.0119618 loss)
I0110 15:10:47.456141 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0333646 (* 1 = 0.0333646 loss)
I0110 15:10:47.456146 10246 solver.cpp:464] Iteration 30100, lr = 0.0001
I0110 15:10:56.524727 10246 solver.cpp:189] Iteration 30200, loss = 0.0949404
I0110 15:10:56.524745 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0515478 (* 1 = 0.0515478 loss)
I0110 15:10:56.524749 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0433926 (* 1 = 0.0433926 loss)
I0110 15:10:56.524752 10246 solver.cpp:464] Iteration 30200, lr = 0.0001
I0110 15:11:05.180425 10246 solver.cpp:189] Iteration 30300, loss = 0.0131121
I0110 15:11:05.180444 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0055522 (* 1 = 0.0055522 loss)
I0110 15:11:05.180447 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00755994 (* 1 = 0.00755994 loss)
I0110 15:11:05.180450 10246 solver.cpp:464] Iteration 30300, lr = 0.0001
I0110 15:11:13.829361 10246 solver.cpp:189] Iteration 30400, loss = 0.0555409
I0110 15:11:13.829378 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0282568 (* 1 = 0.0282568 loss)
I0110 15:11:13.829382 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0272841 (* 1 = 0.0272841 loss)
I0110 15:11:13.829385 10246 solver.cpp:464] Iteration 30400, lr = 0.0001
I0110 15:11:22.726821 10246 solver.cpp:189] Iteration 30500, loss = 0.00314918
I0110 15:11:22.726840 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000914604 (* 1 = 0.000914604 loss)
I0110 15:11:22.726843 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00223458 (* 1 = 0.00223458 loss)
I0110 15:11:22.726846 10246 solver.cpp:464] Iteration 30500, lr = 0.0001
I0110 15:11:31.247953 10246 solver.cpp:189] Iteration 30600, loss = 0.00180358
I0110 15:11:31.247972 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000441545 (* 1 = 0.000441545 loss)
I0110 15:11:31.247975 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00136204 (* 1 = 0.00136204 loss)
I0110 15:11:31.247978 10246 solver.cpp:464] Iteration 30600, lr = 0.0001
I0110 15:11:39.998324 10246 solver.cpp:189] Iteration 30700, loss = 0.00220731
I0110 15:11:39.998342 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00118648 (* 1 = 0.00118648 loss)
I0110 15:11:39.998345 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00102083 (* 1 = 0.00102083 loss)
I0110 15:11:39.998349 10246 solver.cpp:464] Iteration 30700, lr = 0.0001
I0110 15:11:48.595787 10246 solver.cpp:189] Iteration 30800, loss = 0.000863068
I0110 15:11:48.595804 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000136961 (* 1 = 0.000136961 loss)
I0110 15:11:48.595808 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.000726106 (* 1 = 0.000726106 loss)
I0110 15:11:48.595811 10246 solver.cpp:464] Iteration 30800, lr = 0.0001
I0110 15:11:57.250381 10246 solver.cpp:189] Iteration 30900, loss = 0.0380199
I0110 15:11:57.250399 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00550667 (* 1 = 0.00550667 loss)
I0110 15:11:57.250403 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0325132 (* 1 = 0.0325132 loss)
I0110 15:11:57.250406 10246 solver.cpp:464] Iteration 30900, lr = 0.0001
speed: 0.086s / iter
I0110 15:12:05.829650 10246 solver.cpp:189] Iteration 31000, loss = 0.0178705
I0110 15:12:05.829668 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.012975 (* 1 = 0.012975 loss)
I0110 15:12:05.829671 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00489552 (* 1 = 0.00489552 loss)
I0110 15:12:05.829674 10246 solver.cpp:464] Iteration 31000, lr = 0.0001
I0110 15:12:14.465804 10246 solver.cpp:189] Iteration 31100, loss = 0.111501
I0110 15:12:14.465823 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0655 (* 1 = 0.0655 loss)
I0110 15:12:14.465826 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0460009 (* 1 = 0.0460009 loss)
I0110 15:12:14.465829 10246 solver.cpp:464] Iteration 31100, lr = 0.0001
I0110 15:12:23.679795 10246 solver.cpp:189] Iteration 31200, loss = 0.0269222
I0110 15:12:23.679813 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00014083 (* 1 = 0.00014083 loss)
I0110 15:12:23.679817 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0267814 (* 1 = 0.0267814 loss)
I0110 15:12:23.679821 10246 solver.cpp:464] Iteration 31200, lr = 0.0001
I0110 15:12:32.461344 10246 solver.cpp:189] Iteration 31300, loss = 0.133625
I0110 15:12:32.461362 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0679112 (* 1 = 0.0679112 loss)
I0110 15:12:32.461365 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0657142 (* 1 = 0.0657142 loss)
I0110 15:12:32.461369 10246 solver.cpp:464] Iteration 31300, lr = 0.0001
I0110 15:12:41.143846 10246 solver.cpp:189] Iteration 31400, loss = 0.0736789
I0110 15:12:41.143864 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0287272 (* 1 = 0.0287272 loss)
I0110 15:12:41.143868 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0449517 (* 1 = 0.0449517 loss)
I0110 15:12:41.143872 10246 solver.cpp:464] Iteration 31400, lr = 0.0001
I0110 15:12:49.719004 10246 solver.cpp:189] Iteration 31500, loss = 0.240666
I0110 15:12:49.719022 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.101751 (* 1 = 0.101751 loss)
I0110 15:12:49.719027 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.138916 (* 1 = 0.138916 loss)
I0110 15:12:49.719029 10246 solver.cpp:464] Iteration 31500, lr = 0.0001
I0110 15:12:58.303432 10246 solver.cpp:189] Iteration 31600, loss = 0.0913131
I0110 15:12:58.303452 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.037473 (* 1 = 0.037473 loss)
I0110 15:12:58.303455 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0538401 (* 1 = 0.0538401 loss)
I0110 15:12:58.303457 10246 solver.cpp:464] Iteration 31600, lr = 0.0001
I0110 15:13:06.854048 10246 solver.cpp:189] Iteration 31700, loss = 0.0449257
I0110 15:13:06.854066 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0295628 (* 1 = 0.0295628 loss)
I0110 15:13:06.854070 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.015363 (* 1 = 0.015363 loss)
I0110 15:13:06.854074 10246 solver.cpp:464] Iteration 31700, lr = 0.0001
I0110 15:13:15.560698 10246 solver.cpp:189] Iteration 31800, loss = 0.0163981
I0110 15:13:15.560717 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00581625 (* 1 = 0.00581625 loss)
I0110 15:13:15.560721 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0105819 (* 1 = 0.0105819 loss)
I0110 15:13:15.560724 10246 solver.cpp:464] Iteration 31800, lr = 0.0001
I0110 15:13:24.132449 10246 solver.cpp:189] Iteration 31900, loss = 0.110689
I0110 15:13:24.132468 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0863362 (* 1 = 0.0863362 loss)
I0110 15:13:24.132472 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0243531 (* 1 = 0.0243531 loss)
I0110 15:13:24.132475 10246 solver.cpp:464] Iteration 31900, lr = 0.0001
speed: 0.086s / iter
I0110 15:13:32.718545 10246 solver.cpp:189] Iteration 32000, loss = 0.100716
I0110 15:13:32.718564 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.019573 (* 1 = 0.019573 loss)
I0110 15:13:32.718567 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0811434 (* 1 = 0.0811434 loss)
I0110 15:13:32.718570 10246 solver.cpp:464] Iteration 32000, lr = 0.0001
I0110 15:13:41.335775 10246 solver.cpp:189] Iteration 32100, loss = 0.00871845
I0110 15:13:41.335793 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00219624 (* 1 = 0.00219624 loss)
I0110 15:13:41.335798 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00652221 (* 1 = 0.00652221 loss)
I0110 15:13:41.335800 10246 solver.cpp:464] Iteration 32100, lr = 0.0001
I0110 15:13:49.939466 10246 solver.cpp:189] Iteration 32200, loss = 0.00543384
I0110 15:13:49.939486 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000407579 (* 1 = 0.000407579 loss)
I0110 15:13:49.939489 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00502626 (* 1 = 0.00502626 loss)
I0110 15:13:49.939492 10246 solver.cpp:464] Iteration 32200, lr = 0.0001
I0110 15:13:58.524320 10246 solver.cpp:189] Iteration 32300, loss = 0.078553
I0110 15:13:58.524338 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0375389 (* 1 = 0.0375389 loss)
I0110 15:13:58.524341 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0410141 (* 1 = 0.0410141 loss)
I0110 15:13:58.524344 10246 solver.cpp:464] Iteration 32300, lr = 0.0001
I0110 15:14:07.214084 10246 solver.cpp:189] Iteration 32400, loss = 0.00534665
I0110 15:14:07.214103 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000130226 (* 1 = 0.000130226 loss)
I0110 15:14:07.214107 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00521643 (* 1 = 0.00521643 loss)
I0110 15:14:07.214112 10246 solver.cpp:464] Iteration 32400, lr = 0.0001
I0110 15:14:15.739557 10246 solver.cpp:189] Iteration 32500, loss = 0.0206244
I0110 15:14:15.739575 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00542182 (* 1 = 0.00542182 loss)
I0110 15:14:15.739579 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0152026 (* 1 = 0.0152026 loss)
I0110 15:14:15.739583 10246 solver.cpp:464] Iteration 32500, lr = 0.0001
I0110 15:14:24.247777 10246 solver.cpp:189] Iteration 32600, loss = 0.0866546
I0110 15:14:24.247795 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0530445 (* 1 = 0.0530445 loss)
I0110 15:14:24.247799 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0336101 (* 1 = 0.0336101 loss)
I0110 15:14:24.247802 10246 solver.cpp:464] Iteration 32600, lr = 0.0001
I0110 15:14:32.770576 10246 solver.cpp:189] Iteration 32700, loss = 0.0629581
I0110 15:14:32.770594 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00912302 (* 1 = 0.00912302 loss)
I0110 15:14:32.770597 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0538351 (* 1 = 0.0538351 loss)
I0110 15:14:32.770601 10246 solver.cpp:464] Iteration 32700, lr = 0.0001
I0110 15:14:41.245015 10246 solver.cpp:189] Iteration 32800, loss = 0.0399909
I0110 15:14:41.245033 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.012291 (* 1 = 0.012291 loss)
I0110 15:14:41.245036 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0276999 (* 1 = 0.0276999 loss)
I0110 15:14:41.245039 10246 solver.cpp:464] Iteration 32800, lr = 0.0001
I0110 15:14:49.960186 10246 solver.cpp:189] Iteration 32900, loss = 0.226627
I0110 15:14:49.960206 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.121351 (* 1 = 0.121351 loss)
I0110 15:14:49.960209 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.105276 (* 1 = 0.105276 loss)
I0110 15:14:49.960212 10246 solver.cpp:464] Iteration 32900, lr = 0.0001
speed: 0.086s / iter
I0110 15:14:58.523600 10246 solver.cpp:189] Iteration 33000, loss = 0.152724
I0110 15:14:58.523618 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.137705 (* 1 = 0.137705 loss)
I0110 15:14:58.523622 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0150188 (* 1 = 0.0150188 loss)
I0110 15:14:58.523625 10246 solver.cpp:464] Iteration 33000, lr = 0.0001
I0110 15:15:07.198246 10246 solver.cpp:189] Iteration 33100, loss = 0.186606
I0110 15:15:07.198266 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.156797 (* 1 = 0.156797 loss)
I0110 15:15:07.198268 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0298097 (* 1 = 0.0298097 loss)
I0110 15:15:07.198272 10246 solver.cpp:464] Iteration 33100, lr = 0.0001
I0110 15:15:15.776499 10246 solver.cpp:189] Iteration 33200, loss = 0.0953123
I0110 15:15:15.776517 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0303193 (* 1 = 0.0303193 loss)
I0110 15:15:15.776521 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.064993 (* 1 = 0.064993 loss)
I0110 15:15:15.776525 10246 solver.cpp:464] Iteration 33200, lr = 0.0001
I0110 15:15:24.361578 10246 solver.cpp:189] Iteration 33300, loss = 0.0787082
I0110 15:15:24.361596 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0338716 (* 1 = 0.0338716 loss)
I0110 15:15:24.361600 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0448366 (* 1 = 0.0448366 loss)
I0110 15:15:24.361603 10246 solver.cpp:464] Iteration 33300, lr = 0.0001
I0110 15:15:32.871206 10246 solver.cpp:189] Iteration 33400, loss = 0.0164014
I0110 15:15:32.871223 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00878441 (* 1 = 0.00878441 loss)
I0110 15:15:32.871227 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00761701 (* 1 = 0.00761701 loss)
I0110 15:15:32.871230 10246 solver.cpp:464] Iteration 33400, lr = 0.0001
I0110 15:15:41.390053 10246 solver.cpp:189] Iteration 33500, loss = 0.0376621
I0110 15:15:41.390070 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00492865 (* 1 = 0.00492865 loss)
I0110 15:15:41.390074 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0327334 (* 1 = 0.0327334 loss)
I0110 15:15:41.390077 10246 solver.cpp:464] Iteration 33500, lr = 0.0001
I0110 15:15:49.910776 10246 solver.cpp:189] Iteration 33600, loss = 0.161358
I0110 15:15:49.910794 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0733978 (* 1 = 0.0733978 loss)
I0110 15:15:49.910797 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0879603 (* 1 = 0.0879603 loss)
I0110 15:15:49.910801 10246 solver.cpp:464] Iteration 33600, lr = 0.0001
I0110 15:15:58.699730 10246 solver.cpp:189] Iteration 33700, loss = 0.0465785
I0110 15:15:58.699748 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00212757 (* 1 = 0.00212757 loss)
I0110 15:15:58.699753 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.044451 (* 1 = 0.044451 loss)
I0110 15:15:58.699755 10246 solver.cpp:464] Iteration 33700, lr = 0.0001
I0110 15:16:07.442234 10246 solver.cpp:189] Iteration 33800, loss = 0.0763911
I0110 15:16:07.442251 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0176556 (* 1 = 0.0176556 loss)
I0110 15:16:07.442255 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0587354 (* 1 = 0.0587354 loss)
I0110 15:16:07.442258 10246 solver.cpp:464] Iteration 33800, lr = 0.0001
I0110 15:16:16.149278 10246 solver.cpp:189] Iteration 33900, loss = 0.0237532
I0110 15:16:16.149297 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00537486 (* 1 = 0.00537486 loss)
I0110 15:16:16.149300 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0183783 (* 1 = 0.0183783 loss)
I0110 15:16:16.149304 10246 solver.cpp:464] Iteration 33900, lr = 0.0001
speed: 0.086s / iter
I0110 15:16:24.777170 10246 solver.cpp:189] Iteration 34000, loss = 0.0281075
I0110 15:16:24.777190 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00316846 (* 1 = 0.00316846 loss)
I0110 15:16:24.777195 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.024939 (* 1 = 0.024939 loss)
I0110 15:16:24.777199 10246 solver.cpp:464] Iteration 34000, lr = 0.0001
I0110 15:16:33.288314 10246 solver.cpp:189] Iteration 34100, loss = 0.0579334
I0110 15:16:33.288332 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0530644 (* 1 = 0.0530644 loss)
I0110 15:16:33.288336 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00486899 (* 1 = 0.00486899 loss)
I0110 15:16:33.288339 10246 solver.cpp:464] Iteration 34100, lr = 0.0001
I0110 15:16:41.985451 10246 solver.cpp:189] Iteration 34200, loss = 0.12266
I0110 15:16:41.985469 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0633622 (* 1 = 0.0633622 loss)
I0110 15:16:41.985473 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0592973 (* 1 = 0.0592973 loss)
I0110 15:16:41.985476 10246 solver.cpp:464] Iteration 34200, lr = 0.0001
I0110 15:16:50.605696 10246 solver.cpp:189] Iteration 34300, loss = 0.0821001
I0110 15:16:50.605715 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0522124 (* 1 = 0.0522124 loss)
I0110 15:16:50.605718 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0298877 (* 1 = 0.0298877 loss)
I0110 15:16:50.605722 10246 solver.cpp:464] Iteration 34300, lr = 0.0001
I0110 15:16:59.229769 10246 solver.cpp:189] Iteration 34400, loss = 0.188412
I0110 15:16:59.229789 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0913389 (* 1 = 0.0913389 loss)
I0110 15:16:59.229792 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0970731 (* 1 = 0.0970731 loss)
I0110 15:16:59.229795 10246 solver.cpp:464] Iteration 34400, lr = 0.0001
I0110 15:17:07.802089 10246 solver.cpp:189] Iteration 34500, loss = 0.147975
I0110 15:17:07.802106 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0599528 (* 1 = 0.0599528 loss)
I0110 15:17:07.802110 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0880226 (* 1 = 0.0880226 loss)
I0110 15:17:07.802114 10246 solver.cpp:464] Iteration 34500, lr = 0.0001
I0110 15:17:16.356104 10246 solver.cpp:189] Iteration 34600, loss = 0.0167917
I0110 15:17:16.356122 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00402955 (* 1 = 0.00402955 loss)
I0110 15:17:16.356125 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0127622 (* 1 = 0.0127622 loss)
I0110 15:17:16.356129 10246 solver.cpp:464] Iteration 34600, lr = 0.0001
I0110 15:17:25.003259 10246 solver.cpp:189] Iteration 34700, loss = 0.088569
I0110 15:17:25.003278 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00973286 (* 1 = 0.00973286 loss)
I0110 15:17:25.003283 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0788362 (* 1 = 0.0788362 loss)
I0110 15:17:25.003285 10246 solver.cpp:464] Iteration 34700, lr = 0.0001
I0110 15:17:33.497298 10246 solver.cpp:189] Iteration 34800, loss = 0.184328
I0110 15:17:33.497318 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0931838 (* 1 = 0.0931838 loss)
I0110 15:17:33.497320 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0911443 (* 1 = 0.0911443 loss)
I0110 15:17:33.497323 10246 solver.cpp:464] Iteration 34800, lr = 0.0001
I0110 15:17:41.923084 10246 solver.cpp:189] Iteration 34900, loss = 0.00625173
I0110 15:17:41.923102 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000592784 (* 1 = 0.000592784 loss)
I0110 15:17:41.923106 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00565894 (* 1 = 0.00565894 loss)
I0110 15:17:41.923110 10246 solver.cpp:464] Iteration 34900, lr = 0.0001
speed: 0.086s / iter
I0110 15:17:50.405000 10246 solver.cpp:189] Iteration 35000, loss = 0.0400497
I0110 15:17:50.405019 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0209232 (* 1 = 0.0209232 loss)
I0110 15:17:50.405021 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0191265 (* 1 = 0.0191265 loss)
I0110 15:17:50.405025 10246 solver.cpp:464] Iteration 35000, lr = 0.0001
I0110 15:17:58.950587 10246 solver.cpp:189] Iteration 35100, loss = 0.0903264
I0110 15:17:58.950605 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0321163 (* 1 = 0.0321163 loss)
I0110 15:17:58.950609 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0582101 (* 1 = 0.0582101 loss)
I0110 15:17:58.950613 10246 solver.cpp:464] Iteration 35100, lr = 0.0001
I0110 15:18:07.407466 10246 solver.cpp:189] Iteration 35200, loss = 0.00820853
I0110 15:18:07.407485 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00750323 (* 1 = 0.00750323 loss)
I0110 15:18:07.407488 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.000705307 (* 1 = 0.000705307 loss)
I0110 15:18:07.407491 10246 solver.cpp:464] Iteration 35200, lr = 0.0001
I0110 15:18:15.851975 10246 solver.cpp:189] Iteration 35300, loss = 0.0885433
I0110 15:18:15.851994 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0315444 (* 1 = 0.0315444 loss)
I0110 15:18:15.851996 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0569989 (* 1 = 0.0569989 loss)
I0110 15:18:15.851999 10246 solver.cpp:464] Iteration 35300, lr = 0.0001
I0110 15:18:24.323812 10246 solver.cpp:189] Iteration 35400, loss = 0.0949453
I0110 15:18:24.323830 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0432951 (* 1 = 0.0432951 loss)
I0110 15:18:24.323834 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0516502 (* 1 = 0.0516502 loss)
I0110 15:18:24.323837 10246 solver.cpp:464] Iteration 35400, lr = 0.0001
I0110 15:18:32.813277 10246 solver.cpp:189] Iteration 35500, loss = 0.044697
I0110 15:18:32.813294 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0309211 (* 1 = 0.0309211 loss)
I0110 15:18:32.813298 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0137759 (* 1 = 0.0137759 loss)
I0110 15:18:32.813302 10246 solver.cpp:464] Iteration 35500, lr = 0.0001
I0110 15:18:41.581784 10246 solver.cpp:189] Iteration 35600, loss = 0.0138372
I0110 15:18:41.581801 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00684501 (* 1 = 0.00684501 loss)
I0110 15:18:41.581805 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00699219 (* 1 = 0.00699219 loss)
I0110 15:18:41.581809 10246 solver.cpp:464] Iteration 35600, lr = 0.0001
I0110 15:18:50.291692 10246 solver.cpp:189] Iteration 35700, loss = 0.0469117
I0110 15:18:50.291709 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0320573 (* 1 = 0.0320573 loss)
I0110 15:18:50.291712 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0148544 (* 1 = 0.0148544 loss)
I0110 15:18:50.291716 10246 solver.cpp:464] Iteration 35700, lr = 0.0001
I0110 15:18:58.905855 10246 solver.cpp:189] Iteration 35800, loss = 0.153551
I0110 15:18:58.905874 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0409258 (* 1 = 0.0409258 loss)
I0110 15:18:58.905877 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.112625 (* 1 = 0.112625 loss)
I0110 15:18:58.905880 10246 solver.cpp:464] Iteration 35800, lr = 0.0001
I0110 15:19:07.510658 10246 solver.cpp:189] Iteration 35900, loss = 0.0953852
I0110 15:19:07.510676 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0220299 (* 1 = 0.0220299 loss)
I0110 15:19:07.510680 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0733553 (* 1 = 0.0733553 loss)
I0110 15:19:07.510684 10246 solver.cpp:464] Iteration 35900, lr = 0.0001
speed: 0.086s / iter
I0110 15:19:16.273355 10246 solver.cpp:189] Iteration 36000, loss = 0.0679795
I0110 15:19:16.273373 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00809923 (* 1 = 0.00809923 loss)
I0110 15:19:16.273377 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0598803 (* 1 = 0.0598803 loss)
I0110 15:19:16.273380 10246 solver.cpp:464] Iteration 36000, lr = 0.0001
I0110 15:19:24.987613 10246 solver.cpp:189] Iteration 36100, loss = 0.246181
I0110 15:19:24.987632 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.102022 (* 1 = 0.102022 loss)
I0110 15:19:24.987634 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.144159 (* 1 = 0.144159 loss)
I0110 15:19:24.987638 10246 solver.cpp:464] Iteration 36100, lr = 0.0001
I0110 15:19:33.648882 10246 solver.cpp:189] Iteration 36200, loss = 0.0339802
I0110 15:19:33.648900 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00666538 (* 1 = 0.00666538 loss)
I0110 15:19:33.648905 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0273148 (* 1 = 0.0273148 loss)
I0110 15:19:33.648907 10246 solver.cpp:464] Iteration 36200, lr = 0.0001
I0110 15:19:42.303587 10246 solver.cpp:189] Iteration 36300, loss = 0.0481265
I0110 15:19:42.303604 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0424269 (* 1 = 0.0424269 loss)
I0110 15:19:42.303608 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00569959 (* 1 = 0.00569959 loss)
I0110 15:19:42.303611 10246 solver.cpp:464] Iteration 36300, lr = 0.0001
I0110 15:19:50.822979 10246 solver.cpp:189] Iteration 36400, loss = 0.115643
I0110 15:19:50.822998 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0445724 (* 1 = 0.0445724 loss)
I0110 15:19:50.823000 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0710709 (* 1 = 0.0710709 loss)
I0110 15:19:50.823004 10246 solver.cpp:464] Iteration 36400, lr = 0.0001
I0110 15:19:59.335634 10246 solver.cpp:189] Iteration 36500, loss = 0.116161
I0110 15:19:59.335652 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0500896 (* 1 = 0.0500896 loss)
I0110 15:19:59.335655 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.066071 (* 1 = 0.066071 loss)
I0110 15:19:59.335659 10246 solver.cpp:464] Iteration 36500, lr = 0.0001
I0110 15:20:07.956445 10246 solver.cpp:189] Iteration 36600, loss = 0.139576
I0110 15:20:07.956463 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0563472 (* 1 = 0.0563472 loss)
I0110 15:20:07.956467 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.083229 (* 1 = 0.083229 loss)
I0110 15:20:07.956470 10246 solver.cpp:464] Iteration 36600, lr = 0.0001
I0110 15:20:16.666800 10246 solver.cpp:189] Iteration 36700, loss = 0.0106039
I0110 15:20:16.666817 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00315044 (* 1 = 0.00315044 loss)
I0110 15:20:16.666821 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00745346 (* 1 = 0.00745346 loss)
I0110 15:20:16.666823 10246 solver.cpp:464] Iteration 36700, lr = 0.0001
I0110 15:20:25.334496 10246 solver.cpp:189] Iteration 36800, loss = 0.139766
I0110 15:20:25.334514 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0440462 (* 1 = 0.0440462 loss)
I0110 15:20:25.334518 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0957196 (* 1 = 0.0957196 loss)
I0110 15:20:25.334522 10246 solver.cpp:464] Iteration 36800, lr = 0.0001
I0110 15:20:33.918659 10246 solver.cpp:189] Iteration 36900, loss = 0.115883
I0110 15:20:33.918678 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0383185 (* 1 = 0.0383185 loss)
I0110 15:20:33.918681 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0775642 (* 1 = 0.0775642 loss)
I0110 15:20:33.918684 10246 solver.cpp:464] Iteration 36900, lr = 0.0001
speed: 0.086s / iter
I0110 15:20:42.546454 10246 solver.cpp:189] Iteration 37000, loss = 0.19439
I0110 15:20:42.546473 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0533896 (* 1 = 0.0533896 loss)
I0110 15:20:42.546475 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.141 (* 1 = 0.141 loss)
I0110 15:20:42.546479 10246 solver.cpp:464] Iteration 37000, lr = 0.0001
I0110 15:20:51.158798 10246 solver.cpp:189] Iteration 37100, loss = 0.150352
I0110 15:20:51.158816 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0220528 (* 1 = 0.0220528 loss)
I0110 15:20:51.158819 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.128299 (* 1 = 0.128299 loss)
I0110 15:20:51.158823 10246 solver.cpp:464] Iteration 37100, lr = 0.0001
I0110 15:20:59.770686 10246 solver.cpp:189] Iteration 37200, loss = 0.189582
I0110 15:20:59.770704 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0874444 (* 1 = 0.0874444 loss)
I0110 15:20:59.770707 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.102138 (* 1 = 0.102138 loss)
I0110 15:20:59.770710 10246 solver.cpp:464] Iteration 37200, lr = 0.0001
I0110 15:21:08.445340 10246 solver.cpp:189] Iteration 37300, loss = 0.016895
I0110 15:21:08.445359 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0156488 (* 1 = 0.0156488 loss)
I0110 15:21:08.445363 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00124621 (* 1 = 0.00124621 loss)
I0110 15:21:08.445366 10246 solver.cpp:464] Iteration 37300, lr = 0.0001
I0110 15:21:17.197597 10246 solver.cpp:189] Iteration 37400, loss = 0.0426235
I0110 15:21:17.197615 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0309373 (* 1 = 0.0309373 loss)
I0110 15:21:17.197619 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0116863 (* 1 = 0.0116863 loss)
I0110 15:21:17.197623 10246 solver.cpp:464] Iteration 37400, lr = 0.0001
I0110 15:21:25.934139 10246 solver.cpp:189] Iteration 37500, loss = 0.0670063
I0110 15:21:25.934159 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0603735 (* 1 = 0.0603735 loss)
I0110 15:21:25.934162 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00663273 (* 1 = 0.00663273 loss)
I0110 15:21:25.934165 10246 solver.cpp:464] Iteration 37500, lr = 0.0001
I0110 15:21:34.680008 10246 solver.cpp:189] Iteration 37600, loss = 0.114435
I0110 15:21:34.680027 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.082015 (* 1 = 0.082015 loss)
I0110 15:21:34.680030 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0324196 (* 1 = 0.0324196 loss)
I0110 15:21:34.680033 10246 solver.cpp:464] Iteration 37600, lr = 0.0001
I0110 15:21:43.282539 10246 solver.cpp:189] Iteration 37700, loss = 0.136315
I0110 15:21:43.282557 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0216779 (* 1 = 0.0216779 loss)
I0110 15:21:43.282560 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.114637 (* 1 = 0.114637 loss)
I0110 15:21:43.282563 10246 solver.cpp:464] Iteration 37700, lr = 0.0001
I0110 15:21:51.877090 10246 solver.cpp:189] Iteration 37800, loss = 0.0491185
I0110 15:21:51.877110 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0335142 (* 1 = 0.0335142 loss)
I0110 15:21:51.877113 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0156044 (* 1 = 0.0156044 loss)
I0110 15:21:51.877116 10246 solver.cpp:464] Iteration 37800, lr = 0.0001
I0110 15:22:00.414273 10246 solver.cpp:189] Iteration 37900, loss = 0.013343
I0110 15:22:00.414290 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000275923 (* 1 = 0.000275923 loss)
I0110 15:22:00.414294 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0130671 (* 1 = 0.0130671 loss)
I0110 15:22:00.414297 10246 solver.cpp:464] Iteration 37900, lr = 0.0001
speed: 0.086s / iter
I0110 15:22:09.153169 10246 solver.cpp:189] Iteration 38000, loss = 0.0050082
I0110 15:22:09.153187 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00310338 (* 1 = 0.00310338 loss)
I0110 15:22:09.153192 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00190482 (* 1 = 0.00190482 loss)
I0110 15:22:09.153194 10246 solver.cpp:464] Iteration 38000, lr = 0.0001
I0110 15:22:17.854296 10246 solver.cpp:189] Iteration 38100, loss = 0.00530905
I0110 15:22:17.854315 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000181508 (* 1 = 0.000181508 loss)
I0110 15:22:17.854318 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00512754 (* 1 = 0.00512754 loss)
I0110 15:22:17.854321 10246 solver.cpp:464] Iteration 38100, lr = 0.0001
I0110 15:22:26.639749 10246 solver.cpp:189] Iteration 38200, loss = 0.164118
I0110 15:22:26.639765 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0571856 (* 1 = 0.0571856 loss)
I0110 15:22:26.639770 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.106932 (* 1 = 0.106932 loss)
I0110 15:22:26.639772 10246 solver.cpp:464] Iteration 38200, lr = 0.0001
I0110 15:22:35.294050 10246 solver.cpp:189] Iteration 38300, loss = 0.078549
I0110 15:22:35.294069 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.040102 (* 1 = 0.040102 loss)
I0110 15:22:35.294071 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.038447 (* 1 = 0.038447 loss)
I0110 15:22:35.294075 10246 solver.cpp:464] Iteration 38300, lr = 0.0001
I0110 15:22:43.945035 10246 solver.cpp:189] Iteration 38400, loss = 0.152855
I0110 15:22:43.945055 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0794536 (* 1 = 0.0794536 loss)
I0110 15:22:43.945060 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0734014 (* 1 = 0.0734014 loss)
I0110 15:22:43.945062 10246 solver.cpp:464] Iteration 38400, lr = 0.0001
I0110 15:22:52.654387 10246 solver.cpp:189] Iteration 38500, loss = 0.157186
I0110 15:22:52.654405 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0493977 (* 1 = 0.0493977 loss)
I0110 15:22:52.654409 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.107788 (* 1 = 0.107788 loss)
I0110 15:22:52.654412 10246 solver.cpp:464] Iteration 38500, lr = 0.0001
I0110 15:23:01.294018 10246 solver.cpp:189] Iteration 38600, loss = 0.0399291
I0110 15:23:01.294036 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0217716 (* 1 = 0.0217716 loss)
I0110 15:23:01.294039 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0181575 (* 1 = 0.0181575 loss)
I0110 15:23:01.294042 10246 solver.cpp:464] Iteration 38600, lr = 0.0001
I0110 15:23:09.853814 10246 solver.cpp:189] Iteration 38700, loss = 0.0128597
I0110 15:23:09.853832 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000779675 (* 1 = 0.000779675 loss)
I0110 15:23:09.853837 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.01208 (* 1 = 0.01208 loss)
I0110 15:23:09.853839 10246 solver.cpp:464] Iteration 38700, lr = 0.0001
I0110 15:23:18.735173 10246 solver.cpp:189] Iteration 38800, loss = 0.00537969
I0110 15:23:18.735191 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00339048 (* 1 = 0.00339048 loss)
I0110 15:23:18.735195 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00198921 (* 1 = 0.00198921 loss)
I0110 15:23:18.735198 10246 solver.cpp:464] Iteration 38800, lr = 0.0001
I0110 15:23:27.399097 10246 solver.cpp:189] Iteration 38900, loss = 0.0479726
I0110 15:23:27.399116 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0112102 (* 1 = 0.0112102 loss)
I0110 15:23:27.399118 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0367624 (* 1 = 0.0367624 loss)
I0110 15:23:27.399121 10246 solver.cpp:464] Iteration 38900, lr = 0.0001
speed: 0.086s / iter
I0110 15:23:35.982291 10246 solver.cpp:189] Iteration 39000, loss = 0.0131848
I0110 15:23:35.982309 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00942052 (* 1 = 0.00942052 loss)
I0110 15:23:35.982312 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00376429 (* 1 = 0.00376429 loss)
I0110 15:23:35.982316 10246 solver.cpp:464] Iteration 39000, lr = 0.0001
I0110 15:23:44.553966 10246 solver.cpp:189] Iteration 39100, loss = 0.0730682
I0110 15:23:44.553982 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00667661 (* 1 = 0.00667661 loss)
I0110 15:23:44.553987 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0663916 (* 1 = 0.0663916 loss)
I0110 15:23:44.553989 10246 solver.cpp:464] Iteration 39100, lr = 0.0001
I0110 15:23:53.107357 10246 solver.cpp:189] Iteration 39200, loss = 0.119213
I0110 15:23:53.107373 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0589286 (* 1 = 0.0589286 loss)
I0110 15:23:53.107378 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0602849 (* 1 = 0.0602849 loss)
I0110 15:23:53.107380 10246 solver.cpp:464] Iteration 39200, lr = 0.0001
I0110 15:24:01.825526 10246 solver.cpp:189] Iteration 39300, loss = 0.0106707
I0110 15:24:01.825544 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.00731759 (* 1 = 0.00731759 loss)
I0110 15:24:01.825548 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00335315 (* 1 = 0.00335315 loss)
I0110 15:24:01.825551 10246 solver.cpp:464] Iteration 39300, lr = 0.0001
I0110 15:24:10.590813 10246 solver.cpp:189] Iteration 39400, loss = 0.126637
I0110 15:24:10.590831 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0243248 (* 1 = 0.0243248 loss)
I0110 15:24:10.590836 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.102313 (* 1 = 0.102313 loss)
I0110 15:24:10.590838 10246 solver.cpp:464] Iteration 39400, lr = 0.0001
I0110 15:24:19.246120 10246 solver.cpp:189] Iteration 39500, loss = 0.00599272
I0110 15:24:19.246140 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.000516289 (* 1 = 0.000516289 loss)
I0110 15:24:19.246143 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.00547644 (* 1 = 0.00547644 loss)
I0110 15:24:19.246146 10246 solver.cpp:464] Iteration 39500, lr = 0.0001
I0110 15:24:27.769563 10246 solver.cpp:189] Iteration 39600, loss = 0.0970643
I0110 15:24:27.769582 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0576487 (* 1 = 0.0576487 loss)
I0110 15:24:27.769585 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0394156 (* 1 = 0.0394156 loss)
I0110 15:24:27.769588 10246 solver.cpp:464] Iteration 39600, lr = 0.0001
I0110 15:24:36.361703 10246 solver.cpp:189] Iteration 39700, loss = 0.0357004
I0110 15:24:36.361722 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0127975 (* 1 = 0.0127975 loss)
I0110 15:24:36.361726 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.022903 (* 1 = 0.022903 loss)
I0110 15:24:36.361728 10246 solver.cpp:464] Iteration 39700, lr = 0.0001
I0110 15:24:45.095468 10246 solver.cpp:189] Iteration 39800, loss = 0.0541414
I0110 15:24:45.095487 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.019982 (* 1 = 0.019982 loss)
I0110 15:24:45.095490 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0341594 (* 1 = 0.0341594 loss)
I0110 15:24:45.095494 10246 solver.cpp:464] Iteration 39800, lr = 0.0001
I0110 15:24:53.812652 10246 solver.cpp:189] Iteration 39900, loss = 0.116919
I0110 15:24:53.812671 10246 solver.cpp:204]     Train net output #0: loss_bbox = 0.0706702 (* 1 = 0.0706702 loss)
I0110 15:24:53.812674 10246 solver.cpp:204]     Train net output #1: loss_cls = 0.0462484 (* 1 = 0.0462484 loss)
I0110 15:24:53.812678 10246 solver.cpp:464] Iteration 39900, lr = 0.0001
speed: 0.086s / iter
Wrote snapshot to: /home/shuoliu/Research/IROD/Code/sensiac_fast_rcnn_quebec/output/IR_Reg/train/vgg_cnn_m_1024_fast_rcnn_iter_40000.caffemodel
done solving
3606.485158

real	57m43.451s
user	53m8.472s
sys	7m3.172s
+ --solver models/VGG_CNN_M_1024/solver.prototxt --weights data/imagenet_models/VGG_CNN_M_1024.v2.caffemodel --imdb sensiac_train --iters 40000
experiments/scripts/train_vgg_cnn_m_1024.sh: line 13: --solver: command not found
